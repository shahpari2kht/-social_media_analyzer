{"kind": "Listing", "data": {"after": "t3_1nhskvc", "dist": 100, "modhash": "", "geo_filter": null, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 27 Oct, 2025 - 03 Nov, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oh4tzk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761537697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1oh4tzk", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 24, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oh4tzk/weekly_entering_transitioning_thread_27_oct_2025/", "stickied": true, "url": "https://www.reddit.com/r/datascience/comments/1oh4tzk/weekly_entering_transitioning_thread_27_oct_2025/", "subreddit_subscribers": 2695443, "created_utc": 1761537697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve heard that many BIEs and data professionals have been laid off recently. It\u2019s quite unsettling to see, and I\u2019m feeling anxious both as an employee, since it could happen at my company too and as a job seeker, knowing that many of those laid-off professionals will now be competing in the job market alongside me.", "author_fullname": "t2_13xfrfu1xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So what do y\u2019all think of the Amazon layoffs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oje977", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761766511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard that many BIEs and data professionals have been laid off recently. It\u2019s quite unsettling to see, and I\u2019m feeling anxious both as an employee, since it could happen at my company too and as a job seeker, knowing that many of those laid-off professionals will now be competing in the job market alongside me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1oje977", "is_robot_indexable": true, "report_reasons": null, "author": "Lamp_Shade_Head", "discussion_type": null, "num_comments": 64, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oje977/so_what_do_yall_think_of_the_amazon_layoffs/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oje977/so_what_do_yall_think_of_the_amazon_layoffs/", "subreddit_subscribers": 2695443, "created_utc": 1761766511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, \n\nI just wrote this article on Medium I would appreciate any feedback and I would like to know what you think about the matter (since it touches also a bit on ethics).\n\nLink: [https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a](https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a)", "author_fullname": "t2_2opbolsh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Light read on the environmental footprint of data centers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oj9qua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1761756538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I just wrote this article on Medium I would appreciate any feedback and I would like to know what you think about the matter (since it touches also a bit on ethics).&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a\"&gt;https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?auto=webp&amp;s=4b1c80c002fd93a39316e908521d2c8269f40178", "width": 1200, "height": 896}, "resolutions": [{"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37b4e64eb64bb3296568f672da310c4467a99fb9", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b7413c1528c33b187773e8f3072eed6a2ee2565d", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a3fc81ca750d7f373036bbb5d09a1ff75716dc0", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14f8b0d7f2cbecc97b460667330bd0a6cd75b73d", "width": 640, "height": 477}, {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45594686cb0c4a9fb508e87a833e617bf3bf5bcb", "width": 960, "height": 716}, {"url": "https://external-preview.redd.it/IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5441fdee2d72c31dd5246e1908b9dbcb4c75103c", "width": 1080, "height": 806}], "variants": {}, "id": "IAUxWmGA305Wqsly3zUEj0ZWRmbuNAruXHFXbdElBXM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1oj9qua", "is_robot_indexable": true, "report_reasons": null, "author": "ArugulaImpossible134", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oj9qua/light_read_on_the_environmental_footprint_of_data/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oj9qua/light_read_on_the_environmental_footprint_of_data/", "subreddit_subscribers": 2695443, "created_utc": 1761756538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data engineer/analytics engineer and am given about 2 weeks to fully develop 3-4 datasets that are used in the backend for various applications. The issue is the following:\n\n1. Theoretically, if I had even 80% clarity in requirements, I could probably finish a dataset in a span of 1-3 days. However, this is never the case - the requirements are frequently 50% clear, I have to figure that out along developing the dataset. When there\u2019s an issue upstream of me, I have to go back to the source files and dig deep why something is missing. I have to wait on another engineer frequently in the process to either QA why something is missing or merge my pull requests which has frequent delays. \n\n2. In between all of this work, I frequently get asked to make enhancements or fix bugs from previous work that can easily eat 1-3 days. Some of these bugs are random and occur because the source data upstream of me randomly changed that broke my entire process. Enhancements sound simple in theory until I actually work on it. \n\n3. There\u2019s no standard QA process. I told my boss I wanted to develop scripts to do QA as frequently in the past if we had data issues, I would be notified by either my boss or a stakeholder because they happened to notice the issue. I figured if I run a daily script where I can get an automated email that shows all my datasets and what\u2019s going on, it can be easier to be proactive rather than reactive. My boss said that this is something another team is working on developing but there\u2019s no sign that there is such a thing being developed and developing a QA process for every individual project is entirely on me to figure out \n\n4. There\u2019s NO documentation. My team is trying to get better at this but all my projects have been a product of zero past documentation. In order to get better at this, I\u2019m expected to create documentation on top of all this work. Documentation can easily take me 1-2 days for each project and sometimes it gets pushed to the side because of focusing on 1-3.\n\nEven documenting on Jira easily takes me 30 mins - 1 hour \n\n5. Add 3 hours of meeting a day on this already full plate \n\n\nInstead of 3 projects in 2 weeks, I feel if my focus was on just one project - from development, QA, documentation, it would be way more manageable. But there isn\u2019t really an option on my team as they\u2019re obsessed with scaling up, I\u2019m frequently told everything is a priority. My eating and sleeping schedule had gotten so messed up in the span of the past few months - I don\u2019t have time to make breakfast, lunch or dinner and end up skipping meals a lot. I wish to get a new job and would have easily started applying now if the economy wasn\u2019t so bad. \n\nI\u2019m wondering if others have experienced similar. ", "author_fullname": "t2_2prckadt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "burning out because nothing takes as short as the time im expected to complete tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oigf8k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761674097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data engineer/analytics engineer and am given about 2 weeks to fully develop 3-4 datasets that are used in the backend for various applications. The issue is the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Theoretically, if I had even 80% clarity in requirements, I could probably finish a dataset in a span of 1-3 days. However, this is never the case - the requirements are frequently 50% clear, I have to figure that out along developing the dataset. When there\u2019s an issue upstream of me, I have to go back to the source files and dig deep why something is missing. I have to wait on another engineer frequently in the process to either QA why something is missing or merge my pull requests which has frequent delays. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In between all of this work, I frequently get asked to make enhancements or fix bugs from previous work that can easily eat 1-3 days. Some of these bugs are random and occur because the source data upstream of me randomly changed that broke my entire process. Enhancements sound simple in theory until I actually work on it. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There\u2019s no standard QA process. I told my boss I wanted to develop scripts to do QA as frequently in the past if we had data issues, I would be notified by either my boss or a stakeholder because they happened to notice the issue. I figured if I run a daily script where I can get an automated email that shows all my datasets and what\u2019s going on, it can be easier to be proactive rather than reactive. My boss said that this is something another team is working on developing but there\u2019s no sign that there is such a thing being developed and developing a QA process for every individual project is entirely on me to figure out &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There\u2019s NO documentation. My team is trying to get better at this but all my projects have been a product of zero past documentation. In order to get better at this, I\u2019m expected to create documentation on top of all this work. Documentation can easily take me 1-2 days for each project and sometimes it gets pushed to the side because of focusing on 1-3.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Even documenting on Jira easily takes me 30 mins - 1 hour &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Add 3 hours of meeting a day on this already full plate &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Instead of 3 projects in 2 weeks, I feel if my focus was on just one project - from development, QA, documentation, it would be way more manageable. But there isn\u2019t really an option on my team as they\u2019re obsessed with scaling up, I\u2019m frequently told everything is a priority. My eating and sleeping schedule had gotten so messed up in the span of the past few months - I don\u2019t have time to make breakfast, lunch or dinner and end up skipping meals a lot. I wish to get a new job and would have easily started applying now if the economy wasn\u2019t so bad. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if others have experienced similar. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1oigf8k", "is_robot_indexable": true, "report_reasons": null, "author": "thro0away12", "discussion_type": null, "num_comments": 20, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oigf8k/burning_out_because_nothing_takes_as_short_as_the/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oigf8k/burning_out_because_nothing_takes_as_short_as_the/", "subreddit_subscribers": 2695443, "created_utc": 1761674097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1sc86i36d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bank of America: AI Is Powering Growth, But Not Killing Jobs (Yet)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1oicuu9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=140&amp;height=93&amp;auto=webp&amp;s=a80f7ef2e119a658df1361f6d1343d0030badcf5", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1761666226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/bank-of-america-ai-economy-job-impact", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?auto=webp&amp;s=294b12b7c217b6a4e2bcc6ff232253e4a5fa51bc", "width": 1620, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=433743c93aabc09ecb557bf532473f1bfa1cd1bc", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4838b60e1ae9f40dd67377221463162e4bd15cd3", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ecbbd2855ba8daa08202411f5cd117ae32f01c97", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a023bae1ae59555a4df7ec07ed01de6563ba040", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=adc282b31dd7264f6f0f9ca0f6b79d900b9a8cf8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b29bd87c30b74cbd77193cf71574ac298367b88", "width": 1080, "height": 720}], "variants": {}, "id": "w9ql8NGLPnc4cIkaDl6VregtjtVzeMdl_p3CQXLn66g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1oicuu9", "is_robot_indexable": true, "report_reasons": null, "author": "CryoSchema", "discussion_type": null, "num_comments": 14, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oicuu9/bank_of_america_ai_is_powering_growth_but_not/", "stickied": false, "url": "https://www.interviewquery.com/p/bank-of-america-ai-economy-job-impact", "subreddit_subscribers": 2695443, "created_utc": 1761666226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody, I just posted my first article on Medium and I would like some feeback (both positive and negative). Is it something that anyone would bother reading? Do you find it interesting as a light read?\n\n I really enjoy stats and writing so I wanted to merge them in some way.\n\nLink: [https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-\u03b1-0-05-4d5965762646](https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-\u03b1-0-05-4d5965762646)\n\nThanks in advance", "author_fullname": "t2_2opbolsh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Statistics blog/light read. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oirqlb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1761701415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody, I just posted my first article on Medium and I would like some feeback (both positive and negative). Is it something that anyone would bother reading? Do you find it interesting as a light read?&lt;/p&gt;\n\n&lt;p&gt;I really enjoy stats and writing so I wanted to merge them in some way.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-%CE%B1-0-05-4d5965762646\"&gt;https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-\u03b1-0-05-4d5965762646&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?auto=webp&amp;s=c25a7c7fe23edc1011cff6890f457fc650f3c45d", "width": 1200, "height": 788}, "resolutions": [{"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59ec29e644fe7a67047aa943710f6b9aa0d59f5a", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=41ddaf5748eef7c20402978b08dd7993365c952c", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=031f8077c3d556bdd26eba0d3da486bc9bc194ff", "width": 320, "height": 210}, {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62f5cb172099010342695ab259476622a959c62d", "width": 640, "height": 420}, {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=70af4e0ed780bb17a84a2ccbbe7a416455531a09", "width": 960, "height": 630}, {"url": "https://external-preview.redd.it/4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ff85dddeb24bdffb9456f0c7a7fcb74d107f6d80", "width": 1080, "height": 709}], "variants": {}, "id": "4_6kd9I6nhuTqKFtRcDrwqcpFu_HSNYAjm-uVq0HATE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1oirqlb", "is_robot_indexable": true, "report_reasons": null, "author": "ArugulaImpossible134", "discussion_type": null, "num_comments": 11, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oirqlb/statistics_bloglight_read_thoughts/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oirqlb/statistics_bloglight_read_thoughts/", "subreddit_subscribers": 2695443, "created_utc": 1761701415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "step 1: Have 3-5 years experience for L4 (No such thing as Junior DS at FAANG)\n\nstep 2: Don't not have 3-5 years experience\n\nstep 3: Get MSc in Stats/Comp sci./Physics/etc. (do not go for DS degree)\n\nstep 4: Look on career site for which locations they are hiring for DS, move or be ready to move there. Easier to get headcount in Big US offices, latin America, Eastern Europe, India\n\nstep 5: Look what kind of roles they are hiring for and what matches your skillset\n\nstep 6: Tailor your resume, create projects if you don't have experience, for the roles they are hiring for. DS means a lot of things, and big companies are looking for specialists not generalists. There's someone to do ops, someone to do cloud engineering, someone to do dashboards, etc.\n\nstep 7: Apply as much as you can, reach out and get referral from someone. Don't talk yourself out of applying\n\nstep 8: Study at a bare minimum 20-50 hours for each hour of interview. Make sure you study for topics relevant to the role (ex. if it's in product analytics you won't have to know much ML ops)\n\nstep 9: Interview well. You have to be perfect when it comes to the fundamentals. With an 8/10 performance you will either be rejected or request follow up interviews, anything below that doesn't cut it. Your english and fundamental technical skills must be perfect. Any signs of incompetence when it comes to the basics will be red flags. You must know 'why' not just the 'what'.", "author_fullname": "t2_ynk7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I would land FAANG DS in 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ojb3u5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761759518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;step 1: Have 3-5 years experience for L4 (No such thing as Junior DS at FAANG)&lt;/p&gt;\n\n&lt;p&gt;step 2: Don&amp;#39;t not have 3-5 years experience&lt;/p&gt;\n\n&lt;p&gt;step 3: Get MSc in Stats/Comp sci./Physics/etc. (do not go for DS degree)&lt;/p&gt;\n\n&lt;p&gt;step 4: Look on career site for which locations they are hiring for DS, move or be ready to move there. Easier to get headcount in Big US offices, latin America, Eastern Europe, India&lt;/p&gt;\n\n&lt;p&gt;step 5: Look what kind of roles they are hiring for and what matches your skillset&lt;/p&gt;\n\n&lt;p&gt;step 6: Tailor your resume, create projects if you don&amp;#39;t have experience, for the roles they are hiring for. DS means a lot of things, and big companies are looking for specialists not generalists. There&amp;#39;s someone to do ops, someone to do cloud engineering, someone to do dashboards, etc.&lt;/p&gt;\n\n&lt;p&gt;step 7: Apply as much as you can, reach out and get referral from someone. Don&amp;#39;t talk yourself out of applying&lt;/p&gt;\n\n&lt;p&gt;step 8: Study at a bare minimum 20-50 hours for each hour of interview. Make sure you study for topics relevant to the role (ex. if it&amp;#39;s in product analytics you won&amp;#39;t have to know much ML ops)&lt;/p&gt;\n\n&lt;p&gt;step 9: Interview well. You have to be perfect when it comes to the fundamentals. With an 8/10 performance you will either be rejected or request follow up interviews, anything below that doesn&amp;#39;t cut it. Your english and fundamental technical skills must be perfect. Any signs of incompetence when it comes to the basics will be red flags. You must know &amp;#39;why&amp;#39; not just the &amp;#39;what&amp;#39;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ojb3u5", "is_robot_indexable": true, "report_reasons": null, "author": "LeaguePrototype", "discussion_type": null, "num_comments": 15, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ojb3u5/how_i_would_land_faang_ds_in_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ojb3u5/how_i_would_land_faang_ds_in_2025/", "subreddit_subscribers": 2695443, "created_utc": 1761759518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nA little while back, I shared my curated list of data science resources here as a public GitHub repo. The feedback was really valuable.\n\nThanks for all the suggestions and feedback. Here's what was improved thanks to your ideas:\n\n* **Added new sections:** MLOps, AI Applications &amp; Platforms, and Cloud Platforms &amp; Infrastructure to make the list more comprehensive.\n* **Reworked the structure:** Split some bulky sections up. Hopefully now it's less overwhelming and easier to navigate.\n* **Packed more useful Python:** Added more useful Python libraries into each section to help find the right tool faster.\n* **Set up auto-checks**: Implemented an automatic check for broken links to keep the list fresh and reliable.\n\nA nice outcome: the list is now part of the main \"Awesome Data Science\" repository, which many of you probably know.\n\nIf you have more suggestions, I'd love to hear them in the comments. I'm especially curious if adding new subsections for Books or YouTube channels within existing chapters (alongside Resources and Tools) would be useful.\n\nThe list is here: [View on GitHub](https://github.com/PavelGrigoryevDS/awesome-data-analysis#readme)\n\nP.S. Thanks again. This whole process really showed me how powerful Reddit can be for getting real, expert feedback.", "author_fullname": "t2_1w40m9mrr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your feedback got my resource list added to the official \"awesome-datascience\" repo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oiaj5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1761660897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;A little while back, I shared my curated list of data science resources here as a public GitHub repo. The feedback was really valuable.&lt;/p&gt;\n\n&lt;p&gt;Thanks for all the suggestions and feedback. Here&amp;#39;s what was improved thanks to your ideas:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Added new sections:&lt;/strong&gt; MLOps, AI Applications &amp;amp; Platforms, and Cloud Platforms &amp;amp; Infrastructure to make the list more comprehensive.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reworked the structure:&lt;/strong&gt; Split some bulky sections up. Hopefully now it&amp;#39;s less overwhelming and easier to navigate.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Packed more useful Python:&lt;/strong&gt; Added more useful Python libraries into each section to help find the right tool faster.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Set up auto-checks&lt;/strong&gt;: Implemented an automatic check for broken links to keep the list fresh and reliable.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A nice outcome: the list is now part of the main &amp;quot;Awesome Data Science&amp;quot; repository, which many of you probably know.&lt;/p&gt;\n\n&lt;p&gt;If you have more suggestions, I&amp;#39;d love to hear them in the comments. I&amp;#39;m especially curious if adding new subsections for Books or YouTube channels within existing chapters (alongside Resources and Tools) would be useful.&lt;/p&gt;\n\n&lt;p&gt;The list is here: &lt;a href=\"https://github.com/PavelGrigoryevDS/awesome-data-analysis#readme\"&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;P.S. Thanks again. This whole process really showed me how powerful Reddit can be for getting real, expert feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?auto=webp&amp;s=01b8c851a85d9fa3a62f42825a7a92d8f3923f99", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa4bd8710c64c123305fbc04c38500d1fdc8e3d3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d60eeea109757e3effd455b79a2ff55e1f373fb7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=adfcc2940f6a3f651b0dbae951a89697a3a9b0e8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=835b8b0d4fd9434a38162cdc1915fb8bc3ceff8d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ecf07cdde4ddb60399bc8fd02abe565806d38f68", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=76331fbcb0d9c720fd3a89497c111b9b4077c205", "width": 1080, "height": 540}], "variants": {}, "id": "Cb-LZ_ttXp8tpZNBlTLddq5KUKV0xAthN3NmREWXRmA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1oiaj5d", "is_robot_indexable": true, "report_reasons": null, "author": "DeepAnalyze", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oiaj5d/your_feedback_got_my_resource_list_added_to_the/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oiaj5d/your_feedback_got_my_resource_list_added_to_the/", "subreddit_subscribers": 2695443, "created_utc": 1761660897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OK, I accept that this is the worst post title I've ever made...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ohflw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 356, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1fd2qzwbqh", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 356, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/6cr6eh8JbVrihjEpwGEyzbT-lkASpFmmLIlLHRmHKT8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AnalyticsMemes", "selftext": "", "author_fullname": "t2_1fd2qzwbqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sam Altman is Out, Meet Select All-man", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AnalyticsMemes", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ohfkrj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/6cr6eh8JbVrihjEpwGEyzbT-lkASpFmmLIlLHRmHKT8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1761574561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/v4tx388cxnxf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/v4tx388cxnxf1.png?auto=webp&amp;s=a4c262e425924b33c4acb1ccf5199b052095f08c", "width": 5456, "height": 6158}, "resolutions": [{"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e66ec013abdbc14244ea3f340455e766bb0f56c9", "width": 108, "height": 121}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=17e5490198456a37bdd7ab49fd22dff3f11d8795", "width": 216, "height": 243}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4ef0165a93aef933b5ef0e09548d6e68197bb6d", "width": 320, "height": 361}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=da5f1b99ad239fdcb222633e4679e4e3bd24734d", "width": 640, "height": 722}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ad42a5265937723f62ce83d6afa18fdc66a9351", "width": 960, "height": 1083}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02d702d879b336140bc383412a004a1137e2a019", "width": 1080, "height": 1218}], "variants": {}, "id": "tUbKviVn8HROyaeEZ9nWGQfGZdjaHbAE9jon1Mtwb4s"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_ezgh0k", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ohfkrj", "is_robot_indexable": true, "report_reasons": null, "author": "ElectrikMetriks", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AnalyticsMemes/comments/1ohfkrj/sam_altman_is_out_meet_select_allman/", "stickied": false, "url": "https://i.redd.it/v4tx388cxnxf1.png", "subreddit_subscribers": 938, "created_utc": 1761574561.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1761574635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/v4tx388cxnxf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/v4tx388cxnxf1.png?auto=webp&amp;s=a4c262e425924b33c4acb1ccf5199b052095f08c", "width": 5456, "height": 6158}, "resolutions": [{"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e66ec013abdbc14244ea3f340455e766bb0f56c9", "width": 108, "height": 121}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=17e5490198456a37bdd7ab49fd22dff3f11d8795", "width": 216, "height": 243}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4ef0165a93aef933b5ef0e09548d6e68197bb6d", "width": 320, "height": 361}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=da5f1b99ad239fdcb222633e4679e4e3bd24734d", "width": 640, "height": 722}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ad42a5265937723f62ce83d6afa18fdc66a9351", "width": 960, "height": 1083}, {"url": "https://preview.redd.it/v4tx388cxnxf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02d702d879b336140bc383412a004a1137e2a019", "width": 1080, "height": 1218}], "variants": {}, "id": "tUbKviVn8HROyaeEZ9nWGQfGZdjaHbAE9jon1Mtwb4s"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "1ohflw3", "is_robot_indexable": true, "report_reasons": null, "author": "ElectrikMetriks", "discussion_type": null, "num_comments": 12, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1ohfkrj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ohflw3/ok_i_accept_that_this_is_the_worst_post_title_ive/", "stickied": false, "url": "https://i.redd.it/v4tx388cxnxf1.png", "subreddit_subscribers": 2695443, "created_utc": 1761574635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My boss seems to think it should be fine, but there's variance in how many impressions each user has, so perhaps I'd need to compute the ICC (intraclass correlation) and use that to compute the design effect multiplier (DEFF=1+(m-1) x ICC)?\n\nIt also appears that a GLM with a Wald test would be a appropriate in this case, though I have little experience or exposure to these concepts. \n\nI'd appreciate any resources, advice, or pointers. Thank you so much for reading!", "author_fullname": "t2_4lr3dhfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For an A/B test where the user is the randomization unit and the primary metric is a ratio of total conversions over total impressions, is a standard two-proportion z-test fine to use for power analysis and testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ohsucs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761604654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss seems to think it should be fine, but there&amp;#39;s variance in how many impressions each user has, so perhaps I&amp;#39;d need to compute the ICC (intraclass correlation) and use that to compute the design effect multiplier (DEFF=1+(m-1) x ICC)?&lt;/p&gt;\n\n&lt;p&gt;It also appears that a GLM with a Wald test would be a appropriate in this case, though I have little experience or exposure to these concepts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any resources, advice, or pointers. Thank you so much for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "1ohsucs", "is_robot_indexable": true, "report_reasons": null, "author": "PathalogicalObject", "discussion_type": null, "num_comments": 13, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ohsucs/for_an_ab_test_where_the_user_is_the/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ohsucs/for_an_ab_test_where_the_user_is_the/", "subreddit_subscribers": 2695443, "created_utc": 1761604654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We just added an interactive Agent builder to [the GitHub project Kiln](https://github.com/Kiln-AI/Kiln). With it you can build agentic systems in under 10 minutes. You can do it all through our UI, or use our python library.\n\nWhat is it? Well \u201cagentic\u201d is just about the most overloaded term in AI, but Kiln supports everything you need to build agents:\n\n* [Tool Use](https://docs.kiln.tech/docs/agents#tool-use)\n* [Multi-Actor Interaction (aka subtasks)](https://docs.kiln.tech/docs/agents#multi-actor-interaction-aka-subtasks)\n* [Goal Directed, Autonomous Looping &amp; Reasoning](https://docs.kiln.tech/docs/agents#goal-directed-autonomy-and-reasoning)\n* [State &amp; Memory](https://docs.kiln.tech/docs/agents#state-and-memory)\n\n**Context Management with Subtasks (aka Multi-Actor Pattern)**\n\nContext management is the process of curating the model's context (chat/tool history) to ensure it has the right data, at the right time, in the right level of detail to get the job done.\n\nWith Kiln you can implement context management by dividing your agent tasks into subtasks, making context management easy. Each subtask can focus within its own context, then compress/summarize for the parent task. This can make the system faster, cheaper and higher quality. See our [docs on context management](https://docs.kiln.tech/docs/agents#context-management) for more details.\n\n**Eval &amp; Optimize Agent Performance**\n\nKiln agents work with [Kiln evals](https://docs.kiln.tech/docs/evaluations) so you can measure and improve agent performance:\n\n* Find the ideal model to use, balancing quality, cost and speed\n* Test different prompts\n* Evaluate end-to-end quality, or focus on the quality of subtasks\n* Compare different agent system designs: more/fewer subtasks\n\n**Links and Docs**\n\nSome links to the repo and guides:\n\n* [Kiln AI on Github - 4k stars](https://github.com/Kiln-AI/Kiln)\n* [Docs for Kiln Agents](https://docs.kiln.tech/docs/agents)\n* [Kiln Discord](https://getkiln.ai/discord)\n* [Homepage](https://kiln.tech/)\n\nFeedback and suggestions are very welcome! We\u2019re already working on custom evals to inspect the trace, and make sure the right tools are used at the right times. What else would be helpful? Any other agent memory patterns you\u2019d want to see?", "author_fullname": "t2_slbscky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kiln Agent Builder (new): Build agentic systems in minutes with tools, sub-agents, RAG, and context management [Kiln]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "name": "t3_1ohp04q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/G4irRjtci1UbxwU1TIaztOoYN5UvDZhl4f-2bCHUbIw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1761595626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We just added an interactive Agent builder to &lt;a href=\"https://github.com/Kiln-AI/Kiln\"&gt;the GitHub project Kiln&lt;/a&gt;. With it you can build agentic systems in under 10 minutes. You can do it all through our UI, or use our python library.&lt;/p&gt;\n\n&lt;p&gt;What is it? Well \u201cagentic\u201d is just about the most overloaded term in AI, but Kiln supports everything you need to build agents:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/agents#tool-use\"&gt;Tool Use&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/agents#multi-actor-interaction-aka-subtasks\"&gt;Multi-Actor Interaction (aka subtasks)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/agents#goal-directed-autonomy-and-reasoning\"&gt;Goal Directed, Autonomous Looping &amp;amp; Reasoning&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/agents#state-and-memory\"&gt;State &amp;amp; Memory&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Context Management with Subtasks (aka Multi-Actor Pattern)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Context management is the process of curating the model&amp;#39;s context (chat/tool history) to ensure it has the right data, at the right time, in the right level of detail to get the job done.&lt;/p&gt;\n\n&lt;p&gt;With Kiln you can implement context management by dividing your agent tasks into subtasks, making context management easy. Each subtask can focus within its own context, then compress/summarize for the parent task. This can make the system faster, cheaper and higher quality. See our &lt;a href=\"https://docs.kiln.tech/docs/agents#context-management\"&gt;docs on context management&lt;/a&gt; for more details.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Eval &amp;amp; Optimize Agent Performance&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Kiln agents work with &lt;a href=\"https://docs.kiln.tech/docs/evaluations\"&gt;Kiln evals&lt;/a&gt; so you can measure and improve agent performance:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Find the ideal model to use, balancing quality, cost and speed&lt;/li&gt;\n&lt;li&gt;Test different prompts&lt;/li&gt;\n&lt;li&gt;Evaluate end-to-end quality, or focus on the quality of subtasks&lt;/li&gt;\n&lt;li&gt;Compare different agent system designs: more/fewer subtasks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Links and Docs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Some links to the repo and guides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/Kiln-AI/Kiln\"&gt;Kiln AI on Github - 4k stars&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/agents\"&gt;Docs for Kiln Agents&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://getkiln.ai/discord\"&gt;Kiln Discord&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://kiln.tech/\"&gt;Homepage&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Feedback and suggestions are very welcome! We\u2019re already working on custom evals to inspect the trace, and make sure the right tools are used at the right times. What else would be helpful? Any other agent memory patterns you\u2019d want to see?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mn63lbh3opxf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mn63lbh3opxf1.png?auto=webp&amp;s=5a8105cae5fccf22f65721be4a52a7cc21efd094", "width": 2748, "height": 1404}, "resolutions": [{"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0edd90974e8c6bd435022c7900fbd0ae7761dd14", "width": 108, "height": 55}, {"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36e6079140570bdd609371a39df406b49d44fef9", "width": 216, "height": 110}, {"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ea8047889f2d05e718a7256da62060c537c0c77", "width": 320, "height": 163}, {"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=05d5962d819fc6cbbc2eb9abf30609ba8aae7e3c", "width": 640, "height": 326}, {"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4831a5b6dd87b14c75cec5634a45cb5ae5f9ae27", "width": 960, "height": 490}, {"url": "https://preview.redd.it/mn63lbh3opxf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de9ca6b5bf7ca307dc56ba977737dcca58b4aae4", "width": 1080, "height": 551}], "variants": {}, "id": "G2o22uDgdCSvRzSEZVqV3gD9oUMoxueynPM7rchaNiA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ohp04q", "is_robot_indexable": true, "report_reasons": null, "author": "davernow", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ohp04q/kiln_agent_builder_new_build_agentic_systems_in/", "stickied": false, "url": "https://i.redd.it/mn63lbh3opxf1.png", "subreddit_subscribers": 2695443, "created_utc": 1761595626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The book is now available to read online for free: https://deeplearningwithpython.io/chapters/", "author_fullname": "t2_y6wjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone looking to read the third edition of Deep Learning With Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ogwru2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 97, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 97, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1761514766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The book is now available to read online for free: &lt;a href=\"https://deeplearningwithpython.io/chapters/\"&gt;https://deeplearningwithpython.io/chapters/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?auto=webp&amp;s=46dcc1b20ee2a1499ab67dc8efaaf4473e43c707", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a58e27c19d32c77a7763bcd3d1ea97412553acb6", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4482ef82c7fb94b22bc4b45234c9adc9dfc3bd5b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ef2afb44aae6aeef9a558b0cabaac189342d58d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38d3936d6f181687048fa7f635a195e0c72ff06a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=15af03241be9782163c1f6e212cca470ff548312", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=db60d79009634a7ebeec4f1ec7f28eabfe922548", "width": 1080, "height": 567}], "variants": {}, "id": "sT9XGRQPwkYGiNrSL0qWOlkUmwhTBkxwMUSMZCvpL3M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1ogwru2", "is_robot_indexable": true, "report_reasons": null, "author": "yaymayhun", "discussion_type": null, "num_comments": 11, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ogwru2/anyone_looking_to_read_the_third_edition_of_deep/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ogwru2/anyone_looking_to_read_the_third_edition_of_deep/", "subreddit_subscribers": 2695443, "created_utc": 1761514766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How to get hired as a Data Scientist/ Analyst (5yr exp) from France in USA? Is it better if I switch to CS because it is more in demand? thanks", "author_fullname": "t2_bpcrc4t2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get hired in USA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ohw7zt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761613538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to get hired as a Data Scientist/ Analyst (5yr exp) from France in USA? Is it better if I switch to CS because it is more in demand? thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ohw7zt", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Duty961", "discussion_type": null, "num_comments": 26, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ohw7zt/how_to_get_hired_in_usa/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ohw7zt/how_to_get_hired_in_usa/", "subreddit_subscribers": 2695443, "created_utc": 1761613538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you think you're part of this new phenomenon called The Great Stay?", "author_fullname": "t2_1vfpsu4wck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Great Stay \u2014 Here\u2019s the New Reality for Tech Workers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1of2sfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=140&amp;height=93&amp;auto=webp&amp;s=2211124deade7b77b9216a2a4a358242653584d6", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1761324293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you think you&amp;#39;re part of this new phenomenon called The Great Stay?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/the-great-stay-tech-workers-ai-fear", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?auto=webp&amp;s=4b280add43a848a8bf9ecc1c532fc7197d8b98c3", "width": 6720, "height": 4480}, "resolutions": [{"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c2ef4ad62d4fea459674c6dc17669232db4654c", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e77fdf10bbba6edcfa8ae6fcb1c985e5c1aa9646", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f527efce6806283e5730f0b2338911ae816a07c1", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c6aea5cf415da0068a3771dcf25eb2c143e4a8fd", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0145c05ca94c5e68480aab27ac0dfd4cbc5abab9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=86793e718debbefce87ab828ffdbd97b3b75a000", "width": 1080, "height": 720}], "variants": {}, "id": "puOTMBmuwNfb7u2FIvoKe24q57re5O1SvPeiFblLCqc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1of2sfs", "is_robot_indexable": true, "report_reasons": null, "author": "KitchenTaste7229", "discussion_type": null, "num_comments": 30, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1of2sfs/the_great_stay_heres_the_new_reality_for_tech/", "stickied": false, "url": "https://www.interviewquery.com/p/the-great-stay-tech-workers-ai-fear", "subreddit_subscribers": 2695443, "created_utc": 1761324293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any other free options that are similar to ShotBot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1oehj29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_f557bybc", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Good Shooting Day - Basketball AI Shot Detection- ShotBot", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "author_name": "ExcelVault", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/H3nGXVSQww8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ExcelVault"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1oehj29", "height": 200}, "link_flair_text": "Tools", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=140&amp;height=105&amp;auto=webp&amp;s=cc7c78d3f5b5575ae01714d5d7248b69398c0074", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "sportsanalytics", "selftext": "In my experience with ShotBot the Distance and location are off but makes, misses, and total shots are accurate. Any better options?\n\nSee YouTube video https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD", "author_fullname": "t2_f557bybc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any other free options that are similar to ShotBot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/sportsanalytics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1oehhdg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Good Shooting Day - Basketball AI Shot Detection- ShotBot", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "author_name": "ExcelVault", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/H3nGXVSQww8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ExcelVault"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1oehhdg", "height": 200}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "image", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "created": 1761259288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my experience with ShotBot the Distance and location are off but makes, misses, and total shots are accurate. Any better options?&lt;/p&gt;\n\n&lt;p&gt;See YouTube video &lt;a href=\"https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD\"&gt;https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?auto=webp&amp;s=79524b7177894ab9008653f74b0667365dc7fda3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe466c720e86e0fb98cdab682b84151a210395ee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5c28cdc992bdc54c2094998e9e18356360054c3c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc7acf5faf88c3b079812a6705c30620a003c025", "width": 320, "height": 240}], "variants": {}, "id": "6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sb27", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1oehhdg", "is_robot_indexable": true, "report_reasons": null, "author": "Party_Bus_3809", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/sportsanalytics/comments/1oehhdg/any_other_free_options_that_are_similar_to_shotbot/", "stickied": false, "url": "https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD", "subreddit_subscribers": 14957, "created_utc": 1761259288.0, "num_crossposts": 4, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Good Shooting Day - Basketball AI Shot Detection- ShotBot", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "author_name": "ExcelVault", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/H3nGXVSQww8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ExcelVault"}}, "is_video": false}], "created": 1761259418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?auto=webp&amp;s=79524b7177894ab9008653f74b0667365dc7fda3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe466c720e86e0fb98cdab682b84151a210395ee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5c28cdc992bdc54c2094998e9e18356360054c3c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc7acf5faf88c3b079812a6705c30620a003c025", "width": 320, "height": 240}], "variants": {}, "id": "6vFIdMywBTRIKSG8kEsE9d7VGFIbNVIdknQ0NEEymps"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1oehj29", "is_robot_indexable": true, "report_reasons": null, "author": "Party_Bus_3809", "discussion_type": null, "num_comments": 8, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1oehhdg", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oehj29/any_other_free_options_that_are_similar_to_shotbot/", "stickied": false, "url": "https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD", "subreddit_subscribers": 2695443, "created_utc": 1761259418.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Good Shooting Day - Basketball AI Shot Detection- ShotBot", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/H3nGXVSQww8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Good Shooting Day - Basketball AI Shot Detection- ShotBot\"&gt;&lt;/iframe&gt;", "author_name": "ExcelVault", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/H3nGXVSQww8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ExcelVault"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks,\nHope you\u2019re having a great day wherever you are in the world.\n\nContext:\nI\u2019ve been in the data science industry for the past 11 years. I started my career in telecom, where I worked extensively on time series analysis and data cleaning using R, Java, and Pig.\n\nAfter about two years, I landed my first \u201cdata scientist\u201d role in a bank, and I\u2019ve been in the financial sector ever since. Over time, I picked up Python, Spark, and TensorFlow to build ML models for marketing analytics and recommendation systems. It was a really fun period \u2014 the industry wasn\u2019t as mature back then. I used to get ridiculously excited whenever new boosting algorithms came out (think XGBoost, CatBoost, LightGBM) and spent hours experimenting with ensemble techniques to squeeze out higher uplift.\n\nI also did quite a bit of statistical A/B testing \u2014 not just basic t-tests, but full experiment design with power analysis, control-treatment stratification, and post-hoc validation to account for selection bias and seasonality effects. I enjoyed quantifying incremental lift properly, whether through classical hypothesis testing or uplift modeling frameworks, and working with business teams to translate those metrics into campaign ROI or customer conversion outcomes.\n\nFast forward to today \u2014 I\u2019ve been at my current company for about two years. Every department now wants to apply Gen AI (and even \u201cagentic AI\u201d) even though we haven\u2019t truly tested or measured many real-world efficiency gains yet. I spend most of my time in meetings listening to people talk all day about AI. Then I head back to my table to do prompt engineering, data cleaning, testing, and evaluation. Honestly, it feels off-putting that even my business stakeholders can now write decent prompts. I don\u2019t feel like I\u2019m contributing much anymore. Sure, the surrounding processes are important \u2014 but they\u2019ve become mundane, repetitive busywork.\n\nI\u2019m feeling understimulated intellectually and overstimulated by meetings, requests, and routine tasks.\nAnyone else in the same boat? Does this feel like the end of a data science journey? Am I far too gone? It\u2019s been 11 years for me, and lately, I\u2019ve been seriously considering moving into education \u2014 somewhere I might actually feel like I\u2019m contributing again.", "author_fullname": "t2_pnx7y1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s next for a 11 YOE data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1od5zca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 241, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 241, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761133551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,\nHope you\u2019re having a great day wherever you are in the world.&lt;/p&gt;\n\n&lt;p&gt;Context:\nI\u2019ve been in the data science industry for the past 11 years. I started my career in telecom, where I worked extensively on time series analysis and data cleaning using R, Java, and Pig.&lt;/p&gt;\n\n&lt;p&gt;After about two years, I landed my first \u201cdata scientist\u201d role in a bank, and I\u2019ve been in the financial sector ever since. Over time, I picked up Python, Spark, and TensorFlow to build ML models for marketing analytics and recommendation systems. It was a really fun period \u2014 the industry wasn\u2019t as mature back then. I used to get ridiculously excited whenever new boosting algorithms came out (think XGBoost, CatBoost, LightGBM) and spent hours experimenting with ensemble techniques to squeeze out higher uplift.&lt;/p&gt;\n\n&lt;p&gt;I also did quite a bit of statistical A/B testing \u2014 not just basic t-tests, but full experiment design with power analysis, control-treatment stratification, and post-hoc validation to account for selection bias and seasonality effects. I enjoyed quantifying incremental lift properly, whether through classical hypothesis testing or uplift modeling frameworks, and working with business teams to translate those metrics into campaign ROI or customer conversion outcomes.&lt;/p&gt;\n\n&lt;p&gt;Fast forward to today \u2014 I\u2019ve been at my current company for about two years. Every department now wants to apply Gen AI (and even \u201cagentic AI\u201d) even though we haven\u2019t truly tested or measured many real-world efficiency gains yet. I spend most of my time in meetings listening to people talk all day about AI. Then I head back to my table to do prompt engineering, data cleaning, testing, and evaluation. Honestly, it feels off-putting that even my business stakeholders can now write decent prompts. I don\u2019t feel like I\u2019m contributing much anymore. Sure, the surrounding processes are important \u2014 but they\u2019ve become mundane, repetitive busywork.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m feeling understimulated intellectually and overstimulated by meetings, requests, and routine tasks.\nAnyone else in the same boat? Does this feel like the end of a data science journey? Am I far too gone? It\u2019s been 11 years for me, and lately, I\u2019ve been seriously considering moving into education \u2014 somewhere I might actually feel like I\u2019m contributing again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1od5zca", "is_robot_indexable": true, "report_reasons": null, "author": "appleciderv", "discussion_type": null, "num_comments": 86, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1od5zca/whats_next_for_a_11_yoe_data_scientist/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1od5zca/whats_next_for_a_11_yoe_data_scientist/", "subreddit_subscribers": 2695443, "created_utc": 1761133551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm creating a table for managing custoemrs between different locations and uniting their profiles at various outlets for an employer.  I've been doing more modelling in my career than ETL stuff.  I know SQL pretty well but I'm struggling a bit to set up the DBT table in a way where it can both update daily AND maintain stable IDs.  It overrights them.  We can set up github actions but I'm not really sure what would be the appropriate way to solve this issue.", "author_fullname": "t2_9bow4eln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create stable IDs in DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ode6j8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761152941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m creating a table for managing custoemrs between different locations and uniting their profiles at various outlets for an employer.  I&amp;#39;ve been doing more modelling in my career than ETL stuff.  I know SQL pretty well but I&amp;#39;m struggling a bit to set up the DBT table in a way where it can both update daily AND maintain stable IDs.  It overrights them.  We can set up github actions but I&amp;#39;m not really sure what would be the appropriate way to solve this issue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ode6j8", "is_robot_indexable": true, "report_reasons": null, "author": "Unhappy_Technician68", "discussion_type": null, "num_comments": 5, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ode6j8/create_stable_ids_in_dbt/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ode6j8/create_stable_ids_in_dbt/", "subreddit_subscribers": 2695443, "created_utc": 1761152941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After a few months of work, we\u2019re excited to launch [Erdos](https://www.lotas.ai/erdos) \\- a secure, AI-powered data science IDE, all open source! Some reasons you might use it over VS Code:\n\n* An AI that searches, reads, and writes all common data science file formats, with special optimizations for editing Jupyter notebooks\n* Built-in Python, R, and Julia consoles accessible to the user and AI\n* Single-click sign in to a secure, zero data retention backend; or users can bring their own keys\n* Plots pane with plots history organized by file and time\n* Help pane for Python, R, and Julia documentation\n* Database pane for connecting to SQL and FTP databases and manipulating data\n* Environment pane for managing in-memory variables, python environments, and Python, R, and Julia packages\n* Open source with AGPLv3 license\n\nUnlike other AI IDEs built for software development, Erdos is built specifically for data scientists based on what we as data scientists wanted. We'd love if you try it out at [https://www.lotas.ai/erdos](https://www.lotas.ai/erdos)", "author_fullname": "t2_1t7gevrmdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Erdos: open-source IDE for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_1ocenxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 308, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 308, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V5_JX23YsURcKDZBRqZiSDSDSL5sUSJUHqOVlxjXa9Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1761057368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a few months of work, we\u2019re excited to launch &lt;a href=\"https://www.lotas.ai/erdos\"&gt;Erdos&lt;/a&gt; - a secure, AI-powered data science IDE, all open source! Some reasons you might use it over VS Code:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An AI that searches, reads, and writes all common data science file formats, with special optimizations for editing Jupyter notebooks&lt;/li&gt;\n&lt;li&gt;Built-in Python, R, and Julia consoles accessible to the user and AI&lt;/li&gt;\n&lt;li&gt;Single-click sign in to a secure, zero data retention backend; or users can bring their own keys&lt;/li&gt;\n&lt;li&gt;Plots pane with plots history organized by file and time&lt;/li&gt;\n&lt;li&gt;Help pane for Python, R, and Julia documentation&lt;/li&gt;\n&lt;li&gt;Database pane for connecting to SQL and FTP databases and manipulating data&lt;/li&gt;\n&lt;li&gt;Environment pane for managing in-memory variables, python environments, and Python, R, and Julia packages&lt;/li&gt;\n&lt;li&gt;Open source with AGPLv3 license&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Unlike other AI IDEs built for software development, Erdos is built specifically for data scientists based on what we as data scientists wanted. We&amp;#39;d love if you try it out at &lt;a href=\"https://www.lotas.ai/erdos\"&gt;https://www.lotas.ai/erdos&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0m7tebv67hwf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0m7tebv67hwf1.png?auto=webp&amp;s=e44d0633284af672acae88cc20740743f6d17f49", "width": 2880, "height": 1754}, "resolutions": [{"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=312e161a5db0b0513a13fb07c2e0ecd702815c72", "width": 108, "height": 65}, {"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=64780796e0e452639479d52afd6c88b7a9df48e2", "width": 216, "height": 131}, {"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cddcf236997e2f651cf7b193f6cf30a1cf096b15", "width": 320, "height": 194}, {"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9da6ef662a993c41a394541222716b96f70ffb87", "width": 640, "height": 389}, {"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b8992adc34b3128061a45d2f027a95f05c3fa713", "width": 960, "height": 584}, {"url": "https://preview.redd.it/0m7tebv67hwf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3ce5ff69a2bc3909073dcf796654d2d8da8c3bc5", "width": 1080, "height": 657}], "variants": {}, "id": "gh6u-FeI2W-acbopZ3Wo9v7LxEdghcKmJpLRLRSm80Y"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1ocenxj", "is_robot_indexable": true, "report_reasons": null, "author": "SigSeq", "discussion_type": null, "num_comments": 67, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ocenxj/erdos_opensource_ide_for_data_science/", "stickied": false, "url": "https://i.redd.it/0m7tebv67hwf1.png", "subreddit_subscribers": 2695443, "created_utc": 1761057368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1rer4n1ivg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meet the New Buzzword Behind Every Tech Layoff \u2014 From Salesforce to Meta", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1ocgpac", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=140&amp;height=93&amp;auto=webp&amp;s=54c6e4df3b4dc5907a2f2c9aee8c9e10b12bfba0", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1761062064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/ai-layoffs-buzzword-tech-industry", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?auto=webp&amp;s=1c7135a05de46ee8ec12d9c5d2ced94007b2366d", "width": 5536, "height": 3691}, "resolutions": [{"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a18bb0e37d19182747a50afe0c991bc1735ccdf8", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=992996c87ab332c154ea17cd5f249e5298bbe889", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=88bfafd2106be75154980f93144786c04cb16b31", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d07545017ec3c363da652834bdd05c9c7e637a79", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6a96a224461b9fff6e8eb62617a814525d63372", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d54d0333238c888edc4a9a64cb6e07d9dca746e7", "width": 1080, "height": 720}], "variants": {}, "id": "o_q4_GVHuMEz9h-qe3wB4Yhz3ZMypmn8qxKia5Maggg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ocgpac", "is_robot_indexable": true, "report_reasons": null, "author": "nullstillstands", "discussion_type": null, "num_comments": 10, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ocgpac/meet_the_new_buzzword_behind_every_tech_layoff/", "stickied": false, "url": "https://www.interviewquery.com/p/ai-layoffs-buzzword-tech-industry", "subreddit_subscribers": 2695443, "created_utc": 1761062064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I currently work as a data scientist at a large U.S. bank, making around $182K. The compensation is solid, but I\u2019m starting to feel like my technical growth is being stunted.\n\nA lot of our codebase is still in SAS (which I struggle to use), though we\u2019re slowly transitioning to Python. We don\u2019t use version control, LLMs, NLP, or APIs \u2014 most of the work is done in Jupyter notebooks. The modeling is limited to logistic and linear regressions, and collaboration happens mostly through email or shared notebook links.\n\nI\u2019m concerned that staying here long-term will limit my exposure to more modern tools, frameworks, and practices \u2014 and that this could hurt my job prospects down the road.\n\nWhat would you recommend I focus on learning in my free time to stay competitive and become a stronger candidate for more technically advanced data science roles?\n\n", "author_fullname": "t2_bi7z2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling like I\u2019m falling behind on industry standards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1obvzq9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 248, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 248, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760999551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as a data scientist at a large U.S. bank, making around $182K. The compensation is solid, but I\u2019m starting to feel like my technical growth is being stunted.&lt;/p&gt;\n\n&lt;p&gt;A lot of our codebase is still in SAS (which I struggle to use), though we\u2019re slowly transitioning to Python. We don\u2019t use version control, LLMs, NLP, or APIs \u2014 most of the work is done in Jupyter notebooks. The modeling is limited to logistic and linear regressions, and collaboration happens mostly through email or shared notebook links.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned that staying here long-term will limit my exposure to more modern tools, frameworks, and practices \u2014 and that this could hurt my job prospects down the road.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend I focus on learning in my free time to stay competitive and become a stronger candidate for more technically advanced data science roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1obvzq9", "is_robot_indexable": true, "report_reasons": null, "author": "xCrek", "discussion_type": null, "num_comments": 81, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1obvzq9/feeling_like_im_falling_behind_on_industry/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1obvzq9/feeling_like_im_falling_behind_on_industry/", "subreddit_subscribers": 2695443, "created_utc": 1760999551.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1fd2qzwbqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many peoples' days were upset by this today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1obr0ve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 381, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 381, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EoD8kNnNIK3zpYFlWbSu6Rms1ldI-7Y95Hg9Pc9ztDA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1760988178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0fi89gqthbwf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0fi89gqthbwf1.png?auto=webp&amp;s=602ae8754d127d8052eda03d8c06d7e6d440658c", "width": 461, "height": 512}, "resolutions": [{"url": "https://preview.redd.it/0fi89gqthbwf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1471a0ceeba174b7d752e14caac75e7de4f7707", "width": 108, "height": 119}, {"url": "https://preview.redd.it/0fi89gqthbwf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e146ba73e8a039cba65051e438f232dfe8aa3128", "width": 216, "height": 239}, {"url": "https://preview.redd.it/0fi89gqthbwf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=144786dfa2710d99a3101064eb34bc0fc65a69ce", "width": 320, "height": 355}], "variants": {}, "id": "Z1FYP7kwtB8_uvQmpqp4AHeq0Ctn2f23StQWkogoXWs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "1obr0ve", "is_robot_indexable": true, "report_reasons": null, "author": "ElectrikMetriks", "discussion_type": null, "num_comments": 26, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1obr0ve/how_many_peoples_days_were_upset_by_this_today/", "stickied": false, "url": "https://i.redd.it/0fi89gqthbwf1.png", "subreddit_subscribers": 2695443, "created_utc": 1760988178.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hoping to compile a list of resources / communities that are specifically geared towards training large neural networks. Discussions / details around architecture, embedding strategies, optimization, etc are along the lines of what I\u2019m looking for. ", "author_fullname": "t2_gj1m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Communities / forums / resources for building neural networks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1obn0tc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760977777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping to compile a list of resources / communities that are specifically geared towards training large neural networks. Discussions / details around architecture, embedding strategies, optimization, etc are along the lines of what I\u2019m looking for. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1obn0tc", "is_robot_indexable": true, "report_reasons": null, "author": "JimBeanery", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1obn0tc/communities_forums_resources_for_building_neural/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1obn0tc/communities_forums_resources_for_building_neural/", "subreddit_subscribers": 2695443, "created_utc": 1760977777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 20 Oct, 2025 - 27 Oct, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oba336", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760932906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1oba336", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 21, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oba336/weekly_entering_transitioning_thread_20_oct_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oba336/weekly_entering_transitioning_thread_20_oct_2025/", "subreddit_subscribers": 2695443, "created_utc": 1760932906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks!\n\nLet's talk about Awesome lists (curated collections of resources and tools) and what's happening to them now with  LLMs like ChatGPT and Claude around.\n\nI'm constantly impressed by how quickly LLMs can generate answers and surface obscure tools, but I also deeply respect the human-curated, battle-tested reliability of a good Awesome list. Let me be clear: I'm not saying they're obsolete. I genuinely value the curation and reliability they offer, which LLMs often lack.\n\nSo, I'm genuinely curious about the community's take on this.\n\n* In the era of LLMs, are traditional Awesome lists becoming less critical, or do they hold a new kind of value?\n* Do you still actually browse them to discover new stuff, or do you mostly rely on LLMs now?\n* How good are LLMs really when you don\u2019t exactly know what you\u2019re looking for? Are you happy with what they recommend?\n* What's your biggest frustration or limitation with traditional Awesome lists?", "author_fullname": "t2_1w40m9mrr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do we still need Awesome lists now that we have LLMs like ChatGPT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oc8xij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1761047143.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1761041110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks!&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s talk about Awesome lists (curated collections of resources and tools) and what&amp;#39;s happening to them now with  LLMs like ChatGPT and Claude around.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m constantly impressed by how quickly LLMs can generate answers and surface obscure tools, but I also deeply respect the human-curated, battle-tested reliability of a good Awesome list. Let me be clear: I&amp;#39;m not saying they&amp;#39;re obsolete. I genuinely value the curation and reliability they offer, which LLMs often lack.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m genuinely curious about the community&amp;#39;s take on this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In the era of LLMs, are traditional Awesome lists becoming less critical, or do they hold a new kind of value?&lt;/li&gt;\n&lt;li&gt;Do you still actually browse them to discover new stuff, or do you mostly rely on LLMs now?&lt;/li&gt;\n&lt;li&gt;How good are LLMs really when you don\u2019t exactly know what you\u2019re looking for? Are you happy with what they recommend?&lt;/li&gt;\n&lt;li&gt;What&amp;#39;s your biggest frustration or limitation with traditional Awesome lists?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1oc8xij", "is_robot_indexable": true, "report_reasons": null, "author": "DeepAnalyze", "discussion_type": null, "num_comments": 17, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oc8xij/do_we_still_need_awesome_lists_now_that_we_have/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oc8xij/do_we_still_need_awesome_lists_now_that_we_have/", "subreddit_subscribers": 2695443, "created_utc": 1761041110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nHi\nI have never done Synthetic control, i want to work on a small project (like small data. My task is to find incremental effect), i have a few treatment units, have multiple units as a control (which includes some as major/anchor markets).\n\nSo questions are below:\n\n1. I know basic understanding of SCM but never used it, i know you get to optimize control units for a single treatment unit, but how do you perform the test when you have multiple treatments units? Do you build synthetic for each units? \nIf yes, do you use all control units for each treatment units? Then that means hace to do same steps multiple times? \n\n2. How do you use anchor markets? Like do you give them more weights from initial or do we need to do something about their data before doing the performance? \n\n3. How do you do placebo tests? Do we take a control unit then find synthetic control units? And in this synthetic do we include treatment units as well (I assume no, but still wanted to confirm) \n\n4. Lets say we want to check incremental for x metrics, do we do the whole process x times differently for each metric? Or once we have done it for one metric we can use the same synthetics for other metrics? \n(Lets say basic metrics like revenue, conversion, ctr) \n\n5. Which python package do we use  if there is resource on it would be great\n\n\n6. Am i missing any steps or things you believe i should be keep  in mind? \n\nThanks! Would be great help \n", "author_fullname": "t2_5bsp2h4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to perform synthetic control for multiple treated units? What are the things to keep in mind while performing it? Also, what python package i could use? Also have questions about metrics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1obad7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760933823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\nI have never done Synthetic control, i want to work on a small project (like small data. My task is to find incremental effect), i have a few treatment units, have multiple units as a control (which includes some as major/anchor markets).&lt;/p&gt;\n\n&lt;p&gt;So questions are below:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I know basic understanding of SCM but never used it, i know you get to optimize control units for a single treatment unit, but how do you perform the test when you have multiple treatments units? Do you build synthetic for each units? \nIf yes, do you use all control units for each treatment units? Then that means hace to do same steps multiple times? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you use anchor markets? Like do you give them more weights from initial or do we need to do something about their data before doing the performance? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you do placebo tests? Do we take a control unit then find synthetic control units? And in this synthetic do we include treatment units as well (I assume no, but still wanted to confirm) &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Lets say we want to check incremental for x metrics, do we do the whole process x times differently for each metric? Or once we have done it for one metric we can use the same synthetics for other metrics? \n(Lets say basic metrics like revenue, conversion, ctr) &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Which python package do we use  if there is resource on it would be great&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Am i missing any steps or things you believe i should be keep  in mind? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks! Would be great help &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1obad7k", "is_robot_indexable": true, "report_reasons": null, "author": "Starktony11", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1obad7k/how_to_perform_synthetic_control_for_multiple/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1obad7k/how_to_perform_synthetic_control_for_multiple/", "subreddit_subscribers": 2695443, "created_utc": 1760933823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a complex relationship with LLMs. At work, I'm told they're the best thing since the invention of the internet, electricity, or \\[insert other trite comparison here\\], and that I'll lose my job to people who do use them if I won't (I know I won't lose my job). Yes, standard \"there are some amazing use cases, like the breast cancer imaging diagnostics\" applies, and I think it's good for those like senior leaders where \"close enough\" is all they need. Yet, on the front line in a regulated industry where \"close enough\" doesn't cut it,  what I see on a daily basis are models that:\n\n(a) can't be trained on our data for legal and regulatory reasons and so have little to no context with which to help me in my role. Even if they could be trained on our company's data, most of the documentation - if it even exists to begin with - is wrong and out of date.\n\n(b) are suddenly getting worse (looking at you, Claude) at coding help, largely failing at context memory in things as basic as a SQL script - it will make up the names to tables and fields that have clearly, explicitly been written out just a few lines before. Yes they can help create frameworks that I can then patch up, but I do notice degradation in performance.\n\n(c) always manage to get \\*something\\* wrong, making my job part LLM babysitter. For example, my boss will use Teams transcribe for our 1:1s and sends me the AI recap after. I have to sift through because it always creates action items that were never discussed, or quotes me saying things that were never said in the meeting by anyone. One time, it just used a completely different name for me throughout the recap.\n\nHaving seen how the proverbial sausage is made, I have no desire to use it in my personal life, because why would I use it for anything with any actual stakes? And for the remainder, Google gets me by just fine for things like \"Who played the Sheriff in Blazing Saddles?\"\n\nAnyone else feel this way, or have a weird relationship with the technology that is, for better or worse, \"transforming\" our field?\n\nUpdate: some folks are leaving short, one sentence responses to the effect of \"They've only been great for me.\" Good! Tell us more about how you're finding success in your applications. any frustrations along the way? let's have a CONVERSATION. ", "author_fullname": "t2_15h4ul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else tired of the non-stop LLM hype in personal and/or professional life?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oa93fw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 516, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 516, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1760842024.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760825800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a complex relationship with LLMs. At work, I&amp;#39;m told they&amp;#39;re the best thing since the invention of the internet, electricity, or [insert other trite comparison here], and that I&amp;#39;ll lose my job to people who do use them if I won&amp;#39;t (I know I won&amp;#39;t lose my job). Yes, standard &amp;quot;there are some amazing use cases, like the breast cancer imaging diagnostics&amp;quot; applies, and I think it&amp;#39;s good for those like senior leaders where &amp;quot;close enough&amp;quot; is all they need. Yet, on the front line in a regulated industry where &amp;quot;close enough&amp;quot; doesn&amp;#39;t cut it,  what I see on a daily basis are models that:&lt;/p&gt;\n\n&lt;p&gt;(a) can&amp;#39;t be trained on our data for legal and regulatory reasons and so have little to no context with which to help me in my role. Even if they could be trained on our company&amp;#39;s data, most of the documentation - if it even exists to begin with - is wrong and out of date.&lt;/p&gt;\n\n&lt;p&gt;(b) are suddenly getting worse (looking at you, Claude) at coding help, largely failing at context memory in things as basic as a SQL script - it will make up the names to tables and fields that have clearly, explicitly been written out just a few lines before. Yes they can help create frameworks that I can then patch up, but I do notice degradation in performance.&lt;/p&gt;\n\n&lt;p&gt;(c) always manage to get *something* wrong, making my job part LLM babysitter. For example, my boss will use Teams transcribe for our 1:1s and sends me the AI recap after. I have to sift through because it always creates action items that were never discussed, or quotes me saying things that were never said in the meeting by anyone. One time, it just used a completely different name for me throughout the recap.&lt;/p&gt;\n\n&lt;p&gt;Having seen how the proverbial sausage is made, I have no desire to use it in my personal life, because why would I use it for anything with any actual stakes? And for the remainder, Google gets me by just fine for things like &amp;quot;Who played the Sheriff in Blazing Saddles?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Anyone else feel this way, or have a weird relationship with the technology that is, for better or worse, &amp;quot;transforming&amp;quot; our field?&lt;/p&gt;\n\n&lt;p&gt;Update: some folks are leaving short, one sentence responses to the effect of &amp;quot;They&amp;#39;ve only been great for me.&amp;quot; Good! Tell us more about how you&amp;#39;re finding success in your applications. any frustrations along the way? let&amp;#39;s have a CONVERSATION. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1oa93fw", "is_robot_indexable": true, "report_reasons": null, "author": "BlackJack5027", "discussion_type": null, "num_comments": 132, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oa93fw/anyone_else_tired_of_the_nonstop_llm_hype_in/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oa93fw/anyone_else_tired_of_the_nonstop_llm_hype_in/", "subreddit_subscribers": 2695443, "created_utc": 1760825800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Disclaimer: It's UK focused.\n\n  \nHi everyone,\n\nWhen I was looking to buy a house, a big annoyance I had was that I couldn\u2019t easily tell if I was getting value for money. Although, in my opinion, any property is expensive as fuck, I knew that definitely some are more expensive than they should be, always within context.\n\nAt the time, what I did was manually extract historical data for the street and for the property I was interested in, in an attempt to understand whether it was going for more than the street average or less, and why. It wasn\u2019t my best analysis, but it did the job.\n\nFast forward a few years later, I found myself unemployed and started building projects for my portfolio, which brings us to this post. I\u2019ve built an app that, for a given postcode, gives you historical prices, price per m\u00b2, and year-on-year sales for the neighbourhood, the area, and the local authority the property falls under, as well as a property price estimation summary.\n\nThere are, of course, some caveats. Since I\u2019m only using publicly available data, the historical trends are always going to be 2\u20133 months behind. However, there\u2019s still the capacity to see overall trends e.g. an area might be up and coming if the trendline is converging toward the local authority\u2019s average.\n\nAs for the property valuation bits, although I\u2019d say it\u2019s as good as what\u2019s available out there, I\u2019ve found that at the end of the day, property prices are pretty much defined by the price of the most recent, closest property sold.\n\nFinally, this is a portfolio project, not a product  but since I\u2019m planning to maintain it, I thought I might as well share it with people, get some feedback, and maybe even make it a useful tool for some.\n\n  \nAs for what's going on under the hood. The system is organized into three modules: WH, ML, and App. Each month, the WH (Warehouse) module ingests data into BigQuery, where it\u2019s transformed following a medallion architecture. The ML module is then retrained on the latest data, and the resulting inference outputs are stored in the gold layer of BigQuery. The App module, hosted on a Lightsail instance, loads the updated gold-layer inference and analytics data after each monthly iteration. Within the app, DuckDB is used to locally query and serve this data for fast, efficient access.\n\nAnyway, here\u2019s the link if you want to play around:  [https://propertyanalytics.uk](https://propertyanalytics.uk)\n\nNote: It currently covers England and Wales, only.\n\nhttps://preview.redd.it/s220a3z702wf1.png?width=566&amp;format=png&amp;auto=webp&amp;s=1999caa45801a0ab216fa63e2de09cc9c6dfafaf\n\n", "author_fullname": "t2_2fwzqpwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a project and I thought I might share it with the group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s220a3z702wf1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/s220a3z702wf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ec94ad61f59f65716d1473f539da25bc6cb1c8b"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/s220a3z702wf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1fb64d1982822f91e962c6f360594e6a5dde2d5a"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/s220a3z702wf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a6170036ecd684138c5c11bd389083fc4aec333"}], "s": {"y": 2700, "x": 566, "u": "https://preview.redd.it/s220a3z702wf1.png?width=566&amp;format=png&amp;auto=webp&amp;s=1999caa45801a0ab216fa63e2de09cc9c6dfafaf"}, "id": "s220a3z702wf1"}}, "name": "t3_1oana21", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y0pEwxDWt1dxzbRPi4oGoOg600WH7kl5eRvYK_pQ6xY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760873322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: It&amp;#39;s UK focused.&lt;/p&gt;\n\n&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;When I was looking to buy a house, a big annoyance I had was that I couldn\u2019t easily tell if I was getting value for money. Although, in my opinion, any property is expensive as fuck, I knew that definitely some are more expensive than they should be, always within context.&lt;/p&gt;\n\n&lt;p&gt;At the time, what I did was manually extract historical data for the street and for the property I was interested in, in an attempt to understand whether it was going for more than the street average or less, and why. It wasn\u2019t my best analysis, but it did the job.&lt;/p&gt;\n\n&lt;p&gt;Fast forward a few years later, I found myself unemployed and started building projects for my portfolio, which brings us to this post. I\u2019ve built an app that, for a given postcode, gives you historical prices, price per m\u00b2, and year-on-year sales for the neighbourhood, the area, and the local authority the property falls under, as well as a property price estimation summary.&lt;/p&gt;\n\n&lt;p&gt;There are, of course, some caveats. Since I\u2019m only using publicly available data, the historical trends are always going to be 2\u20133 months behind. However, there\u2019s still the capacity to see overall trends e.g. an area might be up and coming if the trendline is converging toward the local authority\u2019s average.&lt;/p&gt;\n\n&lt;p&gt;As for the property valuation bits, although I\u2019d say it\u2019s as good as what\u2019s available out there, I\u2019ve found that at the end of the day, property prices are pretty much defined by the price of the most recent, closest property sold.&lt;/p&gt;\n\n&lt;p&gt;Finally, this is a portfolio project, not a product  but since I\u2019m planning to maintain it, I thought I might as well share it with people, get some feedback, and maybe even make it a useful tool for some.&lt;/p&gt;\n\n&lt;p&gt;As for what&amp;#39;s going on under the hood. The system is organized into three modules: WH, ML, and App. Each month, the WH (Warehouse) module ingests data into BigQuery, where it\u2019s transformed following a medallion architecture. The ML module is then retrained on the latest data, and the resulting inference outputs are stored in the gold layer of BigQuery. The App module, hosted on a Lightsail instance, loads the updated gold-layer inference and analytics data after each monthly iteration. Within the app, DuckDB is used to locally query and serve this data for fast, efficient access.&lt;/p&gt;\n\n&lt;p&gt;Anyway, here\u2019s the link if you want to play around:  &lt;a href=\"https://propertyanalytics.uk\"&gt;https://propertyanalytics.uk&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Note: It currently covers England and Wales, only.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s220a3z702wf1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1999caa45801a0ab216fa63e2de09cc9c6dfafaf\"&gt;https://preview.redd.it/s220a3z702wf1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1999caa45801a0ab216fa63e2de09cc9c6dfafaf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1oana21", "is_robot_indexable": true, "report_reasons": null, "author": "Emergency-Agreeable", "discussion_type": null, "num_comments": 13, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oana21/i_built_a_project_and_i_thought_i_might_share_it/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oana21/i_built_a_project_and_i_thought_i_might_share_it/", "subreddit_subscribers": 2695443, "created_utc": 1760873322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's a common misconception in ML/DL that\u00a0*Transformers shouldn\u2019t be used for forecasting because attention is permutation-invariant.*\n\nLatest evidence shows the opposite, such as Google's latest model, where the experiments show the model performs just as well with or without positional embeddings.\n\nYou can find an analysis on tis topic\u00a0[here](https://aihorizonforecast.substack.com/p/transformers-time-series-and-the).", "author_fullname": "t2_8xymoi0qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transformers, Time Series, and the Myth of Permutation Invariance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1oa6dn1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1760819200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a common misconception in ML/DL that\u00a0&lt;em&gt;Transformers shouldn\u2019t be used for forecasting because attention is permutation-invariant.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Latest evidence shows the opposite, such as Google&amp;#39;s latest model, where the experiments show the model performs just as well with or without positional embeddings.&lt;/p&gt;\n\n&lt;p&gt;You can find an analysis on tis topic\u00a0&lt;a href=\"https://aihorizonforecast.substack.com/p/transformers-time-series-and-the\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4.jpeg?auto=webp&amp;s=8cf7310a2883421d159987cdbdb9f5b59a6d3f9c", "width": 848, "height": 390}, "resolutions": [{"url": "https://external-preview.redd.it/qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4af769ebf4acbc008fef1e5b492e5ade7fd33ea", "width": 108, "height": 49}, {"url": "https://external-preview.redd.it/qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fb6e56e3cb1b5e04b3136877ae466885d62d0bf6", "width": 216, "height": 99}, {"url": "https://external-preview.redd.it/qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8291c2bf07cef0e969f4a84c2eeb81e94c45176a", "width": 320, "height": 147}, {"url": "https://external-preview.redd.it/qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a3c27f82e8befd1a6241fde147fb1d9a523d8bbc", "width": 640, "height": 294}], "variants": {}, "id": "qNaRNYetqENRPMICu0s4P7pwyLK62_7tB0okdeSxT_4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1oa6dn1", "is_robot_indexable": true, "report_reasons": null, "author": "nkafr", "discussion_type": null, "num_comments": 5, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1oa6dn1/transformers_time_series_and_the_myth_of/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1oa6dn1/transformers_time_series_and_the_myth_of/", "subreddit_subscribers": 2695443, "created_utc": 1760819200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been data scientist for four years and I feel we often balance on a verge of cost efficiency, because how expensive the truths are to learn. \n\nArguably, I feel like there are three types of data investigations: trivial ones, almost impossible ones, and randomized controlled experiments. The trivial ones are making a plot of a silly KPI, the impossible ones are getting actionable insights from real-world data. Random studies are the one thing in which I (still) trust. \n\nThat\u2019s why I feel like most of my job is being pain in someone\u2019s ass, finding data flaws, counterfactuals, and all sorts of reasons why whatever stakeholders want is impossible or very expensive to get. \n\nSometimes Im afraid that data science is just not cost effective. And worse, sometimes I feel like I\u2019d be a more successful (paid better) data scientist if I did more of meaningless and shallow data astrology, just reinforcing the stakeholders that their ideas are good - because given the reality of data completeness and quality, there\u2019s no way for me to tell it. Or announcing that I found an area for improvement, deliberately ignoring boring, alternative explanations. And honestly - I think that no one would ever learn what I did.\n\nIf you feel similarly, take care! I hope you too occasionally still get a high from rare moments of scientific and statistical purity we can sometimes find in our job. \n", "author_fullname": "t2_8wny0s1sw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adversarial relation of success and ethics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o9urrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760791357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been data scientist for four years and I feel we often balance on a verge of cost efficiency, because how expensive the truths are to learn. &lt;/p&gt;\n\n&lt;p&gt;Arguably, I feel like there are three types of data investigations: trivial ones, almost impossible ones, and randomized controlled experiments. The trivial ones are making a plot of a silly KPI, the impossible ones are getting actionable insights from real-world data. Random studies are the one thing in which I (still) trust. &lt;/p&gt;\n\n&lt;p&gt;That\u2019s why I feel like most of my job is being pain in someone\u2019s ass, finding data flaws, counterfactuals, and all sorts of reasons why whatever stakeholders want is impossible or very expensive to get. &lt;/p&gt;\n\n&lt;p&gt;Sometimes Im afraid that data science is just not cost effective. And worse, sometimes I feel like I\u2019d be a more successful (paid better) data scientist if I did more of meaningless and shallow data astrology, just reinforcing the stakeholders that their ideas are good - because given the reality of data completeness and quality, there\u2019s no way for me to tell it. Or announcing that I found an area for improvement, deliberately ignoring boring, alternative explanations. And honestly - I think that no one would ever learn what I did.&lt;/p&gt;\n\n&lt;p&gt;If you feel similarly, take care! I hope you too occasionally still get a high from rare moments of scientific and statistical purity we can sometimes find in our job. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o9urrk", "is_robot_indexable": true, "report_reasons": null, "author": "Ciasteczi", "discussion_type": null, "num_comments": 14, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o9urrk/adversarial_relation_of_success_and_ethics/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o9urrk/adversarial_relation_of_success_and_ethics/", "subreddit_subscribers": 2695443, "created_utc": 1760791357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, (TLDR at the end)\n\nI\u2019d like some advice on which option would be best for my career in 2\u20133 years. Both offers are internal, same salary level (France, ~58k\u20ac total, + added bonus and stock on top).\n\nI currently work as a Data Scientist \u2013 AI Lead in the space division of a major European aerospace group. I lead the internal roadmap for generative AI (RAG, LLM, ESA projects), manage ~400k\u20ac/year in R&amp;D budget, and supervise 3 people + 2 interns.\nManagement really believes in me and wants to promote me since I have been applying for new internal opportunities. Today I have 2 options on the same salary bands.\n\n\u2e3b\n\nOption 1 \u2013 getting a promotion in my team and Stay in the Space Division\n\nRole: AI Solutions Engineer / Product Owner\n\nContext: Engineering-heavy environment (satellite systems, physics, data).\n\nCommute: 10 min by bike.\n\nScope:\n\n\t\u2022\tunderstand needs and Deploy an tailored ChatGPT-like solution for technical users (~100 users/use case) as we do not have a cloud available.\n\n\t\u2022\tIntegrate generative AI into internal data platforms (500\u2013800 users).\n\n\t\u2022\tManage a total budget of ~1.2M\u20ac (including ~200k R&amp;D).\n\n\t\u2022\tSupervise subcontractors (to help with the tasks I need, I can delegate everything I want) and handle ESA AI projects (surrogate modeling, etc.).\n\nPros:\n\n\t\u2022\tGreat work-life balance (flexible hours, local site).\n\n\t\u2022\tStrong autonomy and technical depth.\n\n\t\u2022\tSupportive management, solid internal reputation.\n\n\t\u2022\tFits my AI/engineering background perfectly.\n\nCons:\n\n\t\u2022\tRestricted infra (no public cloud, only internal clusters).\n\n\t\u2022\tSlow processes and limited tools.\n\n\t\u2022\tImpact limited to the space business (niche scope).\n\n\t\u2022\tThe space division might merge with another company within 2 years \u2014 could lead to reorgs, project cancellations, or slower salary progression, and lose of big bonuses. Also current health of the branch is bad.\n\n\u2e3b\n\nOption 2 \u2013 Move to the Corporate Digital Department\n\nRole: Project Manager AI for Employee Services (Agentic AI).\n\nContext: Corporate HQ \u2013 global digital transformation team.\n\nCommute: 35\u201340 min by bike.\n\nScope:\n\n\t\u2022\tManage a 1.4M\u20ac budget to deploy AI HR tools (RAG, agentic, \u2026) and automation tools for 130,000 employees.\n\n\t\u2022\tWork with IT architects, data scientists, and HR stakeholders.\n\n\t\u2022\tAccess to modern cloud stack (Azure, M365, Vertex AI) in a more mature environment.\n\n\t\u2022\tExposure to the Chief Digital Officer and HR top management.\n\nPros:\n\n\t\u2022\tGlobal visibility and strategic exposure.\n\n\t\u2022\tFull access to modern AI tools and cloud infrastructure.\n\n\t\u2022\tLarger budget and decision-making autonomy.\n\n\t\u2022\tStronger potential long-term financial upside (high corporate bonuses, stock plan). Great financial health of the company.\n\nCons:\n\n\t\u2022\tLess technical, even though they agreed I can build PoCs and stay hands on, and be active in the architecture decisions. More project management and stakeholder coordination.\n\n\t\u2022\tMostly non-technical interlocutors (HR, business).\n\n\t\u2022\tMore political environment and higher delivery pressure.\n\n\t\u2022\tLonger commute and less daily flexibility.\n\n\u2e3b\n\nTL;DR\n\n\t\u2022\tOption 1 (Space): technical, stable, flexible, management trusts me and promises high career paths, but risk of merger and limited AI or cloud/tools.\n\n\t\u2022\tOption 2 (Corporate Digital): strategic, bigger scope (130k people), access to modern tools, more political, less hands-on.\n\n\t\u2022\tSalary: roughly the same (~58k\u20ac, + extra stock and bonus).\n\nQuestion:\n\nWhich path would give me the strongest market value in 2 years \u2014 staying as a hands-on AI lead in the space division or moving into a corporate-level AI project manager role?\n\nI value growth, getting more full remote / part time options well paid later on, and value WLB.\n\n", "author_fullname": "t2_u9hbkgyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choose between 2 internal offers ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o9r7kl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760779211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, (TLDR at the end)&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like some advice on which option would be best for my career in 2\u20133 years. Both offers are internal, same salary level (France, ~58k\u20ac total, + added bonus and stock on top).&lt;/p&gt;\n\n&lt;p&gt;I currently work as a Data Scientist \u2013 AI Lead in the space division of a major European aerospace group. I lead the internal roadmap for generative AI (RAG, LLM, ESA projects), manage ~400k\u20ac/year in R&amp;amp;D budget, and supervise 3 people + 2 interns.\nManagement really believes in me and wants to promote me since I have been applying for new internal opportunities. Today I have 2 options on the same salary bands.&lt;/p&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;Option 1 \u2013 getting a promotion in my team and Stay in the Space Division&lt;/p&gt;\n\n&lt;p&gt;Role: AI Solutions Engineer / Product Owner&lt;/p&gt;\n\n&lt;p&gt;Context: Engineering-heavy environment (satellite systems, physics, data).&lt;/p&gt;\n\n&lt;p&gt;Commute: 10 min by bike.&lt;/p&gt;\n\n&lt;p&gt;Scope:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 understand needs and Deploy an tailored ChatGPT-like solution for technical users (~100 users/use case) as we do not have a cloud available.\n\n\u2022 Integrate generative AI into internal data platforms (500\u2013800 users).\n\n\u2022 Manage a total budget of ~1.2M\u20ac (including ~200k R&amp;amp;D).\n\n\u2022 Supervise subcontractors (to help with the tasks I need, I can delegate everything I want) and handle ESA AI projects (surrogate modeling, etc.).\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Pros:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Great work-life balance (flexible hours, local site).\n\n\u2022 Strong autonomy and technical depth.\n\n\u2022 Supportive management, solid internal reputation.\n\n\u2022 Fits my AI/engineering background perfectly.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Cons:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Restricted infra (no public cloud, only internal clusters).\n\n\u2022 Slow processes and limited tools.\n\n\u2022 Impact limited to the space business (niche scope).\n\n\u2022 The space division might merge with another company within 2 years \u2014 could lead to reorgs, project cancellations, or slower salary progression, and lose of big bonuses. Also current health of the branch is bad.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;Option 2 \u2013 Move to the Corporate Digital Department&lt;/p&gt;\n\n&lt;p&gt;Role: Project Manager AI for Employee Services (Agentic AI).&lt;/p&gt;\n\n&lt;p&gt;Context: Corporate HQ \u2013 global digital transformation team.&lt;/p&gt;\n\n&lt;p&gt;Commute: 35\u201340 min by bike.&lt;/p&gt;\n\n&lt;p&gt;Scope:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Manage a 1.4M\u20ac budget to deploy AI HR tools (RAG, agentic, \u2026) and automation tools for 130,000 employees.\n\n\u2022 Work with IT architects, data scientists, and HR stakeholders.\n\n\u2022 Access to modern cloud stack (Azure, M365, Vertex AI) in a more mature environment.\n\n\u2022 Exposure to the Chief Digital Officer and HR top management.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Pros:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Global visibility and strategic exposure.\n\n\u2022 Full access to modern AI tools and cloud infrastructure.\n\n\u2022 Larger budget and decision-making autonomy.\n\n\u2022 Stronger potential long-term financial upside (high corporate bonuses, stock plan). Great financial health of the company.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Cons:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Less technical, even though they agreed I can build PoCs and stay hands on, and be active in the architecture decisions. More project management and stakeholder coordination.\n\n\u2022 Mostly non-technical interlocutors (HR, business).\n\n\u2022 More political environment and higher delivery pressure.\n\n\u2022 Longer commute and less daily flexibility.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;TL;DR&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Option 1 (Space): technical, stable, flexible, management trusts me and promises high career paths, but risk of merger and limited AI or cloud/tools.\n\n\u2022 Option 2 (Corporate Digital): strategic, bigger scope (130k people), access to modern tools, more political, less hands-on.\n\n\u2022 Salary: roughly the same (~58k\u20ac, + extra stock and bonus).\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;Which path would give me the strongest market value in 2 years \u2014 staying as a hands-on AI lead in the space division or moving into a corporate-level AI project manager role?&lt;/p&gt;\n\n&lt;p&gt;I value growth, getting more full remote / part time options well paid later on, and value WLB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o9r7kl", "is_robot_indexable": true, "report_reasons": null, "author": "LocPat", "discussion_type": null, "num_comments": 21, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o9r7kl/choose_between_2_internal_offers/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o9r7kl/choose_between_2_internal_offers/", "subreddit_subscribers": 2695443, "created_utc": 1760779211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, \n\nI am working on improving in areas of Bayesian and Frequentists A/B testings and Causal Inference, and applying them in industry. I am currently working on normal Frequentists A/B testings, and simple Causal Inference but want to expand to more nuanced cases and have some examples of what they may look like. For example, when to choose TMLE over Propensity Score Matching etc or Bayesian vs Frequentists. \n\n  \nPlease let me know if theres any resources that helped you apply these methods in your job. ", "author_fullname": "t2_u7io3tm4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Causal Data Scientists, what resources helped you the most?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o93utr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760713636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;I am working on improving in areas of Bayesian and Frequentists A/B testings and Causal Inference, and applying them in industry. I am currently working on normal Frequentists A/B testings, and simple Causal Inference but want to expand to more nuanced cases and have some examples of what they may look like. For example, when to choose TMLE over Propensity Score Matching etc or Bayesian vs Frequentists. &lt;/p&gt;\n\n&lt;p&gt;Please let me know if theres any resources that helped you apply these methods in your job. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o93utr", "is_robot_indexable": true, "report_reasons": null, "author": "LebrawnJames416", "discussion_type": null, "num_comments": 23, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o93utr/causal_data_scientists_what_resources_helped_you/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o93utr/causal_data_scientists_what_resources_helped_you/", "subreddit_subscribers": 2695443, "created_utc": 1760713636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a DS but salary is below average. Getting recruiters reaching out for other data roles though because my experience is broad. Sometimes these roles start at ~$40k over what I\u2019m making now, and even over other open DS roles I see on LinkedIn in my area for my yoe.\n\nThe issue is I love DS work, and don\u2019t want to make it super difficult to get future DS jobs. But I also wouldn\u2019t mind working in another data role for a bit to get that money though. \n\nWhat are everyone\u2019s thoughts on this? Would you leave DS for more money?", "author_fullname": "t2_9psfcrxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you move from DS to BI/DA/DE for a salary increase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o8ipwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760649795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a DS but salary is below average. Getting recruiters reaching out for other data roles though because my experience is broad. Sometimes these roles start at ~$40k over what I\u2019m making now, and even over other open DS roles I see on LinkedIn in my area for my yoe.&lt;/p&gt;\n\n&lt;p&gt;The issue is I love DS work, and don\u2019t want to make it super difficult to get future DS jobs. But I also wouldn\u2019t mind working in another data role for a bit to get that money though. &lt;/p&gt;\n\n&lt;p&gt;What are everyone\u2019s thoughts on this? Would you leave DS for more money?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o8ipwa", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Employee-4393", "discussion_type": null, "num_comments": 44, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o8ipwa/would_you_move_from_ds_to_bidade_for_a_salary/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o8ipwa/would_you_move_from_ds_to_bidade_for_a_salary/", "subreddit_subscribers": 2695443, "created_utc": 1760649795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[](https://www.reddit.com/r/analytics/?f=flair_name%3A%22Question%22)I'm early in my career, and I've been tasked with a lot of data management and governance work, building SOPs and policies, things like that, for the first time. Everytime I try to research the best templates, guides, documents, spreadsheets, mindmaps, etc., all I get are the annoying generic blog posts that companies use for SEO, like\u00a0[this](https://www.datamation.com/big-data/data-management-best-practices/). They say \"You should document everything\" but don't actually offer templates on how! I want to avoid reinventing the wheel, especially since I'm new to this side of data work.\n\nDoes anyone know of a good public resources to find guides, templates, spreadsheets, etc., for documentation, data management, SOPs, things like that instead of just the long blog posts that are littering the internet", "author_fullname": "t2_3u65v6ol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find actual resources and templates for data management that aren't just blog posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o8p6f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760667113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/analytics/?f=flair_name%3A%22Question%22\"&gt;&lt;/a&gt;I&amp;#39;m early in my career, and I&amp;#39;ve been tasked with a lot of data management and governance work, building SOPs and policies, things like that, for the first time. Everytime I try to research the best templates, guides, documents, spreadsheets, mindmaps, etc., all I get are the annoying generic blog posts that companies use for SEO, like\u00a0&lt;a href=\"https://www.datamation.com/big-data/data-management-best-practices/\"&gt;this&lt;/a&gt;. They say &amp;quot;You should document everything&amp;quot; but don&amp;#39;t actually offer templates on how! I want to avoid reinventing the wheel, especially since I&amp;#39;m new to this side of data work.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a good public resources to find guides, templates, spreadsheets, etc., for documentation, data management, SOPs, things like that instead of just the long blog posts that are littering the internet&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o8p6f0", "is_robot_indexable": true, "report_reasons": null, "author": "lemonbottles_89", "discussion_type": null, "num_comments": 9, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o8p6f0/where_to_find_actual_resources_and_templates_for/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o8p6f0/where_to_find_actual_resources_and_templates_for/", "subreddit_subscribers": 2695443, "created_utc": 1760667113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to branch out and do more personal projects for my portfolio. My personal computer is pretty old, and I\u2019m reluctant to use my work computer for my personal projects, so I\u2019m curious about what kinds of computers you all use.", "author_fullname": "t2_28f4s4s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What computer do you use for personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o8bkbt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760633697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to branch out and do more personal projects for my portfolio. My personal computer is pretty old, and I\u2019m reluctant to use my work computer for my personal projects, so I\u2019m curious about what kinds of computers you all use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o8bkbt", "is_robot_indexable": true, "report_reasons": null, "author": "BloatedGlobe", "discussion_type": null, "num_comments": 39, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o8bkbt/what_computer_do_you_use_for_personal_projects/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o8bkbt/what_computer_do_you_use_for_personal_projects/", "subreddit_subscribers": 2695443, "created_utc": 1760633697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Maven Analytics is hosting their Open Campus event Oct 20-30.  This means their whole platform is 100% free during that time. If you've been thinking about taking a course on Power BI, SQL, Python, how to approach the job search, etc., it would be a great time to binge and learn something new.\n\n  \nThere's also live sessions for these two weeks around portfolio projects, interviewing, etc.  And they all have Q&amp;A at the end, so you can ask any of the questions you have around getting into data. ", "author_fullname": "t2_r1qpqza", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Completely Free Courses Oct 20-30 from Maven Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1o7a0rk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=140&amp;height=73&amp;auto=webp&amp;s=4830f865f3ef0d46ac1fedc0a5f14fdd60121e1e", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1760532389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mavenanalytics.io", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maven Analytics is hosting their Open Campus event Oct 20-30.  This means their whole platform is 100% free during that time. If you&amp;#39;ve been thinking about taking a course on Power BI, SQL, Python, how to approach the job search, etc., it would be a great time to binge and learn something new.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also live sessions for these two weeks around portfolio projects, interviewing, etc.  And they all have Q&amp;amp;A at the end, so you can ask any of the questions you have around getting into data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://mavenanalytics.io/open-campus", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?auto=webp&amp;s=9c19f0343b3ad7cda74d39391c544949b027e815", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f7a779ac6f8b788c1a276d39550409972f52b84d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fabd8865ec6efa8715a8ca9ee264d26d6bfcf33d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1df205e98cf3fee50bf4b801167480592c2c9f1d", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18e0730730b1a2d282fe1c64e8e91067b5930dfd", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3f8cbba7c60f39a3d612cedb6631730b57e8ac0", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ffb1fe3dde856e662ab2c096172f5f082b00a5d", "width": 1080, "height": 565}], "variants": {}, "id": "6r2BRYL6rpo-pPTBLrOpxBRnohRR7WSy5VytWWOvzX0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o7a0rk", "is_robot_indexable": true, "report_reasons": null, "author": "Clicketrie", "discussion_type": null, "num_comments": 13, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o7a0rk/completely_free_courses_oct_2030_from_maven/", "stickied": false, "url": "https://mavenanalytics.io/open-campus", "subreddit_subscribers": 2695443, "created_utc": 1760532389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello data scientists and adjacent,\n\nI'm at a large company which is taking an interest in moving away from the traditional ML approach of training models ourselves to using AutoML. I have limited experience in it (except an intuition that it is likely to be less powerful in terms of explainability and debugging) and I was wondering what you guys think.\n\nHas anyone had experience with both \"custom\" modelling pipelines and using AutoML (specifically the GCP product)? What were the pros and cons? Do you think one is better than the other for specific use cases?\n\nThanks :)", "author_fullname": "t2_ucmv3u5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AutoML: Yay or nay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o6f3l8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760447450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data scientists and adjacent,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a large company which is taking an interest in moving away from the traditional ML approach of training models ourselves to using AutoML. I have limited experience in it (except an intuition that it is likely to be less powerful in terms of explainability and debugging) and I was wondering what you guys think.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had experience with both &amp;quot;custom&amp;quot; modelling pipelines and using AutoML (specifically the GCP product)? What were the pros and cons? Do you think one is better than the other for specific use cases?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o6f3l8", "is_robot_indexable": true, "report_reasons": null, "author": "idontknowotimdoing", "discussion_type": null, "num_comments": 29, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o6f3l8/automl_yay_or_nay/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o6f3l8/automl_yay_or_nay/", "subreddit_subscribers": 2695443, "created_utc": 1760447450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1vfpsu4wck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI Is Overhyped as a Job Killer, Says Google Cloud CEO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1o5nvkp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 448, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 448, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=140&amp;height=93&amp;auto=webp&amp;s=80261fe6be008279ac35443e80073aaeffe371f0", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1760371520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/ai-job-killer-google-cloud-ceo", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?auto=webp&amp;s=72e25e053c2c8ba154f4a31ff2987e22dcf90022", "width": 1024, "height": 683}, "resolutions": [{"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0725ab67386329dd77258483f71f48cc2eb58bbc", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1803d3b30e2496a6872e64576db7f897d51b2908", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=37bb4341bc8b2a39b19920cc471353baca20a956", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20cdccb184223b7b0535ee0a27dd706f27d4c0e0", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e8f77b14dc120f3e70330c2b7df7547b3873cae", "width": 960, "height": 640}], "variants": {}, "id": "x9IyERQCtMg4Uh9g7k_i1Tp7roN_5gs05RQpLzqlyWY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o5nvkp", "is_robot_indexable": true, "report_reasons": null, "author": "KitchenTaste7229", "discussion_type": null, "num_comments": 82, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o5nvkp/ai_is_overhyped_as_a_job_killer_says_google_cloud/", "stickied": false, "url": "https://www.interviewquery.com/p/ai-job-killer-google-cloud-ceo", "subreddit_subscribers": 2695443, "created_utc": 1760371520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been a DS for almost 5 years, with a good majority in NLP. I've been wanting to do more POCs, less model production (IT budget, stack ranking, general burn-out) and get into Product Management for a while. \n\nI know the technology quite well, but I lack PM experience. Honestly, I'm pretty burnt out from DS. I really like working with cross-functional teams and focusing on strategy/business more so than coding. I tend to mainly do that these days during the day, then have to code at night and it's gotten exhausting. And coming into the office with all of that... not sustainable.  \n\nI'd love to know your journey and what made you stand out when making the switch! ", "author_fullname": "t2_7lgf0u9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone switched to AI Product Management from Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o64n48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760411893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a DS for almost 5 years, with a good majority in NLP. I&amp;#39;ve been wanting to do more POCs, less model production (IT budget, stack ranking, general burn-out) and get into Product Management for a while. &lt;/p&gt;\n\n&lt;p&gt;I know the technology quite well, but I lack PM experience. Honestly, I&amp;#39;m pretty burnt out from DS. I really like working with cross-functional teams and focusing on strategy/business more so than coding. I tend to mainly do that these days during the day, then have to code at night and it&amp;#39;s gotten exhausting. And coming into the office with all of that... not sustainable.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to know your journey and what made you stand out when making the switch! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o64n48", "is_robot_indexable": true, "report_reasons": null, "author": "SnooWalruses4775", "discussion_type": null, "num_comments": 22, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o64n48/has_anyone_switched_to_ai_product_management_from/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o64n48/has_anyone_switched_to_ai_product_management_from/", "subreddit_subscribers": 2695443, "created_utc": 1760411893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Background: I have a BS double major in Data Analytics and Information Systems: Data Engineering emphasis. I\u2019m currently pursuing an MS in Data Analytics with a Statistics emphasis, plus graduate certificates in ML/AI and Data Science.\n\nI enjoy:\n\n\t\u2022\tClassical ML and statistics (regression, tree-based models, etc.)\n\n\t\u2022\tA/B testing and experimentation design\n\n\t\u2022\tForecasting and time-series analysis\n\n\t\u2022\tCausal inference\n\n\t\u2022\tSQL and Python (leveraging libraries for applied work rather than building from scratch)\n\n\nWhat I\u2019m less interested in:\n\n\t\u2022\tDeep learning, computer vision, NLP\n\n\t\u2022\tHeavy dashboard work (I can build functional dashboards but lack the design eye for making them actually look good)\n\nMy question is: To work as a Data Scientist, do I need to dive deeper into neural networks, transformers, and other deep learning topics? I don\u2019t want to get stuck doing dashboards all day as a \u201cData Analyst,\u201d but I also don\u2019t see myself doing deep learning research or building production models for image/text applications.\n\nIs there space in the industry for data scientists who specialize in classical ML, experimentation, and statistical modeling, or does the field increasingly expect everyone to know deep learning inside out?", "author_fullname": "t2_f7te6qaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deep Learning Topics: How Important Are They?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o68gf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1760452484.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760424867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I have a BS double major in Data Analytics and Information Systems: Data Engineering emphasis. I\u2019m currently pursuing an MS in Data Analytics with a Statistics emphasis, plus graduate certificates in ML/AI and Data Science.&lt;/p&gt;\n\n&lt;p&gt;I enjoy:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Classical ML and statistics (regression, tree-based models, etc.)\n\n\u2022 A/B testing and experimentation design\n\n\u2022 Forecasting and time-series analysis\n\n\u2022 Causal inference\n\n\u2022 SQL and Python (leveraging libraries for applied work rather than building from scratch)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;What I\u2019m less interested in:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Deep learning, computer vision, NLP\n\n\u2022 Heavy dashboard work (I can build functional dashboards but lack the design eye for making them actually look good)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My question is: To work as a Data Scientist, do I need to dive deeper into neural networks, transformers, and other deep learning topics? I don\u2019t want to get stuck doing dashboards all day as a \u201cData Analyst,\u201d but I also don\u2019t see myself doing deep learning research or building production models for image/text applications.&lt;/p&gt;\n\n&lt;p&gt;Is there space in the industry for data scientists who specialize in classical ML, experimentation, and statistical modeling, or does the field increasingly expect everyone to know deep learning inside out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o68gf8", "is_robot_indexable": true, "report_reasons": null, "author": "LilParkButt", "discussion_type": null, "num_comments": 18, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o68gf8/deep_learning_topics_how_important_are_they/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o68gf8/deep_learning_topics_how_important_are_they/", "subreddit_subscribers": 2695443, "created_utc": 1760424867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read somewhere that something like 60%-75% of YC-backed startups that are building agents are using Typescript. I've also heard that Typescript's native type system is very helpful for building AI apps. Is Typescript a better language than Python for building AI agents? \n\nI don't planning on training my own models so I am not sure if Python is really necessary in my case.", "author_fullname": "t2_1fke816mve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you recommend starting new agentic projects with Typescript instead of Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o6tquy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760480579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read somewhere that something like 60%-75% of YC-backed startups that are building agents are using Typescript. I&amp;#39;ve also heard that Typescript&amp;#39;s native type system is very helpful for building AI apps. Is Typescript a better language than Python for building AI agents? &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t planning on training my own models so I am not sure if Python is really necessary in my case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o6tquy", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Pound266", "discussion_type": null, "num_comments": 15, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o6tquy/would_you_recommend_starting_new_agentic_projects/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o6tquy/would_you_recommend_starting_new_agentic_projects/", "subreddit_subscribers": 2695443, "created_utc": 1760480579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a Data Scientist and am going to be moving from London to Amsterdam next year. \n\nI wanted to start freelancing to cover any unemployment period. On fiverr, I see a saturated Data Science space with hundreds of people offering quite similar expertise. On Upwork I realise you need to pay to Connect with project offerings (which sort of makes sense to me to avoid spam for the offerers), which makes me hesitant to start. \n\nI\u2019m just wondering, with where GenAI is right now, is there actually opportunity to start freelancing now or are there still ample opportunities out there? Are people still quite freely doing this as a side hustle?", "author_fullname": "t2_2qi2mssd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting my Freelance Journey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o5l0g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760365202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Data Scientist and am going to be moving from London to Amsterdam next year. &lt;/p&gt;\n\n&lt;p&gt;I wanted to start freelancing to cover any unemployment period. On fiverr, I see a saturated Data Science space with hundreds of people offering quite similar expertise. On Upwork I realise you need to pay to Connect with project offerings (which sort of makes sense to me to avoid spam for the offerers), which makes me hesitant to start. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just wondering, with where GenAI is right now, is there actually opportunity to start freelancing now or are there still ample opportunities out there? Are people still quite freely doing this as a side hustle?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o5l0g8", "is_robot_indexable": true, "report_reasons": null, "author": "cdtmh", "discussion_type": null, "num_comments": 29, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o5l0g8/starting_my_freelance_journey/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o5l0g8/starting_my_freelance_journey/", "subreddit_subscribers": 2695443, "created_utc": 1760365202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a use case where I need to get the right answer and send it to the user. I have been struggling for a time to find a reliable metric to use that tells me when an answer is correct.\n\nThe cost of a **false positive** is very high; there is a huge risk in sending an incorrect answer to the user.\n\nI have been spending most of my time trying to find which metric to use to evaluate the answer.\n\nHere is what I have tried so far:\n\n* I have checked the perplexity or the average log probability of the generated tokens, but it is only consistent when the model cannot find the answer in the provided chunks. The way my prompt is **designed**, in this case, the model returns, \"I cannot find the answer in the provided context\\*\\*,\\*\\*\" and that is a good signal when I cannot find the **answer**.\n* However, when the model is hallucinating an answer based on the provided tokens, it is very confident and returns a high perplexity / average token probability.\n* I have tried to use the cosine **similarity** between the question and the embeddings. It is okay when the model cannot find the correct chunks; the similarity is low, and for those, I am certain that the answer will be incorrect. But sometimes, the embedding models have some flaws.\n* I have tried to create a **metric** that is a weighted average of the average cosine **similarity** and the average token probability; it seems to work, but not quite well.\n* I cannot use an LLM as a judge. I don't think it **works** or is reliable, and the stakeholders do not trust the whole concept of judging the output of an LLM with another LLM.\n* I am in the process of getting **samples** of questions and answers labelled by **humans** who answer these questions in practice to see which metric will **correlate** with the human answer.\n\n**Other information:**\n\nFor now, I am only working with 164 **samples** of **questions**. Is this good enough? The **business** is planning on providing us with more questions to test the system.\n\nThe workflow I am suggesting for production is this:\n\n1. Get the question.\n2. If the average cosine **similarity** between the question and the chunks is low, route the question to an agent because we cannot find the answer.\n3. If it is high, we send it to the LLM and prompt it to generate an **answer** based on the context. If the LLM cannot find the answer in the provided context, send it to the agent.\n4. If it **says** it can find the answer, **generate** the answer and the reference. Check the average distance and the average token probability; if it is low, send it to the agent.\n5. Now, if the answer is there, there are enough references, and the **weighted** average of the token probability is high, send the answer to the user.\n\nHow do you think about this approach? What are other **ways** I can do better in order to evaluate and increase the number of answers I am sending to the user? For those who have worked with RAG in production, how do you handle this type of problem?\n\nHow do you quantify the **business** impact of **such a** system?\n\nI think if I manage to **answer** 50% of the users' queries correctly and the other 50% of queries go to an agent, the system **reduces** the workload of the agent by 50%.\n\nBut my boss is saying that it is not a good system if it is just 50% accurate, and **sometimes** the agents will stop using it in production. Is that true?", "author_fullname": "t2_4m2zb1fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In production, how do you evaluate the quality of the response generated by a RAG system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o5n86i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1760370981.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760370101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a use case where I need to get the right answer and send it to the user. I have been struggling for a time to find a reliable metric to use that tells me when an answer is correct.&lt;/p&gt;\n\n&lt;p&gt;The cost of a &lt;strong&gt;false positive&lt;/strong&gt; is very high; there is a huge risk in sending an incorrect answer to the user.&lt;/p&gt;\n\n&lt;p&gt;I have been spending most of my time trying to find which metric to use to evaluate the answer.&lt;/p&gt;\n\n&lt;p&gt;Here is what I have tried so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have checked the perplexity or the average log probability of the generated tokens, but it is only consistent when the model cannot find the answer in the provided chunks. The way my prompt is &lt;strong&gt;designed&lt;/strong&gt;, in this case, the model returns, &amp;quot;I cannot find the answer in the provided context**,**&amp;quot; and that is a good signal when I cannot find the &lt;strong&gt;answer&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;However, when the model is hallucinating an answer based on the provided tokens, it is very confident and returns a high perplexity / average token probability.&lt;/li&gt;\n&lt;li&gt;I have tried to use the cosine &lt;strong&gt;similarity&lt;/strong&gt; between the question and the embeddings. It is okay when the model cannot find the correct chunks; the similarity is low, and for those, I am certain that the answer will be incorrect. But sometimes, the embedding models have some flaws.&lt;/li&gt;\n&lt;li&gt;I have tried to create a &lt;strong&gt;metric&lt;/strong&gt; that is a weighted average of the average cosine &lt;strong&gt;similarity&lt;/strong&gt; and the average token probability; it seems to work, but not quite well.&lt;/li&gt;\n&lt;li&gt;I cannot use an LLM as a judge. I don&amp;#39;t think it &lt;strong&gt;works&lt;/strong&gt; or is reliable, and the stakeholders do not trust the whole concept of judging the output of an LLM with another LLM.&lt;/li&gt;\n&lt;li&gt;I am in the process of getting &lt;strong&gt;samples&lt;/strong&gt; of questions and answers labelled by &lt;strong&gt;humans&lt;/strong&gt; who answer these questions in practice to see which metric will &lt;strong&gt;correlate&lt;/strong&gt; with the human answer.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Other information:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For now, I am only working with 164 &lt;strong&gt;samples&lt;/strong&gt; of &lt;strong&gt;questions&lt;/strong&gt;. Is this good enough? The &lt;strong&gt;business&lt;/strong&gt; is planning on providing us with more questions to test the system.&lt;/p&gt;\n\n&lt;p&gt;The workflow I am suggesting for production is this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get the question.&lt;/li&gt;\n&lt;li&gt;If the average cosine &lt;strong&gt;similarity&lt;/strong&gt; between the question and the chunks is low, route the question to an agent because we cannot find the answer.&lt;/li&gt;\n&lt;li&gt;If it is high, we send it to the LLM and prompt it to generate an &lt;strong&gt;answer&lt;/strong&gt; based on the context. If the LLM cannot find the answer in the provided context, send it to the agent.&lt;/li&gt;\n&lt;li&gt;If it &lt;strong&gt;says&lt;/strong&gt; it can find the answer, &lt;strong&gt;generate&lt;/strong&gt; the answer and the reference. Check the average distance and the average token probability; if it is low, send it to the agent.&lt;/li&gt;\n&lt;li&gt;Now, if the answer is there, there are enough references, and the &lt;strong&gt;weighted&lt;/strong&gt; average of the token probability is high, send the answer to the user.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How do you think about this approach? What are other &lt;strong&gt;ways&lt;/strong&gt; I can do better in order to evaluate and increase the number of answers I am sending to the user? For those who have worked with RAG in production, how do you handle this type of problem?&lt;/p&gt;\n\n&lt;p&gt;How do you quantify the &lt;strong&gt;business&lt;/strong&gt; impact of &lt;strong&gt;such a&lt;/strong&gt; system?&lt;/p&gt;\n\n&lt;p&gt;I think if I manage to &lt;strong&gt;answer&lt;/strong&gt; 50% of the users&amp;#39; queries correctly and the other 50% of queries go to an agent, the system &lt;strong&gt;reduces&lt;/strong&gt; the workload of the agent by 50%.&lt;/p&gt;\n\n&lt;p&gt;But my boss is saying that it is not a good system if it is just 50% accurate, and &lt;strong&gt;sometimes&lt;/strong&gt; the agents will stop using it in production. Is that true?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o5n86i", "is_robot_indexable": true, "report_reasons": null, "author": "esp_py", "discussion_type": null, "num_comments": 19, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o5n86i/in_production_how_do_you_evaluate_the_quality_of/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o5n86i/in_production_how_do_you_evaluate_the_quality_of/", "subreddit_subscribers": 2695443, "created_utc": 1760370101.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "They seem to be merging? Thoughts on this please. How does this shakeup the landscape if at all? ", "author_fullname": "t2_9dswaf0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1o5pg14", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pw0fgCdlWe8n_tCtFCA9623gQWajdzkYlTAJPdRnqOw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1760374864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They seem to be merging? Thoughts on this please. How does this shakeup the landscape if at all? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5ycpvlt9uwuf1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?auto=webp&amp;s=66edeb7691bcf55efca513c9e530a33455a4884b", "width": 1179, "height": 1433}, "resolutions": [{"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59b690a3fb67472cb5e31dbbc1661b7696ef72e8", "width": 108, "height": 131}, {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=33ea90764dd7f16cedc14191480f05079fc022ef", "width": 216, "height": 262}, {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cd81f71483c43afb809197058e80c69a363082b", "width": 320, "height": 388}, {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca13efe05af2be5dbdf62ed72910a53b13057822", "width": 640, "height": 777}, {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e86844815394836eea2f47c4fcf43326f4c56d0f", "width": 960, "height": 1166}, {"url": "https://preview.redd.it/5ycpvlt9uwuf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=422fdd6aa0dea9fed1a38829a42e5d3ddd9bfca9", "width": 1080, "height": 1312}], "variants": {}, "id": "xb-eGHhH7I8dZ2SBmJNWgDctgdlhRcji1niyXtA0BKQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o5pg14", "is_robot_indexable": true, "report_reasons": null, "author": "Fondant_Decent", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o5pg14/fivetran_and_dbt/", "stickied": false, "url": "https://i.redd.it/5ycpvlt9uwuf1.jpeg", "subreddit_subscribers": 2695443, "created_utc": 1760374864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 13 Oct, 2025 - 20 Oct, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o59o2w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760328070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1o59o2w", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 12, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o59o2w/weekly_entering_transitioning_thread_13_oct_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o59o2w/weekly_entering_transitioning_thread_13_oct_2025/", "subreddit_subscribers": 2695443, "created_utc": 1760328070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 200 observations, 3 variables ( somewhat correlated).For v1, the median is 300 dollars. but I have a really long tail. when I do the histogram, 100 obs are near 0 and the others form a really long tail, even when I cap outliers. what is best way to cluster?", "author_fullname": "t2_bpcrc4t2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustring very different values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o37n2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760118067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 200 observations, 3 variables ( somewhat correlated).For v1, the median is 300 dollars. but I have a really long tail. when I do the histogram, 100 obs are near 0 and the others form a really long tail, even when I cap outliers. what is best way to cluster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o37n2r", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Duty961", "discussion_type": null, "num_comments": 22, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o37n2r/clustring_very_different_values/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o37n2r/clustring_very_different_values/", "subreddit_subscribers": 2695443, "created_utc": 1760118067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI\u2019m 25, currently working as a Data Scientist &amp; AI Engineer at a large Space company in Europe, with ~2.5 years of experience. My focus has been on LLM R&amp;D, RAG pipelines, satellite telemetry anomaly detection, surrogate modeling, and some FPGA-compatible ML for onboard systems. I also mentor interns, coordinate small R&amp;D projects, and occasionally present findings internally.\n\nThe context is tough (departures, headcount freezes) and I have an opportunity to move to a large aeronautics company or stay in my team, but grow in scope.\n\nI\u2019m now evaluating two potential next roles (which I might intend as ~2-year commitments before moving on) and would love advice from anyone who has experience with either path:\n\n\u2e3b\n\nOption 1 \u2013 AI Product Manager / Project Manager in HR\n\n\t\u2022\tDeploy 8 AI agents across HR services, impacting ~130k employees.\n\n\t\u2022\tLead roadmap, orchestrate AI integrations, and liaise with IT and HR VPs.\n\n\t\u2022\tFocus on coordination, strategy, and high-level product ownership.\n\n\t\u2022\tAccess to cutting-edge generative AI tools and cloud-based agentic workflows.\n\n\t\u2022\tHigh exposure to senior stakeholders and leadership opportunities.\n\n\t\u2022\tSome political stress: managing expectations of VPs, cross-team alignment, continuous meetings. It is said to be a quite political environment as you deal with HR and not just engineers.\n\n\u2e3b\n\nOption 2 \u2013 Big data product owner + AI R&amp;D manager (Tech + Product Ownership) in Space\n\n\t\u2022\tMerge internal Big Data platforms and integrate AI/analytics pipelines and PO role for a 600 user data lake platform (on premise due to security constraints), coordinating subcontractors.\n\n\t\u2022\tManage R&amp;D programs with subcontractors, support bids, and deploy ML models.\n\n\t\u2022\tsome Hands-on technical + coordination (MLops, RAG, keeping 1 data science R&amp;D project as a IC and take subs for the rest), some product ownership.\n\n\t\u2022\tExposure mostly internal; less political stress, but operational and technical expectations remain high.\n\n\t\u2022\tTechnical constraints due to working in a defense context: access to cutting-edge AI tools is limited, and infrastructure is slower/more constrained.\n\n\t\u2022\tOpportunity to remain in the aerospace/space field I\u2019m passionate about, but external market is niche.\n\n\u2e3b\n\nMy Considerations\n\n\t\u2022\tI\u2019m not an elite coder; my strength is prototyping, vision, and leadership rather than optimizing code.\n\n\t\u2022\tLife-work balance is important; I do ~12\u201320h of meetings per week currently and enjoy running, cycling, and other hobbies.\n\n\t\u2022\tOption 1 offers exposure to latest AI technologies and high-level leadership, but comes with political challenges. Also, HR tech is not sexy.\n\n\t\u2022\tOption 2 is more technical and personally interesting (space), but tools and infrastructure are slower, and the field is more niche. Plus it\u2019s in a crisis in Europe meaning we could have 2-5 years of stagnation.\n\n\u2e3b\n\nQuestions to the community:\n\n\t1.\tIf you had to choose between strategic PM exposure with generative AI vs hands-on hybrid tech + product in a niche field, which would you pick early in your career?\n\n\t2.\tWhich path do you think gives the strongest leverage for leadership or high-profile opportunities?\n\n\t3.\tAny advice on navigating political stress if I take the PM role?\n\n\t4.\tAre there hybrid ways to make the PM role technically \u201csexier\u201d or future-proof in AI?\n\n      5.   I am also considering moving into high paid remote roles such as tech sales in the future. Which would work as the best intermediate role ?\n\nThanks in advance for your insights! Any real-world experience, pros/cons, or anecdotal advice is hugely appreciated.", "author_fullname": "t2_u9hbkgyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From data scientist to a new role ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o2y9ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760095555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m 25, currently working as a Data Scientist &amp;amp; AI Engineer at a large Space company in Europe, with ~2.5 years of experience. My focus has been on LLM R&amp;amp;D, RAG pipelines, satellite telemetry anomaly detection, surrogate modeling, and some FPGA-compatible ML for onboard systems. I also mentor interns, coordinate small R&amp;amp;D projects, and occasionally present findings internally.&lt;/p&gt;\n\n&lt;p&gt;The context is tough (departures, headcount freezes) and I have an opportunity to move to a large aeronautics company or stay in my team, but grow in scope.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m now evaluating two potential next roles (which I might intend as ~2-year commitments before moving on) and would love advice from anyone who has experience with either path:&lt;/p&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;Option 1 \u2013 AI Product Manager / Project Manager in HR&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Deploy 8 AI agents across HR services, impacting ~130k employees.\n\n\u2022 Lead roadmap, orchestrate AI integrations, and liaise with IT and HR VPs.\n\n\u2022 Focus on coordination, strategy, and high-level product ownership.\n\n\u2022 Access to cutting-edge generative AI tools and cloud-based agentic workflows.\n\n\u2022 High exposure to senior stakeholders and leadership opportunities.\n\n\u2022 Some political stress: managing expectations of VPs, cross-team alignment, continuous meetings. It is said to be a quite political environment as you deal with HR and not just engineers.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;Option 2 \u2013 Big data product owner + AI R&amp;amp;D manager (Tech + Product Ownership) in Space&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Merge internal Big Data platforms and integrate AI/analytics pipelines and PO role for a 600 user data lake platform (on premise due to security constraints), coordinating subcontractors.\n\n\u2022 Manage R&amp;amp;D programs with subcontractors, support bids, and deploy ML models.\n\n\u2022 some Hands-on technical + coordination (MLops, RAG, keeping 1 data science R&amp;amp;D project as a IC and take subs for the rest), some product ownership.\n\n\u2022 Exposure mostly internal; less political stress, but operational and technical expectations remain high.\n\n\u2022 Technical constraints due to working in a defense context: access to cutting-edge AI tools is limited, and infrastructure is slower/more constrained.\n\n\u2022 Opportunity to remain in the aerospace/space field I\u2019m passionate about, but external market is niche.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;My Considerations&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 I\u2019m not an elite coder; my strength is prototyping, vision, and leadership rather than optimizing code.\n\n\u2022 Life-work balance is important; I do ~12\u201320h of meetings per week currently and enjoy running, cycling, and other hobbies.\n\n\u2022 Option 1 offers exposure to latest AI technologies and high-level leadership, but comes with political challenges. Also, HR tech is not sexy.\n\n\u2022 Option 2 is more technical and personally interesting (space), but tools and infrastructure are slower, and the field is more niche. Plus it\u2019s in a crisis in Europe meaning we could have 2-5 years of stagnation.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;\u2e3b&lt;/p&gt;\n\n&lt;p&gt;Questions to the community:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;1.  If you had to choose between strategic PM exposure with generative AI vs hands-on hybrid tech + product in a niche field, which would you pick early in your career?\n\n2.  Which path do you think gives the strongest leverage for leadership or high-profile opportunities?\n\n3.  Any advice on navigating political stress if I take the PM role?\n\n4.  Are there hybrid ways to make the PM role technically \u201csexier\u201d or future-proof in AI?\n\n  5.   I am also considering moving into high paid remote roles such as tech sales in the future. Which would work as the best intermediate role ?\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Thanks in advance for your insights! Any real-world experience, pros/cons, or anecdotal advice is hugely appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o2y9ki", "is_robot_indexable": true, "report_reasons": null, "author": "LocPat", "discussion_type": null, "num_comments": 37, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o2y9ki/from_data_scientist_to_a_new_role/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o2y9ki/from_data_scientist_to_a_new_role/", "subreddit_subscribers": 2695443, "created_utc": 1760095555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m deciding between two mid-level data science offers at large tech companies. These are more applied scientist type of roles than analytics. Comp and level are similar, so I\u2019m really trying to figure out which one will set me up for a stronger career in the long run.\n\nThis will be my first true DS role (coming from a technical background, PhD + previous R&amp;D role). I want to do interesting, high-impact work that keeps doors open possibly toward more research-type paths down the line but I also care a lot about working under a manager who can actually help me grow and foster a good career trajectory.\n\nFor those who\u2019ve been in big-tech DS roles, what should I be asking or paying attention to when talking to the managers or teams to tell which role will offer better career growth, mentorship, and long-term options?\n\nWould love any advice or signals I should be looking for.", "author_fullname": "t2_b6ovigu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I ask my potential managers when choosing between two jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o2nf09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760058554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m deciding between two mid-level data science offers at large tech companies. These are more applied scientist type of roles than analytics. Comp and level are similar, so I\u2019m really trying to figure out which one will set me up for a stronger career in the long run.&lt;/p&gt;\n\n&lt;p&gt;This will be my first true DS role (coming from a technical background, PhD + previous R&amp;amp;D role). I want to do interesting, high-impact work that keeps doors open possibly toward more research-type paths down the line but I also care a lot about working under a manager who can actually help me grow and foster a good career trajectory.&lt;/p&gt;\n\n&lt;p&gt;For those who\u2019ve been in big-tech DS roles, what should I be asking or paying attention to when talking to the managers or teams to tell which role will offer better career growth, mentorship, and long-term options?&lt;/p&gt;\n\n&lt;p&gt;Would love any advice or signals I should be looking for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1o2nf09", "is_robot_indexable": true, "report_reasons": null, "author": "SavingsMortgage1972", "discussion_type": null, "num_comments": 16, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o2nf09/what_should_i_ask_my_potential_managers_when/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o2nf09/what_should_i_ask_my_potential_managers_when/", "subreddit_subscribers": 2695443, "created_utc": 1760058554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Best ressource to classify for example: walmart. food ( top classification) supermarket ( sub classification). I work with european companies also.\nthanks.", "author_fullname": "t2_bpcrc4t2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free data set that links company to type of activity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o26g7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1760017793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Best ressource to classify for example: walmart. food ( top classification) supermarket ( sub classification). I work with european companies also.\nthanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o26g7h", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Duty961", "discussion_type": null, "num_comments": 12, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o26g7h/free_data_set_that_links_company_to_type_of/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o26g7h/free_data_set_that_links_company_to_type_of/", "subreddit_subscribers": 2695443, "created_utc": 1760017793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Less is More: Recursive Reasoning with Tiny Networks (7M model beats R1, Gemini 2.5 Pro on ARC AGI)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o1e1vm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_th2ct5t8g", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "**Less is More: Recursive Reasoning with Tiny Network**s, from Samsung Montr\u00e9al by Alexia Jolicoeur-Martineau, shows how a **7M-parameter Tiny Recursive Model (TRM)** outperforms trillion-parameter LLMs on hard reasoning benchmarks. TRM learns by **recursively refining its own answers** using two internal memories: a latent reasoning state (*z*) and a current answer (*y*). \n\nNo chain-of-thought, no fixed-point math, no biological hierarchies. It beats the Hierarchical Reasoning Model (HRM), which used two networks and heavy training tricks. Results: **87% on Sudoku-Extreme**, **85% on Maze-Hard**, **45% on ARC-AGI-1**, **8% on ARC-AGI-2,** surpassing Gemini 2.5 Pro, DeepSeek R1, and o3-mini despite having &lt;0.01% their size.  \n**In short:** recursion, not scale, drives reasoning.\n\n  \nPaper : [https://arxiv.org/html/2510.04871v1](https://arxiv.org/html/2510.04871v1)\n\nSummary : [https://youtu.be/wQbEITW7BMw?si=U3SFKAGYF5K06fFw](https://youtu.be/wQbEITW7BMw?si=U3SFKAGYF5K06fFw)", "author_fullname": "t2_th2ct5t8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Less is More: Recursive Reasoning with Tiny Networks (7M model beats R1, Gemini 2.5 Pro on ARC AGI)", "link_flair_richtext": [{"e": "text", "t": "News"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1o1e04z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "", "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [{"a": ":Discord:", "e": "emoji", "u": "https://emoji.redditmedia.com/08m5x9chttjf1_t5_81eyvm/Discord"}], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759938005.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Less is More: Recursive Reasoning with Tiny Network&lt;/strong&gt;s, from Samsung Montr\u00e9al by Alexia Jolicoeur-Martineau, shows how a &lt;strong&gt;7M-parameter Tiny Recursive Model (TRM)&lt;/strong&gt; outperforms trillion-parameter LLMs on hard reasoning benchmarks. TRM learns by &lt;strong&gt;recursively refining its own answers&lt;/strong&gt; using two internal memories: a latent reasoning state (&lt;em&gt;z&lt;/em&gt;) and a current answer (&lt;em&gt;y&lt;/em&gt;). &lt;/p&gt;\n\n&lt;p&gt;No chain-of-thought, no fixed-point math, no biological hierarchies. It beats the Hierarchical Reasoning Model (HRM), which used two networks and heavy training tricks. Results: &lt;strong&gt;87% on Sudoku-Extreme&lt;/strong&gt;, &lt;strong&gt;85% on Maze-Hard&lt;/strong&gt;, &lt;strong&gt;45% on ARC-AGI-1&lt;/strong&gt;, &lt;strong&gt;8% on ARC-AGI-2,&lt;/strong&gt; surpassing Gemini 2.5 Pro, DeepSeek R1, and o3-mini despite having &amp;lt;0.01% their size.&lt;br/&gt;\n&lt;strong&gt;In short:&lt;/strong&gt; recursion, not scale, drives reasoning.&lt;/p&gt;\n\n&lt;p&gt;Paper : &lt;a href=\"https://arxiv.org/html/2510.04871v1\"&gt;https://arxiv.org/html/2510.04871v1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Summary : &lt;a href=\"https://youtu.be/wQbEITW7BMw?si=U3SFKAGYF5K06fFw\"&gt;https://youtu.be/wQbEITW7BMw?si=U3SFKAGYF5K06fFw&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": ":Discord:", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "1o1e04z", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Love-8479", "discussion_type": null, "num_comments": 38, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/LocalLLaMA/comments/1o1e04z/less_is_more_recursive_reasoning_with_tiny/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1o1e04z/less_is_more_recursive_reasoning_with_tiny/", "subreddit_subscribers": 553645, "created_utc": 1759938005.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1759938110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/LocalLLaMA/comments/1o1e04z/less_is_more_recursive_reasoning_with_tiny/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1o1e1vm", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Love-8479", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1o1e04z", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o1e1vm/less_is_more_recursive_reasoning_with_tiny/", "stickied": false, "url": "/r/LocalLLaMA/comments/1o1e04z/less_is_more_recursive_reasoning_with_tiny/", "subreddit_subscribers": 2695443, "created_utc": 1759938110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone!\n\nStaying on top of the constantly growing skill requirements in Data Science is quite a challenge. To manage my own learning and growth, I've been curating a list of useful resources and tools that cover the full spectrum of the field \u2014 from data analysis and engineering to deep learning and AI.\n\nI'd love to get your professional opinion. Could you please take a look? Have I missed anything crucial? What else would you recommend adding or focusing on?\n\nTo give you an immediate sense of the list's scope and structure, I've attached screenshots of the table of contents below.\n\nThe full version with all the active links and additional resources is available on GitHub. You can find the link at the end of the post.\n\nhttps://preview.redd.it/egbe8jmruotf1.png?width=890&amp;format=png&amp;auto=webp&amp;s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c\n\nhttps://preview.redd.it/3vq4pm8k1evf1.png?width=882&amp;format=png&amp;auto=webp&amp;s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f\n\nI'd be happy if this list is useful to others.\n\nYou can view the full list here [View on GitHub](https://github.com/PavelGrigoryevDS/awesome-data-analysis?#awesome-data-analysis-)\n\nThanks for your time! Your advice is invaluable!", "author_fullname": "t2_1w40m9mrr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Data Science &amp; Analysis: A curated list of roadmaps, tutorials, Python libraries, SQL, ML/AI, data visualization, statistics, cheatsheets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"egbe8jmruotf1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/egbe8jmruotf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c38d8c65a04d8d0125256ff9b57e0dab4ba86806"}, {"y": 242, "x": 216, "u": "https://preview.redd.it/egbe8jmruotf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3496102fd8db789bbd84903a59a1a6d5de5ce342"}, {"y": 359, "x": 320, "u": "https://preview.redd.it/egbe8jmruotf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb9d41c393f1f825b362f79120004889f6097a6e"}, {"y": 719, "x": 640, "u": "https://preview.redd.it/egbe8jmruotf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b62959e011ccf0e397856b96a29d037886fc9ff4"}], "s": {"y": 1001, "x": 890, "u": "https://preview.redd.it/egbe8jmruotf1.png?width=890&amp;format=png&amp;auto=webp&amp;s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c"}, "id": "egbe8jmruotf1"}, "3vq4pm8k1evf1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 106, "x": 108, "u": "https://preview.redd.it/3vq4pm8k1evf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c530002e3721126e24645c1da738dafc048b660"}, {"y": 212, "x": 216, "u": "https://preview.redd.it/3vq4pm8k1evf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c86b8af59e798d51b759df6303f297cbe5cbaecf"}, {"y": 314, "x": 320, "u": "https://preview.redd.it/3vq4pm8k1evf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f10f72c4d4a6a7298fef88e2271cbff47c5828ad"}, {"y": 629, "x": 640, "u": "https://preview.redd.it/3vq4pm8k1evf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae265e1e8f60284afd2a408c51fae6db250a533b"}], "s": {"y": 868, "x": 882, "u": "https://preview.redd.it/3vq4pm8k1evf1.png?width=882&amp;format=png&amp;auto=webp&amp;s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f"}, "id": "3vq4pm8k1evf1"}}, "name": "t3_1o0eed8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 277, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 277, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=140&amp;height=70&amp;auto=webp&amp;s=4a78946c185439f614b1ab5e28bd4c736b44943b", "edited": 1760583204.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1759842743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;Staying on top of the constantly growing skill requirements in Data Science is quite a challenge. To manage my own learning and growth, I&amp;#39;ve been curating a list of useful resources and tools that cover the full spectrum of the field \u2014 from data analysis and engineering to deep learning and AI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to get your professional opinion. Could you please take a look? Have I missed anything crucial? What else would you recommend adding or focusing on?&lt;/p&gt;\n\n&lt;p&gt;To give you an immediate sense of the list&amp;#39;s scope and structure, I&amp;#39;ve attached screenshots of the table of contents below.&lt;/p&gt;\n\n&lt;p&gt;The full version with all the active links and additional resources is available on GitHub. You can find the link at the end of the post.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/egbe8jmruotf1.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c\"&gt;https://preview.redd.it/egbe8jmruotf1.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3vq4pm8k1evf1.png?width=882&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f\"&gt;https://preview.redd.it/3vq4pm8k1evf1.png?width=882&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be happy if this list is useful to others.&lt;/p&gt;\n\n&lt;p&gt;You can view the full list here &lt;a href=\"https://github.com/PavelGrigoryevDS/awesome-data-analysis?#awesome-data-analysis-\"&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time! Your advice is invaluable!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?auto=webp&amp;s=8796dfcd0c1225ed2f872f646adc1bfd2b109865", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bdb8a85428306107d8520206c1774cf537f321a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=28114ac3adc5274ec3dddc46361d1b65c90a1cd4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd614ea609e7cc34469ffd0331be5ac635be82a6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd3cecc3ab6a0197a3998491868d1334787ad516", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a61fdc285648c0fb7bdd6c4daae0566a2c20f358", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3cd2e1a4eca255b837c00708e8e916afab68b491", "width": 1080, "height": 540}], "variants": {}, "id": "DF_VcOH-nTX-sM6LCOgAiz_ETGQQ7BsGrD_nohgRkL4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o0eed8", "is_robot_indexable": true, "report_reasons": null, "author": "DeepAnalyze", "discussion_type": null, "num_comments": 76, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o0eed8/resources_for_data_science_analysis_a_curated/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1o0eed8/resources_for_data_science_analysis_a_curated/", "subreddit_subscribers": 2695443, "created_utc": 1759842743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1rer4n1ivg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nvidia CEO Reveals the Job That\u2019ll Win the AI Race", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1o0khz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=140&amp;height=93&amp;auto=webp&amp;s=a21ec54ff2f9fec976853dcfd7dcfdb017eecd17", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1759856474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/nvidia-ceo-ai-race", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?auto=webp&amp;s=de45dcc5689f4395fe96f917b0e3a73bb1de8bbf", "width": 1280, "height": 854}, "resolutions": [{"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f00de94ec1c66bee45c8de3a8c3704f00e7e1856", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83719dac1946c90d1ec672506ea1f98733e58d3b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d3b0a654762776517aebfb4f2660a4d9a666a82", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=308e61f9c795cf6cee973375c101a43199294484", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3267282093f7f49231de69615b3c1c35edb48e5f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f907a2e378f479290cbe8e5057ed2884bccaa87", "width": 1080, "height": 720}], "variants": {}, "id": "DzWDQJx2ZMr-rr7IFtRMAVronLVyDjQNKMH9qEqrqqM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1o0khz8", "is_robot_indexable": true, "report_reasons": null, "author": "nullstillstands", "discussion_type": null, "num_comments": 48, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1o0khz8/nvidia_ceo_reveals_the_job_thatll_win_the_ai_race/", "stickied": false, "url": "https://www.interviewquery.com/p/nvidia-ceo-ai-race", "subreddit_subscribers": 2695443, "created_utc": 1759856474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently ran exploratory analysis on the group chat of the [AI Village](https://theaidigest.org/village): 4+ frontier LLMs all have their own computer, access to the internet, and a group chat, and then get set goals like [raise money](https://theaidigest.org/village/blog/season-recap-agents-raise-2k) for charity, [sell T-shirts](https://theaidigest.org/village/blog/im-gemini-i-sold-t-shirts), or debate ethics. The goal is to build some awareness around what models are capable of now. I took the 200+ hours of group chat between the models and ran some exploratory analyses. Turns out:\n\n  \n\\- o3 has the highest Type-Token Ratio, even higher than GPT-5! o3 is also the model that wins at [diplomacy](https://every.to/diplomacy) against other agents, and won at AI debate in the AI Village.\n\n\\- GPT-5 uses the fewest contractions, writes the longest sentences, and uses the least slang/filler. I'm thinking about this as \"most formal\" but maybe it's something else?\n\n\\- GPT-4o had the highest positive sentiment scores in the Village and is also known as the most sycophantic model\n\n  \nI enjoyed analyzing the data and would love to do more. Any tips on what to look at? I might be able to share the data if people are interested. Feel free to send me a DM and we can see what's possible :)", "author_fullname": "t2_13ocpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploratory analysis of 12 frontier LLM's across 100s of hours shows o3 highest Type-Token Ratio (Lexical Diversity), GPT-5 most formal language, and GPT-4o most positive sentiment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1nzfr4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=140&amp;height=73&amp;auto=webp&amp;s=eacac1c829c0d7fb0adf1cb4eacabc48c68280c8", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1759747939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theaidigest.org", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently ran exploratory analysis on the group chat of the &lt;a href=\"https://theaidigest.org/village\"&gt;AI Village&lt;/a&gt;: 4+ frontier LLMs all have their own computer, access to the internet, and a group chat, and then get set goals like &lt;a href=\"https://theaidigest.org/village/blog/season-recap-agents-raise-2k\"&gt;raise money&lt;/a&gt; for charity, &lt;a href=\"https://theaidigest.org/village/blog/im-gemini-i-sold-t-shirts\"&gt;sell T-shirts&lt;/a&gt;, or debate ethics. The goal is to build some awareness around what models are capable of now. I took the 200+ hours of group chat between the models and ran some exploratory analyses. Turns out:&lt;/p&gt;\n\n&lt;p&gt;- o3 has the highest Type-Token Ratio, even higher than GPT-5! o3 is also the model that wins at &lt;a href=\"https://every.to/diplomacy\"&gt;diplomacy&lt;/a&gt; against other agents, and won at AI debate in the AI Village.&lt;/p&gt;\n\n&lt;p&gt;- GPT-5 uses the fewest contractions, writes the longest sentences, and uses the least slang/filler. I&amp;#39;m thinking about this as &amp;quot;most formal&amp;quot; but maybe it&amp;#39;s something else?&lt;/p&gt;\n\n&lt;p&gt;- GPT-4o had the highest positive sentiment scores in the Village and is also known as the most sycophantic model&lt;/p&gt;\n\n&lt;p&gt;I enjoyed analyzing the data and would love to do more. Any tips on what to look at? I might be able to share the data if people are interested. Feel free to send me a DM and we can see what&amp;#39;s possible :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://theaidigest.org/village/blog/village-in-numbers", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?auto=webp&amp;s=f447e5b900b5908d9074260affb723ba14dd7d68", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=addddfeba02bd26466e5b90c8505d25ad3e0189e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=914a26fa1b847d42002ea14a6c327c80ef14ddd7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=842d9247091b9471cc86202dce79cc52a7da5e7f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d32cefcf0532012b4c3c0a04fd79bba1fbeb71df", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=40c7f4ad8c5d0ee1ba33ee8b1b47b552ffb6650e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d2579278ad63ae481f08bb022c2e6431c68f9de", "width": 1080, "height": 567}], "variants": {}, "id": "ndZwAoSaFctC86zbw47jMQBn9QlgS4xmui9p9CBDPoo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1nzfr4k", "is_robot_indexable": true, "report_reasons": null, "author": "ExplorAI", "discussion_type": null, "num_comments": 6, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nzfr4k/exploratory_analysis_of_12_frontier_llms_across/", "stickied": false, "url": "https://theaidigest.org/village/blog/village-in-numbers", "subreddit_subscribers": 2695443, "created_utc": 1759747939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 06 Oct, 2025 - 13 Oct, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nz94dg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759723299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nz94dg", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 21, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nz94dg/weekly_entering_transitioning_thread_06_oct_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nz94dg/weekly_entering_transitioning_thread_06_oct_2025/", "subreddit_subscribers": 2695443, "created_utc": 1759723299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As mentioned before, I can't use the weekly transition because it doesn't allow pictures. I appreciate your help last time when I asked. I've implemented your recommendations but I'm still not getting responses. I've added a completely new ML-based project, fixed mistakes, revamped the layout and I'm still not getting anything. I appreciate your attention.\n\nhttps://preview.redd.it/u7bbf3q5vatf1.png?width=666&amp;format=png&amp;auto=webp&amp;s=8d6983cb5e8713b1b8b736f95b916ee52fb0dc21\n\n  \n", "author_fullname": "t2_2wzu5n8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why am I not getting responses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u7bbf3q5vatf1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 153, "x": 108, "u": "https://preview.redd.it/u7bbf3q5vatf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5719c267374f3229aaf858ee220e4bf98213cae"}, {"y": 307, "x": 216, "u": "https://preview.redd.it/u7bbf3q5vatf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ee2bc05d6d57418639d18e209c29dfa5ba24c37"}, {"y": 455, "x": 320, "u": "https://preview.redd.it/u7bbf3q5vatf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9421f74b5558971fe44cc97b6d40918e4b55686"}, {"y": 910, "x": 640, "u": "https://preview.redd.it/u7bbf3q5vatf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f075cf8062c53b885aca4e3e37f244641787dd8"}], "s": {"y": 947, "x": 666, "u": "https://preview.redd.it/u7bbf3q5vatf1.png?width=666&amp;format=png&amp;auto=webp&amp;s=8d6983cb5e8713b1b8b736f95b916ee52fb0dc21"}, "id": "u7bbf3q5vatf1"}}, "name": "t3_1nyp1uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nU0EV6uki1a5UbSvS6OzhQ_C0fktALAdfu6pZ1tyQ20.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759672989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As mentioned before, I can&amp;#39;t use the weekly transition because it doesn&amp;#39;t allow pictures. I appreciate your help last time when I asked. I&amp;#39;ve implemented your recommendations but I&amp;#39;m still not getting responses. I&amp;#39;ve added a completely new ML-based project, fixed mistakes, revamped the layout and I&amp;#39;m still not getting anything. I appreciate your attention.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/u7bbf3q5vatf1.png?width=666&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d6983cb5e8713b1b8b736f95b916ee52fb0dc21\"&gt;https://preview.redd.it/u7bbf3q5vatf1.png?width=666&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d6983cb5e8713b1b8b736f95b916ee52fb0dc21&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nyp1uw", "is_robot_indexable": true, "report_reasons": null, "author": "KyronAWF", "discussion_type": null, "num_comments": 82, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nyp1uw/why_am_i_not_getting_responses/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nyp1uw/why_am_i_not_getting_responses/", "subreddit_subscribers": 2695443, "created_utc": 1759672989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm 26 years old been working as a junior data scientist in marketing for the past two years and I'm a bit bored/ have no idea how to progress further in my career.\n\nCurrently I do end to end modeling, from gathering data up to production (not in the most data sciency way since I'm very limited in terms of tools but my models are being effectively used by other departments). \n\nI have built 5 different models: propensity score models, customer segmentation, churn models and a time series forecasting model.\n\nAll my job has been revolving around developing, validating, monitoring and updating these models I have built with the current tools I have available.\n\nI realise I'm already privileged in terms of what I'm doing. It's my first job and already developing models end to end in a company that recognises their usefulness and I'm pretty much free to take any decision about them.\n\nHowever, I would love to advance further since the my job is starting to get a bit repetitive.\nIn terms of innovating further my workflow I realised it's actually pretty much impossible. The company IT is stagnant and any time I asked for anything, like introducing MlFlow in my sagemaker flow (YES, from development to \"production\" is done in sagemaker using notebooks. I understand and have faced many of the problems that come out of this) or Airflow or anything else, the request has never gotten anywhere.\nThe size of the company and the IT privileges setup makes it impossible for me to take the innovation in my own hands and do as I please. I've tried lots of technical workarounds and loopholes but not very successfully.\n\n\nI don't feel confident enough now take a more senior position, nor there is the possibility at my current job. My boss is not directly involved in modeling stuff and don't really have anyone I can go to with career progression questions.\n\nI feel like I kinda already reached the end of progression and I'm pretty much lost in terms of what I can do, other than ask for various tools to make the pipeline up to current standards (which will not have an impact in terms of how the output will be used by other departments and profits).\n\nI understand it's an open ended question, but what else could I do to advance?", "author_fullname": "t2_eft8kpoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What could be my next career progression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nxrrcw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759578186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m 26 years old been working as a junior data scientist in marketing for the past two years and I&amp;#39;m a bit bored/ have no idea how to progress further in my career.&lt;/p&gt;\n\n&lt;p&gt;Currently I do end to end modeling, from gathering data up to production (not in the most data sciency way since I&amp;#39;m very limited in terms of tools but my models are being effectively used by other departments). &lt;/p&gt;\n\n&lt;p&gt;I have built 5 different models: propensity score models, customer segmentation, churn models and a time series forecasting model.&lt;/p&gt;\n\n&lt;p&gt;All my job has been revolving around developing, validating, monitoring and updating these models I have built with the current tools I have available.&lt;/p&gt;\n\n&lt;p&gt;I realise I&amp;#39;m already privileged in terms of what I&amp;#39;m doing. It&amp;#39;s my first job and already developing models end to end in a company that recognises their usefulness and I&amp;#39;m pretty much free to take any decision about them.&lt;/p&gt;\n\n&lt;p&gt;However, I would love to advance further since the my job is starting to get a bit repetitive.\nIn terms of innovating further my workflow I realised it&amp;#39;s actually pretty much impossible. The company IT is stagnant and any time I asked for anything, like introducing MlFlow in my sagemaker flow (YES, from development to &amp;quot;production&amp;quot; is done in sagemaker using notebooks. I understand and have faced many of the problems that come out of this) or Airflow or anything else, the request has never gotten anywhere.\nThe size of the company and the IT privileges setup makes it impossible for me to take the innovation in my own hands and do as I please. I&amp;#39;ve tried lots of technical workarounds and loopholes but not very successfully.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t feel confident enough now take a more senior position, nor there is the possibility at my current job. My boss is not directly involved in modeling stuff and don&amp;#39;t really have anyone I can go to with career progression questions.&lt;/p&gt;\n\n&lt;p&gt;I feel like I kinda already reached the end of progression and I&amp;#39;m pretty much lost in terms of what I can do, other than ask for various tools to make the pipeline up to current standards (which will not have an impact in terms of how the output will be used by other departments and profits).&lt;/p&gt;\n\n&lt;p&gt;I understand it&amp;#39;s an open ended question, but what else could I do to advance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nxrrcw", "is_robot_indexable": true, "report_reasons": null, "author": "Gaston154", "discussion_type": null, "num_comments": 50, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nxrrcw/what_could_be_my_next_career_progression/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nxrrcw/what_could_be_my_next_career_progression/", "subreddit_subscribers": 2695443, "created_utc": 1759578186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I need to do a project using many linear models and I\u2019m looking for a dataset. Ideally something interesting with lots of numerical variables, especially one where kriging could be applied.\n\nIf you have any dataset suggestions or interesting research questions I could build the project around, I\u2019d really appreciate it. Thanks a lot!\n\nPS: i did not like chatgpt suggestions, they were cliche (even if i explicitly asked \u201cnot cliche\u201d)", "author_fullname": "t2_42f6j4fc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you know interesting datasets for kriging?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nxqln5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759574296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I need to do a project using many linear models and I\u2019m looking for a dataset. Ideally something interesting with lots of numerical variables, especially one where kriging could be applied.&lt;/p&gt;\n\n&lt;p&gt;If you have any dataset suggestions or interesting research questions I could build the project around, I\u2019d really appreciate it. Thanks a lot!&lt;/p&gt;\n\n&lt;p&gt;PS: i did not like chatgpt suggestions, they were cliche (even if i explicitly asked \u201cnot cliche\u201d)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nxqln5", "is_robot_indexable": true, "report_reasons": null, "author": "FinalRide7181", "discussion_type": null, "num_comments": 10, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nxqln5/do_you_know_interesting_datasets_for_kriging/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nxqln5/do_you_know_interesting_datasets_for_kriging/", "subreddit_subscribers": 2695443, "created_utc": 1759574296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For someone laid off in 2023 before the LLM/Agent craze went mainstream, do you think I need to learn LLM architecture? Are certs or github projects worth anything as far as getting through the filters and/or landing a job?  \n\nI have 10 YOE. I specialized in machine learning at the start, but the last 5 years of employment, I was at a FAANG company and didnt directly own any ML stuff. It seems \"traditional\" ML demand, especially without LLM knowledge, is almost zero. I've had some interviews for roles focused on experimentation, but no offers.    \nI can't tell whether my previous experience is irrelevant now. I deployed \"deep\" learning pipelines with basic MLOps. I did a lot of predictive analytics, segmentation, and data exploration with ML.  \n\nI understand the landscape and tech OK, but it seems like every job description now says you need direct experience with agentic frameworks, developing/optimizing/tuning LLMs, and using orchestration frameworks or advanced MLOps. I don't see how DS could have changed enough in two years that every candidate has on-the-job experience with this now.  \n\nIt seems like actually getting confident with the full stack/architecture would take a 6 month course or cert. Ive tried shorter trainings and free content... and it seems like everyone is just learning \"prompt engineering,\" basic RAG with agents, and building chatbots without investigating the underlying architecture at all.  \n\nAre the job descriptions misrepresenting the level of skill needed or am I just out of the loop?", "author_fullname": "t2_ewem7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are LLMs necessary to get a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nwh00i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759441380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For someone laid off in 2023 before the LLM/Agent craze went mainstream, do you think I need to learn LLM architecture? Are certs or github projects worth anything as far as getting through the filters and/or landing a job?  &lt;/p&gt;\n\n&lt;p&gt;I have 10 YOE. I specialized in machine learning at the start, but the last 5 years of employment, I was at a FAANG company and didnt directly own any ML stuff. It seems &amp;quot;traditional&amp;quot; ML demand, especially without LLM knowledge, is almost zero. I&amp;#39;ve had some interviews for roles focused on experimentation, but no offers.&lt;br/&gt;\nI can&amp;#39;t tell whether my previous experience is irrelevant now. I deployed &amp;quot;deep&amp;quot; learning pipelines with basic MLOps. I did a lot of predictive analytics, segmentation, and data exploration with ML.  &lt;/p&gt;\n\n&lt;p&gt;I understand the landscape and tech OK, but it seems like every job description now says you need direct experience with agentic frameworks, developing/optimizing/tuning LLMs, and using orchestration frameworks or advanced MLOps. I don&amp;#39;t see how DS could have changed enough in two years that every candidate has on-the-job experience with this now.  &lt;/p&gt;\n\n&lt;p&gt;It seems like actually getting confident with the full stack/architecture would take a 6 month course or cert. Ive tried shorter trainings and free content... and it seems like everyone is just learning &amp;quot;prompt engineering,&amp;quot; basic RAG with agents, and building chatbots without investigating the underlying architecture at all.  &lt;/p&gt;\n\n&lt;p&gt;Are the job descriptions misrepresenting the level of skill needed or am I just out of the loop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nwh00i", "is_robot_indexable": true, "report_reasons": null, "author": "br0monium", "discussion_type": null, "num_comments": 65, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nwh00i/are_llms_necessary_to_get_a_job/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nwh00i/are_llms_necessary_to_get_a_job/", "subreddit_subscribers": 2695443, "created_utc": 1759441380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had the opportunity to interview Jason Strimpel.  He's been in trading and technology for 25 years as a hedge fund trader, risk quant, machine learning engineering manager, and GenAI specialist at AWS. He is now the Managing Director of AI and Advanced Analytics at a major consulting company.\u00a0\n\nI asked him all about the transferable skills, the mindset shifts, tools someone should pick up if they're just getting started, how algo trading is similar to ML, and differences in how you think about/work with the data. He had a lot of great tips if you're a data person thinking about getting into trading.", "author_fullname": "t2_r1qpqza", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fun Interview with Jason Strimpel about transferable skills from data science to algorithmic trading.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1nvduc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=1127dd5b979085fa763f6bd45adaeb1f88d1fd9e", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1759338056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datamovesme.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had the opportunity to interview Jason Strimpel.  He&amp;#39;s been in trading and technology for 25 years as a hedge fund trader, risk quant, machine learning engineering manager, and GenAI specialist at AWS. He is now the Managing Director of AI and Advanced Analytics at a major consulting company.\u00a0&lt;/p&gt;\n\n&lt;p&gt;I asked him all about the transferable skills, the mindset shifts, tools someone should pick up if they&amp;#39;re just getting started, how algo trading is similar to ML, and differences in how you think about/work with the data. He had a lot of great tips if you&amp;#39;re a data person thinking about getting into trading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datamovesme.com/blog/qfe2cds9h37bdmvi8h4a7p0x785ic9", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?auto=webp&amp;s=285236c549d8badb45f0068df33c7690ad5f6bf7", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=898fd0dd7a28dc7a1b0ff525ff8c6cd7f98f4f63", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f6122961448417789a97db393e20390d9c98891", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f887a569af7b97749430b2aec4a41d023eb8757", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c87debbe0d50a895e27c13139cb06c01bb79ea25", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e88339592405f3ae34f5f8992d74d283e9b375c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7fe909550d41774c42875d63dcb0564ab2b9fcbe", "width": 1080, "height": 567}], "variants": {}, "id": "joHIwgAfbC_VuZ3JWO5n5kMtSr4xLD3dT4H6L75mFA8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nvduc2", "is_robot_indexable": true, "report_reasons": null, "author": "Clicketrie", "discussion_type": null, "num_comments": 6, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nvduc2/fun_interview_with_jason_strimpel_about/", "stickied": false, "url": "https://www.datamovesme.com/blog/qfe2cds9h37bdmvi8h4a7p0x785ic9", "subreddit_subscribers": 2695443, "created_utc": 1759338056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to get a better sense of how this is developing in financial services. Anything from insurance/banking or adjacent fields would be most appreciated.", "author_fullname": "t2_lorcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For data scientists in insurance and banking, how many data scientists/ML engineers work in your company, how are their teams organised, and roughly what do they work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nv0lfh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "", "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "seniorflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759299041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a better sense of how this is developing in financial services. Anything from insurance/banking or adjacent fields would be most appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "PhD | Data Scientist | Insurance", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nv0lfh", "is_robot_indexable": true, "report_reasons": null, "author": "geebr", "discussion_type": null, "num_comments": 28, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/1nv0lfh/for_data_scientists_in_insurance_and_banking_how/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nv0lfh/for_data_scientists_in_insurance_and_banking_how/", "subreddit_subscribers": 2695443, "created_utc": 1759299041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Fun side project. You can configure (almost) any LLM as a player. The main capabilities (tools) each agent can call are:\n\n1) Hand Analysis\nGet detailed info about current hand and possibilities (straight draws, flush potential, many other things)\n\n2) Monte Carlo\nGet an estimated win probability if the player continues in the hand (can only be called one time per hand)\n\n3) Opponent Statistics\nGet metrics about opponent behavior, specifically how aggressive or passively they\u2019ve played\n\nIt\u2019s not a completely novel - other people have made LLMs play poker. The configurability and the specific callable tools are, to my knowledge, unique. Using it requires an OpenRouter API key.\n\n\nVideo:\nhttps://youtu.be/1PDo6-tcWfE?si=WR-vgYtmlksKCAm4\n\nCode:\nhttps://github.com/OlivierNDO/llm_poker_agents\n\n", "author_fullname": "t2_1o5ny9hbpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekend Project - Poker Agents Video/Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_1nucvgd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cUv6QCgRgCgM4PARTT0HK36jkqViyYF9U2V103HVGII.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1759238037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fun side project. You can configure (almost) any LLM as a player. The main capabilities (tools) each agent can call are:&lt;/p&gt;\n\n&lt;p&gt;1) Hand Analysis\nGet detailed info about current hand and possibilities (straight draws, flush potential, many other things)&lt;/p&gt;\n\n&lt;p&gt;2) Monte Carlo\nGet an estimated win probability if the player continues in the hand (can only be called one time per hand)&lt;/p&gt;\n\n&lt;p&gt;3) Opponent Statistics\nGet metrics about opponent behavior, specifically how aggressive or passively they\u2019ve played&lt;/p&gt;\n\n&lt;p&gt;It\u2019s not a completely novel - other people have made LLMs play poker. The configurability and the specific callable tools are, to my knowledge, unique. Using it requires an OpenRouter API key.&lt;/p&gt;\n\n&lt;p&gt;Video:\n&lt;a href=\"https://youtu.be/1PDo6-tcWfE?si=WR-vgYtmlksKCAm4\"&gt;https://youtu.be/1PDo6-tcWfE?si=WR-vgYtmlksKCAm4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Code:\n&lt;a href=\"https://github.com/OlivierNDO/llm_poker_agents\"&gt;https://github.com/OlivierNDO/llm_poker_agents&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hqdrczgwxasf1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?auto=webp&amp;s=cb5f2a0712b71f6ae1d1e890c00ac5abe066c6e6", "width": 1230, "height": 912}, "resolutions": [{"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0df61fe26830a1e15f3636b9ce5e6e2f1e3d1d62", "width": 108, "height": 80}, {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=326c07c86a0ef186d5be23d3f9254228b87994d4", "width": 216, "height": 160}, {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19bdf041d09eea697d2486117e62aa30e508714d", "width": 320, "height": 237}, {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=26858ed1204544d9af0ed1c6f66265819aef6beb", "width": 640, "height": 474}, {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7491ec13463149c894923ebaf3e9b109eceac21c", "width": 960, "height": 711}, {"url": "https://preview.redd.it/hqdrczgwxasf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd9b97fb5c3320e7698dc3c5a3e44049f10a49ca", "width": 1080, "height": 800}], "variants": {}, "id": "BQvRJ9dTdpNMuuBR6eUEy3iD-BPmmQhGcQB-YeV0NaI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nucvgd", "is_robot_indexable": true, "report_reasons": null, "author": "MLEngDelivers", "discussion_type": null, "num_comments": 17, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nucvgd/weekend_project_poker_agents_videocode/", "stickied": false, "url": "https://i.redd.it/hqdrczgwxasf1.jpeg", "subreddit_subscribers": 2695443, "created_utc": 1759238037.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distance Correlation &amp; Matrix Association. Good stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nurg0y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_37d28", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskStatistics", "selftext": "Sz\u00e9kely and Rizzo\u2019s work is so good. Their 2007 paper writing was excellent and super useful in terms of measuring association via distances and powerful as 0 distance correlation establishes statistical independence. The Euclidean distance requirement was a bit iffy but their follow up work with Partial Distance Correlation 2014 blew my mind because it becomes a non-factor.\n\nTheir U-Centering mechanism (analogous to matrix double centering) is absolutely brilliant and accessible to a more quantitative social scientist like me. Their unbiased sample statistic, which is similar to a cosine similarity measure, is based on Hilbert Spaces where the association measure is invariant to adding a constant to vector inputs (doesn\u2019t have to be the same for each input). So if you take any symmetric dissimilarity matrix and ucenter it, there\u2019s an equivalent Euclidean embedding that after ucentering it is equivalent to the ucentered version of the original dissimilarity matrix. So you don\u2019t need to make your dissimilarity Euclidean anymore. It works because you can take any symmetric dissimilarity matrix and add a constant to make it Euclidean: see Lingoes and others.\n\nAnyhow, I feel like this method is not getting the attention it deserves because it\u2019s published under partial distance correlation. But the unbiased estimator is general and powerful stuff. Maybe I\u2019m missing something though.\n\nPardon my terminology and use. It\u2019s not technically precise but I\u2019m typing from my phone on my walk.\n\n", "author_fullname": "t2_37d28", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distance Correlation &amp; Matrix Association. Good stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskStatistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nurfk1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759271677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskStatistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sz\u00e9kely and Rizzo\u2019s work is so good. Their 2007 paper writing was excellent and super useful in terms of measuring association via distances and powerful as 0 distance correlation establishes statistical independence. The Euclidean distance requirement was a bit iffy but their follow up work with Partial Distance Correlation 2014 blew my mind because it becomes a non-factor.&lt;/p&gt;\n\n&lt;p&gt;Their U-Centering mechanism (analogous to matrix double centering) is absolutely brilliant and accessible to a more quantitative social scientist like me. Their unbiased sample statistic, which is similar to a cosine similarity measure, is based on Hilbert Spaces where the association measure is invariant to adding a constant to vector inputs (doesn\u2019t have to be the same for each input). So if you take any symmetric dissimilarity matrix and ucenter it, there\u2019s an equivalent Euclidean embedding that after ucentering it is equivalent to the ucentered version of the original dissimilarity matrix. So you don\u2019t need to make your dissimilarity Euclidean anymore. It works because you can take any symmetric dissimilarity matrix and add a constant to make it Euclidean: see Lingoes and others.&lt;/p&gt;\n\n&lt;p&gt;Anyhow, I feel like this method is not getting the attention it deserves because it\u2019s published under partial distance correlation. But the unbiased estimator is general and powerful stuff. Maybe I\u2019m missing something though.&lt;/p&gt;\n\n&lt;p&gt;Pardon my terminology and use. It\u2019s not technically precise but I\u2019m typing from my phone on my walk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sioa", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nurfk1", "is_robot_indexable": true, "report_reasons": null, "author": "uSeeEsBee", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskStatistics/comments/1nurfk1/distance_correlation_matrix_association_good_stuff/", "stickied": false, "url": "https://www.reddit.com/r/AskStatistics/comments/1nurfk1/distance_correlation_matrix_association_good_stuff/", "subreddit_subscribers": 120656, "created_utc": 1759271677.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1759271709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/AskStatistics/comments/1nurfk1/distance_correlation_matrix_association_good_stuff/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nurg0y", "is_robot_indexable": true, "report_reasons": null, "author": "uSeeEsBee", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1nurfk1", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nurg0y/distance_correlation_matrix_association_good_stuff/", "stickied": false, "url": "/r/AskStatistics/comments/1nurfk1/distance_correlation_matrix_association_good_stuff/", "subreddit_subscribers": 2695443, "created_utc": 1759271709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "recruitment companies posting jobs like this are just setting bait to get resumes so they can push other jobs right?", "author_fullname": "t2_a74red5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This has to be bait right?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ntmrix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 192, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 192, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/En9ow-X2zDCYaVMBTOkcGmtciS2V9q3ZgUP16lCT2JM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1759163512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;recruitment companies posting jobs like this are just setting bait to get resumes so they can push other jobs right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/o7gh03w4s4sf1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?auto=webp&amp;s=07442c291dc790c3341860615d0ec877f2069de6", "width": 1179, "height": 1409}, "resolutions": [{"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95302936fe5f316a1d961b023a98dcd19b5bee18", "width": 108, "height": 129}, {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb4c5a5e2b26e7ab80597833bb0b9c16826298d1", "width": 216, "height": 258}, {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd6e8f2849bab00583172dad36549af8f5850a68", "width": 320, "height": 382}, {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=103833feaacf62f7706e9202466c9a8cc1b48956", "width": 640, "height": 764}, {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a48eb39830f0d3a2bb4964e47bf4df7d8836eab9", "width": 960, "height": 1147}, {"url": "https://preview.redd.it/o7gh03w4s4sf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=84adbc2e3ce10829d0f6f3a805823c4ab7617db3", "width": 1080, "height": 1290}], "variants": {}, "id": "UbT5xEzAlubzwA6EHE5Q6fabXqzKezAFfPhdfPFw1U4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ntmrix", "is_robot_indexable": true, "report_reasons": null, "author": "ds_throw", "discussion_type": null, "num_comments": 55, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ntmrix/this_has_to_be_bait_right/", "stickied": false, "url": "https://i.redd.it/o7gh03w4s4sf1.jpeg", "subreddit_subscribers": 2695443, "created_utc": 1759163512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Honestly, GLM 4.6 might be my favorite LLM right now. I threw it a messy, real-world coding project, full front-end build, 20+ components, custom data transformations, and a bunch of steps that normally require me to constantly keep track of what\u2019s happening. With older models like GLM 4.5 and even the latest Claude 4.5 Sonnet, I\u2019d be juggling context limits, cleaning up messy outputs, and basically babysitting the process.\n\nGLM 4.6? It handled everything smoothly. Remembered the full context, generated clean code, even suggested little improvements I hadn\u2019t thought of. Multi-step workflows that normally get confusing were just\u2026 done. And it did all that using fewer tokens than 4.5, so it\u2019s faster and cheaper too.\n\nLoved the new release [Z.ai](http://Z.ai)", "author_fullname": "t2_th2ct5t8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GLM 4.6 is the BEST CODING LLM. Period.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nv6wv8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.07, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759321922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Honestly, GLM 4.6 might be my favorite LLM right now. I threw it a messy, real-world coding project, full front-end build, 20+ components, custom data transformations, and a bunch of steps that normally require me to constantly keep track of what\u2019s happening. With older models like GLM 4.5 and even the latest Claude 4.5 Sonnet, I\u2019d be juggling context limits, cleaning up messy outputs, and basically babysitting the process.&lt;/p&gt;\n\n&lt;p&gt;GLM 4.6? It handled everything smoothly. Remembered the full context, generated clean code, even suggested little improvements I hadn\u2019t thought of. Multi-step workflows that normally get confusing were just\u2026 done. And it did all that using fewer tokens than 4.5, so it\u2019s faster and cheaper too.&lt;/p&gt;\n\n&lt;p&gt;Loved the new release &lt;a href=\"http://Z.ai\"&gt;Z.ai&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1nv6wv8", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Love-8479", "discussion_type": null, "num_comments": 13, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nv6wv8/glm_46_is_the_best_coding_llm_period/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nv6wv8/glm_46_is_the_best_coding_llm_period/", "subreddit_subscribers": 2695443, "created_utc": 1759321922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI think I need a little general guidance on how to move forward.  After working in retail for 11 years, I went back to school in 2020 to do a Bachelor\u2019s in Mathematics and a masters in analytics.  I was hoping to become a data scientist upon graduating.  Obviously, market conditions have fluctuated substantially since I started.  \n\nI took a job as a materials planner in electronics manufacturing, with the expectation that my boss was looking for someone that was data minded and would primarily focus on building pipelines and tools to make things run more smoothly.   my planning duties would be small while I used my skills to automate and streamline workflows.  Up to this point, my job has been about 70 percent coding and \u201cdata engineering/analyzing\u201d, 20 percent managing and organizing my projects, and 10 percent actual materials planning.\n\nI think my boss made a risky hire.  He\u2019s not an IT person, and has not been able to move the needle on giving me the access I need to scale these processes.  I found an old reporting tool that is basically SQL that nobody uses: have been able to install VS code on my work laptop, so I have been able to  substantially streamline, dashboard, and improve a ton of stuff using Python, \u201cSQL\u201d, and PowerQuery.\n\nThey pulled my access to the reporting tool: no advance communication.  All of my projects are pretty much kaput.  I feel like I\u2019ve been lowballed big time.  I\u2019m glad to have a job right now, but also I\u2019m in a bit of a predicament.  If my job search went on for another 6 months, most employers in actual \u201cdata\u201d roles would understand the struggle: and I might even have an actual role in data analytics right now, if I got lucky.  But now I am in a position that is a huge departure from what was discussed.  No matter the situation, leaving after only 6 months would look terrible one me.  It seems like the best thing to do is ride it out, but I\u2019m not sure or for how long I should. ", "author_fullname": "t2_4vgawwho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ntlgy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759160584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I think I need a little general guidance on how to move forward.  After working in retail for 11 years, I went back to school in 2020 to do a Bachelor\u2019s in Mathematics and a masters in analytics.  I was hoping to become a data scientist upon graduating.  Obviously, market conditions have fluctuated substantially since I started.  &lt;/p&gt;\n\n&lt;p&gt;I took a job as a materials planner in electronics manufacturing, with the expectation that my boss was looking for someone that was data minded and would primarily focus on building pipelines and tools to make things run more smoothly.   my planning duties would be small while I used my skills to automate and streamline workflows.  Up to this point, my job has been about 70 percent coding and \u201cdata engineering/analyzing\u201d, 20 percent managing and organizing my projects, and 10 percent actual materials planning.&lt;/p&gt;\n\n&lt;p&gt;I think my boss made a risky hire.  He\u2019s not an IT person, and has not been able to move the needle on giving me the access I need to scale these processes.  I found an old reporting tool that is basically SQL that nobody uses: have been able to install VS code on my work laptop, so I have been able to  substantially streamline, dashboard, and improve a ton of stuff using Python, \u201cSQL\u201d, and PowerQuery.&lt;/p&gt;\n\n&lt;p&gt;They pulled my access to the reporting tool: no advance communication.  All of my projects are pretty much kaput.  I feel like I\u2019ve been lowballed big time.  I\u2019m glad to have a job right now, but also I\u2019m in a bit of a predicament.  If my job search went on for another 6 months, most employers in actual \u201cdata\u201d roles would understand the struggle: and I might even have an actual role in data analytics right now, if I got lucky.  But now I am in a position that is a huge departure from what was discussed.  No matter the situation, leaving after only 6 months would look terrible one me.  It seems like the best thing to do is ride it out, but I\u2019m not sure or for how long I should. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ntlgy5", "is_robot_indexable": true, "report_reasons": null, "author": "rmb91896", "discussion_type": null, "num_comments": 11, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ntlgy5/career_advice/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1ntlgy5/career_advice/", "subreddit_subscribers": 2695443, "created_utc": 1759160584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Autocorrelation &amp; The Random Walk explained** with a drunk man \ud83c\udf7a\n\nLet me illustrate this statistical concept with an example we can all visualize.\n\nImagine a drunk man wandering a city. His steps are completely random and unpredictable.\n\n**Here's the intuition**:\n\n\\- His current position is completely tied to his previous position\n\n\\- We know where he is RIGHT NOW, but have no idea where he'll be in the next minute\n\n**The statistical insight**:\n\nIn a random walk, the *current position* is highly correlated with the *previous position*, but the *changes in position* (the steps) are completely random &amp; uncorrelated.\n\n\n\nThis is why random walks are so tricky to forecast!\n\n[Part 2: Time Series Forecasting: Build a Baseline &amp; Understand the Random Walk](https://youtu.be/_Ke54TJqY9s) \n\n  \nWould love to hear your\u00a0**thoughts, feedback** about this topic", "author_fullname": "t2_owdeq6tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What a Drunk Man Can Teach Us About Time Series Forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nt8wl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1759120285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Autocorrelation &amp;amp; The Random Walk explained&lt;/strong&gt; with a drunk man \ud83c\udf7a&lt;/p&gt;\n\n&lt;p&gt;Let me illustrate this statistical concept with an example we can all visualize.&lt;/p&gt;\n\n&lt;p&gt;Imagine a drunk man wandering a city. His steps are completely random and unpredictable.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s the intuition&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;- His current position is completely tied to his previous position&lt;/p&gt;\n\n&lt;p&gt;- We know where he is RIGHT NOW, but have no idea where he&amp;#39;ll be in the next minute&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The statistical insight&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;In a random walk, the &lt;em&gt;current position&lt;/em&gt; is highly correlated with the &lt;em&gt;previous position&lt;/em&gt;, but the &lt;em&gt;changes in position&lt;/em&gt; (the steps) are completely random &amp;amp; uncorrelated.&lt;/p&gt;\n\n&lt;p&gt;This is why random walks are so tricky to forecast!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/_Ke54TJqY9s\"&gt;Part 2: Time Series Forecasting: Build a Baseline &amp;amp; Understand the Random Walk&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Would love to hear your\u00a0&lt;strong&gt;thoughts, feedback&lt;/strong&gt; about this topic&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yvBiT58HXlA1QJMSLnltiWLIeF0K6o1MUxMfMb90WUM.jpeg?auto=webp&amp;s=b70030b3f16dab6fe4f17b51faf896b7c622b3c7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yvBiT58HXlA1QJMSLnltiWLIeF0K6o1MUxMfMb90WUM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=822d77216d8f5a399d09414afcf3cec97088fb2d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yvBiT58HXlA1QJMSLnltiWLIeF0K6o1MUxMfMb90WUM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9687c32858f2206757aac6b44f3292b671d10630", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yvBiT58HXlA1QJMSLnltiWLIeF0K6o1MUxMfMb90WUM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=30c05a830be9ddf09f8639ce84dd43472ed25505", "width": 320, "height": 240}], "variants": {}, "id": "yvBiT58HXlA1QJMSLnltiWLIeF0K6o1MUxMfMb90WUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1nt8wl0", "is_robot_indexable": true, "report_reasons": null, "author": "The_Simpsons_22", "discussion_type": null, "num_comments": 12, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nt8wl0/what_a_drunk_man_can_teach_us_about_time_series/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nt8wl0/what_a_drunk_man_can_teach_us_about_time_series/", "subreddit_subscribers": 2695443, "created_utc": 1759120285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Share links if possible.", "author_fullname": "t2_y6wjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What interesting projects are you working on that are not related to AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nt6q59", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759113264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Share links if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nt6q59", "is_robot_indexable": true, "report_reasons": null, "author": "yaymayhun", "discussion_type": null, "num_comments": 38, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nt6q59/what_interesting_projects_are_you_working_on_that/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nt6q59/what_interesting_projects_are_you_working_on_that/", "subreddit_subscribers": 2695443, "created_utc": 1759113264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 29 Sep, 2025 - 06 Oct, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nt8d65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759118483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nt8d65", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 16, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nt8d65/weekly_entering_transitioning_thread_29_sep_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nt8d65/weekly_entering_transitioning_thread_29_sep_2025/", "subreddit_subscribers": 2695443, "created_utc": 1759118483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Heya, I been studying the gains curve, and I\u2019ve noticed there\u2019s a relationship between the gains curve and ROC curve the smaller the base rate the closer is gains curve is to ROC curve. Anyway onto the point, is if fair to assume that for two models if the area under the ROC curve is bigger for model A and then the gains curve will always be better for model A as well?\n Thanks ", "author_fullname": "t2_2fwzqpwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relationship between ROC AUC and Gain curve?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nso6sy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759065654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya, I been studying the gains curve, and I\u2019ve noticed there\u2019s a relationship between the gains curve and ROC curve the smaller the base rate the closer is gains curve is to ROC curve. Anyway onto the point, is if fair to assume that for two models if the area under the ROC curve is bigger for model A and then the gains curve will always be better for model A as well?\n Thanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "1nso6sy", "is_robot_indexable": true, "report_reasons": null, "author": "Emergency-Agreeable", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nso6sy/relationship_between_roc_auc_and_gain_curve/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nso6sy/relationship_between_roc_auc_and_gain_curve/", "subreddit_subscribers": 2695443, "created_utc": 1759065654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been working in AI since before it was cool (think 80s expert systems, not ChatGPT hype). Lately I've been developing this cognitive architecture called OGI that uses Top-K gating between specialized modules. Works well, proved the stability, got the complexity down to O(k\u00b2). But something's been bugging me about the whole approach.\nThe central routing feels... inelegant. Like we're forcing a fundamentally parallel, distributed process through a computational bottleneck. Your brain doesn't have a little scheduler deciding when your visual cortex can talk to your language areas.\nSo I've been diving back into some old neuroscience papers on neural oscillations. Turns out biological neural networks coordinate through phase-locking across different frequency bands - gamma for local binding, theta for memory consolidation, alpha for attention. No central controller needed.\nThe Math That's Getting Me Excited\nStarted modeling cognitive modules as weakly coupled oscillators. Each module i has intrinsic frequency \u03c9\u1d62 and phase \u03b8\u1d62(t), with dynamics:\n\u03b8\u0307\u1d62 = \u03c9\u1d62 + \u03a3\u2c7c A\u1d62\u2c7c sin(\u03b8\u2c7c - \u03b8\u1d62 + \u03b1\u1d62\u2c7c)\nThis is just Kuramoto model with adaptive coupling strengths A\u1d62\u2c7c and phase lags \u03b1\u1d62\u2c7c that encode computational dependencies. When |\u03c9\u1d62 - \u03c9\u2c7c| falls below critical coupling threshold, modules naturally phase-lock and start coordinating.\nThe order parameter R(t) = |\u03a3\u2c7c e^(i\u03b8\u2c7c)|/N gives you a continuous measure of how synchronized the whole system is. Instead of discrete routing decisions, you get smooth phase relationships that preserve gradient flow.\nWhy This Might Actually Work\nThree big advantages I'm seeing:\n\nScalability: Communication cost scales with active phase-locked clusters, not total modules. For sparse coupling graphs, this could be near-linear.\nRobustness: Lyapunov analysis suggests exponential convergence to stable states. System naturally self-corrects.\nTemporal Multiplexing: Different frequency bands can carry orthogonal information streams without interference. Massive bandwidth increase.\n\nThe Hard Problems\nObviously the devil's in the details. How do you encode actual computational information in phase relationships? How do you learn the coupling matrix A(t)? Probably need some variant of Hebbian plasticity, but the specifics matter.\nThe inverse problem is fascinating though - given desired computational dependencies, what coupling topology produces the right synchronization patterns? Starting to look like optimal transport theory applied to dynamical systems.\nBigger Picture\nMaybe we've been thinking about AI architecture wrong. Instead of discrete computational graphs, what if cognition is fundamentally about temporal organization of information flow? The binding problem, consciousness, unified experience - could all emerge from phase coherence mathematics.\nI know this sounds hand-wavy, but the math is solid. Kuramoto theory is well-established, neural oscillations are real, and the computational advantages are compelling.\nAnyone worked on similar problems? Particularly interested in numerical integration schemes for large coupled oscillator networks and learning rules for adaptive coupling.\n\nEdit: For those asking about implementation - yes, this requires continuous dynamics instead of discrete updates. Computationally more expensive per step, but potentially fewer steps needed due to natural coordination. Still working out the trade-offs.\n\nEdit 2: Getting DMs about biological plausibility. Obviously artificial oscillators don't need to match neural firing rates exactly. The key insight is coordination through phase relationships, not literal biological mimicry.\n\nMike ", "author_fullname": "t2_5bbf5g6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oscillatory Coordination in Cognitive Architectures: Old Dog, New Math", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nsxpad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1759088818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working in AI since before it was cool (think 80s expert systems, not ChatGPT hype). Lately I&amp;#39;ve been developing this cognitive architecture called OGI that uses Top-K gating between specialized modules. Works well, proved the stability, got the complexity down to O(k\u00b2). But something&amp;#39;s been bugging me about the whole approach.\nThe central routing feels... inelegant. Like we&amp;#39;re forcing a fundamentally parallel, distributed process through a computational bottleneck. Your brain doesn&amp;#39;t have a little scheduler deciding when your visual cortex can talk to your language areas.\nSo I&amp;#39;ve been diving back into some old neuroscience papers on neural oscillations. Turns out biological neural networks coordinate through phase-locking across different frequency bands - gamma for local binding, theta for memory consolidation, alpha for attention. No central controller needed.\nThe Math That&amp;#39;s Getting Me Excited\nStarted modeling cognitive modules as weakly coupled oscillators. Each module i has intrinsic frequency \u03c9\u1d62 and phase \u03b8\u1d62(t), with dynamics:\n\u03b8\u0307\u1d62 = \u03c9\u1d62 + \u03a3\u2c7c A\u1d62\u2c7c sin(\u03b8\u2c7c - \u03b8\u1d62 + \u03b1\u1d62\u2c7c)\nThis is just Kuramoto model with adaptive coupling strengths A\u1d62\u2c7c and phase lags \u03b1\u1d62\u2c7c that encode computational dependencies. When |\u03c9\u1d62 - \u03c9\u2c7c| falls below critical coupling threshold, modules naturally phase-lock and start coordinating.\nThe order parameter R(t) = |\u03a3\u2c7c e&lt;sup&gt;i\u03b8\u2c7c&lt;/sup&gt;|/N gives you a continuous measure of how synchronized the whole system is. Instead of discrete routing decisions, you get smooth phase relationships that preserve gradient flow.\nWhy This Might Actually Work\nThree big advantages I&amp;#39;m seeing:&lt;/p&gt;\n\n&lt;p&gt;Scalability: Communication cost scales with active phase-locked clusters, not total modules. For sparse coupling graphs, this could be near-linear.\nRobustness: Lyapunov analysis suggests exponential convergence to stable states. System naturally self-corrects.\nTemporal Multiplexing: Different frequency bands can carry orthogonal information streams without interference. Massive bandwidth increase.&lt;/p&gt;\n\n&lt;p&gt;The Hard Problems\nObviously the devil&amp;#39;s in the details. How do you encode actual computational information in phase relationships? How do you learn the coupling matrix A(t)? Probably need some variant of Hebbian plasticity, but the specifics matter.\nThe inverse problem is fascinating though - given desired computational dependencies, what coupling topology produces the right synchronization patterns? Starting to look like optimal transport theory applied to dynamical systems.\nBigger Picture\nMaybe we&amp;#39;ve been thinking about AI architecture wrong. Instead of discrete computational graphs, what if cognition is fundamentally about temporal organization of information flow? The binding problem, consciousness, unified experience - could all emerge from phase coherence mathematics.\nI know this sounds hand-wavy, but the math is solid. Kuramoto theory is well-established, neural oscillations are real, and the computational advantages are compelling.\nAnyone worked on similar problems? Particularly interested in numerical integration schemes for large coupled oscillator networks and learning rules for adaptive coupling.&lt;/p&gt;\n\n&lt;p&gt;Edit: For those asking about implementation - yes, this requires continuous dynamics instead of discrete updates. Computationally more expensive per step, but potentially fewer steps needed due to natural coordination. Still working out the trade-offs.&lt;/p&gt;\n\n&lt;p&gt;Edit 2: Getting DMs about biological plausibility. Obviously artificial oscillators don&amp;#39;t need to match neural firing rates exactly. The key insight is coordination through phase relationships, not literal biological mimicry.&lt;/p&gt;\n\n&lt;p&gt;Mike &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nsxpad", "is_robot_indexable": true, "report_reasons": null, "author": "Efficient-Hovercraft", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nsxpad/oscillatory_coordination_in_cognitive/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nsxpad/oscillatory_coordination_in_cognitive/", "subreddit_subscribers": 2695443, "created_utc": 1759088818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI'm a Data Analyst, but I'm really interested in the whole data science world. For my current job, I don't need to be an expert in machine learning, deep learning, or data engineering, but I've been trying to learn the basics anyway.\n\nI feel like even a basic understanding helps me out in a few ways:\n\n* Better Problem-Solving: It helps me choose the right tool for the job and come up with better solutions.\n* Deeper Analysis: I can push my analyses further and ask more interesting questions.\n* Smoother Communication: It makes talking to data scientists and engineers on my team way easier because I kinda \"get\" what they're doing.\n\nPlus, I've noticed that just learning one new library or concept makes picking up the next one a lot less intimidating.\n\nWhat do you all think? Should Data Analysts just stick to getting really good at core analytics (SQL, stats, viz), or is there a real advantage to becoming more of a \"T-shaped\" person with a broad base of knowledge?\n\nCurious to hear your experiences.", "author_fullname": "t2_1w40m9mrr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is it for a Data Analyst to learn some ML, Data Engineering, and DL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nrtluz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 107, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758974994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a Data Analyst, but I&amp;#39;m really interested in the whole data science world. For my current job, I don&amp;#39;t need to be an expert in machine learning, deep learning, or data engineering, but I&amp;#39;ve been trying to learn the basics anyway.&lt;/p&gt;\n\n&lt;p&gt;I feel like even a basic understanding helps me out in a few ways:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Better Problem-Solving: It helps me choose the right tool for the job and come up with better solutions.&lt;/li&gt;\n&lt;li&gt;Deeper Analysis: I can push my analyses further and ask more interesting questions.&lt;/li&gt;\n&lt;li&gt;Smoother Communication: It makes talking to data scientists and engineers on my team way easier because I kinda &amp;quot;get&amp;quot; what they&amp;#39;re doing.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Plus, I&amp;#39;ve noticed that just learning one new library or concept makes picking up the next one a lot less intimidating.&lt;/p&gt;\n\n&lt;p&gt;What do you all think? Should Data Analysts just stick to getting really good at core analytics (SQL, stats, viz), or is there a real advantage to becoming more of a &amp;quot;T-shaped&amp;quot; person with a broad base of knowledge?&lt;/p&gt;\n\n&lt;p&gt;Curious to hear your experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nrtluz", "is_robot_indexable": true, "report_reasons": null, "author": "DeepAnalyze", "discussion_type": null, "num_comments": 45, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nrtluz/how_important_is_it_for_a_data_analyst_to_learn/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nrtluz/how_important_is_it_for_a_data_analyst_to_learn/", "subreddit_subscribers": 2695443, "created_utc": 1758974994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve had up to 10 recruiters contact me in the last few weeks. Before this I hadn\u2019t heard anything but crickets for years. Anyone else noticing more outreach lately? Note that I\u2019m a US citizen but the outreach starts before the H1B news so I don\u2019t think it\u2019s related to that. ", "author_fullname": "t2_hyi3nd0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone noticing an uptick in recruiter outreach?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nri84g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758935134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve had up to 10 recruiters contact me in the last few weeks. Before this I hadn\u2019t heard anything but crickets for years. Anyone else noticing more outreach lately? Note that I\u2019m a US citizen but the outreach starts before the H1B news so I don\u2019t think it\u2019s related to that. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nri84g", "is_robot_indexable": true, "report_reasons": null, "author": "BB_147", "discussion_type": null, "num_comments": 55, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nri84g/anyone_noticing_an_uptick_in_recruiter_outreach/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nri84g/anyone_noticing_an_uptick_in_recruiter_outreach/", "subreddit_subscribers": 2695443, "created_utc": 1758935134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone I\u2019m sharing\u00a0**Week Bites**, a series of\u00a0**light, digestible videos on data science**. Each week, I cover\u00a0**key concepts, practical techniques, and industry insights**\u00a0in short, easy-to-watch videos.\n\n1. [Where Data Scientists Find Free Datasets (Beyond Kaggle)](https://youtu.be/HR1sDaZOMDI) Authentic datasets that are clustered between research datasets, government datasets, massive-sized datasets that fit TF and PyTorch projects.\n2. [Time Series Forecasting in Python (Practical Guide)](https://youtu.be/Y7KCMaBDeDM) Starting from the fundamentals supported by source code available in the video description\n3. [Causal Inference Comprehensive Guide](https://youtu.be/40wIk7FSxdM) This area seems tricky a little, and I've started a series to halp intertwine causal inference into our AI models.\n\nWould love to hear your\u00a0**thoughts, feedback, and topic suggestions**! Let me know which topics you find most useful", "author_fullname": "t2_owdeq6tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Week Bites: Weekly Dose of Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nrla6h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1758944693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone I\u2019m sharing\u00a0&lt;strong&gt;Week Bites&lt;/strong&gt;, a series of\u00a0&lt;strong&gt;light, digestible videos on data science&lt;/strong&gt;. Each week, I cover\u00a0&lt;strong&gt;key concepts, practical techniques, and industry insights&lt;/strong&gt;\u00a0in short, easy-to-watch videos.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/HR1sDaZOMDI\"&gt;Where Data Scientists Find Free Datasets (Beyond Kaggle)&lt;/a&gt; Authentic datasets that are clustered between research datasets, government datasets, massive-sized datasets that fit TF and PyTorch projects.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/Y7KCMaBDeDM\"&gt;Time Series Forecasting in Python (Practical Guide)&lt;/a&gt; Starting from the fundamentals supported by source code available in the video description&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/40wIk7FSxdM\"&gt;Causal Inference Comprehensive Guide&lt;/a&gt; This area seems tricky a little, and I&amp;#39;ve started a series to halp intertwine causal inference into our AI models.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would love to hear your\u00a0&lt;strong&gt;thoughts, feedback, and topic suggestions&lt;/strong&gt;! Let me know which topics you find most useful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P3H41ZUdISJF0n6dukQcHmz--h_6oRaDIfU5lv0m300.jpeg?auto=webp&amp;s=d523e289f04bbd14e79417f4a16e8963fe756cfd", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/P3H41ZUdISJF0n6dukQcHmz--h_6oRaDIfU5lv0m300.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17af1d7373e56845278f2f695a303be73b68f95f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/P3H41ZUdISJF0n6dukQcHmz--h_6oRaDIfU5lv0m300.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3b3e79efafe72be6b83b4ba51503774f647ff72", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/P3H41ZUdISJF0n6dukQcHmz--h_6oRaDIfU5lv0m300.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e7de074ee045791357365fb8854e2391a0a64ba", "width": 320, "height": 240}], "variants": {}, "id": "P3H41ZUdISJF0n6dukQcHmz--h_6oRaDIfU5lv0m300"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1nrla6h", "is_robot_indexable": true, "report_reasons": null, "author": "The_Simpsons_22", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nrla6h/week_bites_weekly_dose_of_data_science/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nrla6h/week_bites_weekly_dose_of_data_science/", "subreddit_subscribers": 2695443, "created_utc": 1758944693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently was accepted to the UC Berkeley MIDS program, but I'm a bit conflicted as to whether I should accept the offer. A little bit about me: I just got my bachelors in data science and economics this past May from Berkeley as well, and I'm starting a job as a data scientist this month at a medium sized company. My goal is to become a data scientist, and a lot of people have advised me to do a data science master's since it's so competitive nowadays. My plan originally was to do the master's along with my job, but I'm a bit worried about the time commitment. Even though the people in my company say we have a chill 9-5 culture, the MIDS program will require 20-30 hours of work for the first semester because everyone is required to take 2 classes in the beginning. That means I'll have to work 60+ hours a week, at least during the first semester, although I'm not sure how accurate this time commitment is, since I already have coding experience from my bachelor's. Another thing I'm worried about is cost. Berkeley MIDS costs 67k for me (original was 80k+ but I got a scholarship). Even though I'm lucky enough to have my parents' financial support, I still hate for them to spend so much money. I also applied to UPenn's MSE-DS program, which is not as good as Berkeley's but it's significantly cheaper (38k), but I won't know the results until November, and I'm hoping to get back to Berkeley before then. Should I just not do a masters until several years down the line, or should I decline Berkeley and wait for UPenn's results? What's my best course of action? Thank you \ud83d\ude4f", "author_fullname": "t2_5jb10tgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I enroll in UC Berkeley MIDS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nr8iu0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1758910444.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758910123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently was accepted to the UC Berkeley MIDS program, but I&amp;#39;m a bit conflicted as to whether I should accept the offer. A little bit about me: I just got my bachelors in data science and economics this past May from Berkeley as well, and I&amp;#39;m starting a job as a data scientist this month at a medium sized company. My goal is to become a data scientist, and a lot of people have advised me to do a data science master&amp;#39;s since it&amp;#39;s so competitive nowadays. My plan originally was to do the master&amp;#39;s along with my job, but I&amp;#39;m a bit worried about the time commitment. Even though the people in my company say we have a chill 9-5 culture, the MIDS program will require 20-30 hours of work for the first semester because everyone is required to take 2 classes in the beginning. That means I&amp;#39;ll have to work 60+ hours a week, at least during the first semester, although I&amp;#39;m not sure how accurate this time commitment is, since I already have coding experience from my bachelor&amp;#39;s. Another thing I&amp;#39;m worried about is cost. Berkeley MIDS costs 67k for me (original was 80k+ but I got a scholarship). Even though I&amp;#39;m lucky enough to have my parents&amp;#39; financial support, I still hate for them to spend so much money. I also applied to UPenn&amp;#39;s MSE-DS program, which is not as good as Berkeley&amp;#39;s but it&amp;#39;s significantly cheaper (38k), but I won&amp;#39;t know the results until November, and I&amp;#39;m hoping to get back to Berkeley before then. Should I just not do a masters until several years down the line, or should I decline Berkeley and wait for UPenn&amp;#39;s results? What&amp;#39;s my best course of action? Thank you \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1nr8iu0", "is_robot_indexable": true, "report_reasons": null, "author": "ExcitingCommission5", "discussion_type": null, "num_comments": 34, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nr8iu0/should_i_enroll_in_uc_berkeley_mids/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nr8iu0/should_i_enroll_in_uc_berkeley_mids/", "subreddit_subscribers": 2695443, "created_utc": 1758910123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_12kon3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback on My Data Science CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ns18vu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.35, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9B4e-ZYi-IFB5nG2fdOHbiSj5mlQfTsDm0gDJPEZZoE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758994620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4z80agbvtqrf1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?auto=webp&amp;s=67be8ee41394f4bf643b2546e237504c8ddba916", "width": 1224, "height": 1584}, "resolutions": [{"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f9bb2238a1b00e05c366b615c3aed06e41fd87c", "width": 108, "height": 139}, {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9853f680c2fd3a845f84afa84207b81acb9a5c6", "width": 216, "height": 279}, {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b68d66506f1914012a17788265455eebedaaf10", "width": 320, "height": 414}, {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ace7f0484f8645aaff8f2df2802f9be54d1eaa2", "width": 640, "height": 828}, {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7565cef2f00337758d350b877742e7000a86fbbc", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/4z80agbvtqrf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c56d39c39812dda427198acf0b79e1e0a5f20ce", "width": 1080, "height": 1397}], "variants": {}, "id": "ez4rxigDbNRkE3ztOsk5i-ZZOUJSMhK50AWMcZue4OA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ns18vu", "is_robot_indexable": true, "report_reasons": null, "author": "telperion101", "discussion_type": null, "num_comments": 10, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ns18vu/seeking_feedback_on_my_data_science_cv/", "stickied": false, "url": "https://i.redd.it/4z80agbvtqrf1.jpeg", "subreddit_subscribers": 2695443, "created_utc": 1758994620.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1rer4n1ivg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your Boss Is Faking Their Way Through AI Adoption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1nqcu82", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 208, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 208, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=e5185c5c0e5eddfb94a95bfbfacf615a73a3f0d6", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758820978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "interviewquery.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.interviewquery.com/p/ai-leadership-fake-promises", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?auto=webp&amp;s=e795886eb6017b1c2b09b48b427d872bc7449cbf", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e03159e5933d7981154867be81538edea6a54738", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b632ff93ce13d73522aacd05db7a78f2995da0af", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91637cc55207e52d3832ae58cc3352cbd50747ae", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=55b8d7e067cbeb73fff6c3016326476672bb5f83", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5c7525cdfefbacc90e50515dc08918024b95d2c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=74accb01bd9b65d07d9ae333d1f8a1951e927c7a", "width": 1080, "height": 607}], "variants": {}, "id": "za86DIoRwY61cIWykokMTxZMV6sObpcGbmMFOJcS9mw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nqcu82", "is_robot_indexable": true, "report_reasons": null, "author": "nullstillstands", "discussion_type": null, "num_comments": 52, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nqcu82/your_boss_is_faking_their_way_through_ai_adoption/", "stickied": false, "url": "https://www.interviewquery.com/p/ai-leadership-fake-promises", "subreddit_subscribers": 2695443, "created_utc": 1758820978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Questions like:\n\n* *\u201cHow do you approach building a model?\u201d*\n* *\u201cWhat metrics would you look at to evaluate success?\u201d*\n* *\u201cHow would you handle missing data?\u201d*\n* *\u201cHow do you decide between different algorithms?\u201d*\n\netc etc\n\n  \nWhere its highly dependent on context and it feels like no matter how much you qualify your answers with justifications, you never really know if it's the right answer.\n\nFor some of these there are decent, generic answers but it really does seem like it's up to the interviewer to determine whether they like the answer you give \n\n", "author_fullname": "t2_a74red5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm still not sure how to answer vague DS questions...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nq8hi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758811004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Questions like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;\u201cHow do you approach building a model?\u201d&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;\u201cWhat metrics would you look at to evaluate success?\u201d&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;\u201cHow would you handle missing data?\u201d&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;\u201cHow do you decide between different algorithms?\u201d&lt;/em&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;etc etc&lt;/p&gt;\n\n&lt;p&gt;Where its highly dependent on context and it feels like no matter how much you qualify your answers with justifications, you never really know if it&amp;#39;s the right answer.&lt;/p&gt;\n\n&lt;p&gt;For some of these there are decent, generic answers but it really does seem like it&amp;#39;s up to the interviewer to determine whether they like the answer you give &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nq8hi5", "is_robot_indexable": true, "report_reasons": null, "author": "ds_throw", "discussion_type": null, "num_comments": 40, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nq8hi5/im_still_not_sure_how_to_answer_vague_ds_questions/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nq8hi5/im_still_not_sure_how_to_answer_vague_ds_questions/", "subreddit_subscribers": 2695443, "created_utc": 1758811004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "FYI - If you are considering an analytics job at PNC Bank, they are moving to 5 days in office.  It's now being required for senior managers, and will trickle down to individual contributors in the new year.", "author_fullname": "t2_712qz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PNC Bank Moving To 5 Days In Office", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1npq7ty", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758753303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;FYI - If you are considering an analytics job at PNC Bank, they are moving to 5 days in office.  It&amp;#39;s now being required for senior managers, and will trickle down to individual contributors in the new year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1npq7ty", "is_robot_indexable": true, "report_reasons": null, "author": "random_user_fp", "discussion_type": null, "num_comments": 35, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1npq7ty/pnc_bank_moving_to_5_days_in_office/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1npq7ty/pnc_bank_moving_to_5_days_in_office/", "subreddit_subscribers": 2695443, "created_utc": 1758753303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working on a university project and want to predict the next day's closing price of a stock. I am using a foundation model for time series based on the transformer architecture (decoder only).\n\nSince I have no touchpoints with the practical procedures of the industry I was asking myself what the best prediction performance, especially directional accuracy (\"stock will go up/down tomorrow\") is. I am currently able to achieve 59% accuracy only.\n\nAny practical insights? Thank you!", "author_fullname": "t2_571s6v5b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the state-of-the-art prediction performance for the stock market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nqwcip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.28, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758877133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working on a university project and want to predict the next day&amp;#39;s closing price of a stock. I am using a foundation model for time series based on the transformer architecture (decoder only).&lt;/p&gt;\n\n&lt;p&gt;Since I have no touchpoints with the practical procedures of the industry I was asking myself what the best prediction performance, especially directional accuracy (&amp;quot;stock will go up/down tomorrow&amp;quot;) is. I am currently able to achieve 59% accuracy only.&lt;/p&gt;\n\n&lt;p&gt;Any practical insights? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1nqwcip", "is_robot_indexable": true, "report_reasons": null, "author": "Poxput", "discussion_type": null, "num_comments": 53, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nqwcip/what_is_the_stateoftheart_prediction_performance/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nqwcip/what_is_the_stateoftheart_prediction_performance/", "subreddit_subscribers": 2695443, "created_utc": 1758877133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I'm a PhD candidate in CS, currently starting to interview for industry jobs. I had an interview earlier this week for a research scientist job that I was hoping to get an outside perspective on - I'm pretty new to technical interviewing and there don't seem to be many online resources about what interviewers expectations are going to be for more probability-style questions. I was not selected for a next round of interviews based on my performance, and that's at odds with my self-assessment and with the affect and demeanor of the interviewer. \n\n  \n**The Interview Questions:** A question asking about probabilistic decay of N particles (over discrete time steps, known probability), and was asked to derive the probability that all particles would decay by a certain time. Then, I was asked to write a simulation of this scenario, and get point estimates, variance &amp;c. Lastly, I was asked about a variation where I would estimate the probability, given observed counts. \n\n  \n**My Performance:** I correctly characterized the problem as a Binomial(N,p) problem, where p is the probability that a single particle survives till time T. I did not get a closed form solution (I asked about how I did at the end and the interviewer mentioned that it would have been nice to get one). The code I wrote was correct, and I think fairly efficient? I got a little bit hung up on trying to estimate variance, but ended up with a bootstrap approach. We ran out of time before I could entirely solve the last variation, but generally described an approach. I felt that my interviewer and I had decent rapport, and it seemed like I did decently. \n\n  \n**Question:** Overall, I'd like to know what I did wrong, though of course that's probably not possible without someone sitting in. I did talk throughout, and I have struggled with clear and concise verbal communication in the past. Was the expectation that I would solve all parts of the questions completely? What aspects of these interviews do interviewers tend to look for?", "author_fullname": "t2_4356d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expectations for probability questions in interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nphgwl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758732803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m a PhD candidate in CS, currently starting to interview for industry jobs. I had an interview earlier this week for a research scientist job that I was hoping to get an outside perspective on - I&amp;#39;m pretty new to technical interviewing and there don&amp;#39;t seem to be many online resources about what interviewers expectations are going to be for more probability-style questions. I was not selected for a next round of interviews based on my performance, and that&amp;#39;s at odds with my self-assessment and with the affect and demeanor of the interviewer. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Interview Questions:&lt;/strong&gt; A question asking about probabilistic decay of N particles (over discrete time steps, known probability), and was asked to derive the probability that all particles would decay by a certain time. Then, I was asked to write a simulation of this scenario, and get point estimates, variance &amp;amp;c. Lastly, I was asked about a variation where I would estimate the probability, given observed counts. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Performance:&lt;/strong&gt; I correctly characterized the problem as a Binomial(N,p) problem, where p is the probability that a single particle survives till time T. I did not get a closed form solution (I asked about how I did at the end and the interviewer mentioned that it would have been nice to get one). The code I wrote was correct, and I think fairly efficient? I got a little bit hung up on trying to estimate variance, but ended up with a bootstrap approach. We ran out of time before I could entirely solve the last variation, but generally described an approach. I felt that my interviewer and I had decent rapport, and it seemed like I did decently. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; Overall, I&amp;#39;d like to know what I did wrong, though of course that&amp;#39;s probably not possible without someone sitting in. I did talk throughout, and I have struggled with clear and concise verbal communication in the past. Was the expectation that I would solve all parts of the questions completely? What aspects of these interviews do interviewers tend to look for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nphgwl", "is_robot_indexable": true, "report_reasons": null, "author": "gforce121", "discussion_type": null, "num_comments": 16, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nphgwl/expectations_for_probability_questions_in/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nphgwl/expectations_for_probability_questions_in/", "subreddit_subscribers": 2695443, "created_utc": 1758732803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nThese past weeks I've been working on an R and Python package (called rixpress and ryxpress respectively) which aim to make it easy to build multilanguage projects by using Nix as the underlying build tool.\n\nryxpress is a Python port of the R package `{rixpress}`, both in early development and they let you define data pipelines in R (with helpers for Python steps), build them reproducibly using Nix, and then inspect, read, or load artifacts from Python.\n\nIf you're familiar with the `{targets}` R package, this is very similar.\n\nIt\u2019s designed to provide a smoother experience for those working in polyglot environments (Python, R, Julia and even Quarto/Markdown for reports) where reproducibility and cross-language workflows matter.\n\nPipelines are defined in R, but the artifacts can be explored and loaded in Python, opening up easy interoperability for teams or projects using both languages.\n\nIt uses Nix as the underyling build tool, so you get the power of Nix for dependency management, but can work in Python for artifact inspection and downstream tasks.\n\nHere is a basic definition of a pipeline:\n\n```\nlibrary(rixpress)\n\nlist(\n  rxp_py_file(\n    name = mtcars_pl,\n    path = 'https://raw.githubusercontent.com/b-rodrigues/rixpress_demos/refs/heads/master/basic_r/data/mtcars.csv',\n    read_function = \"lambda x: polars.read_csv(x, separator='|')\"\n  ),\n\n  rxp_py(\n    name = mtcars_pl_am,\n    expr = \"mtcars_pl.filter(polars.col('am') == 1)\",\n    user_functions = \"functions.py\",\n    encoder = \"serialize_to_json\",\n  ),\n\n  rxp_r(\n    name = mtcars_head,\n    expr = my_head(mtcars_pl_am),\n    user_functions = \"functions.R\",\n    decoder = \"jsonlite::fromJSON\"\n  ),\n\n  rxp_r(\n    name = mtcars_mpg,\n    expr = dplyr::select(mtcars_head, mpg)\n  )\n) |&gt;\n  rxp_populate(project_path = \".\")\n```\n\nIt's R code, but as explained, you can build it from Python and explore build artifacts from Python as well. You'll also need to define the \"execution environment\" in which this pipeline is supposed to run, using Nix as well.\n\nryxpress is on PyPI, but you\u2019ll need Nix (and R + {rixpress}) installed. See the [GitHub repo](https://github.com/b-rodrigues/ryxpress) for quickstart instructions and environment setup.\n\nWould love feedback, questions, or ideas for improvements! If you\u2019re interested in reproducible, multi-language pipelines, give it a try.", "author_fullname": "t2_f7t22oxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing ryxpress: Reproducible Polyglot Analytical Pipelines with Nix (Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nq1bj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758789079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;These past weeks I&amp;#39;ve been working on an R and Python package (called rixpress and ryxpress respectively) which aim to make it easy to build multilanguage projects by using Nix as the underlying build tool.&lt;/p&gt;\n\n&lt;p&gt;ryxpress is a Python port of the R package &lt;code&gt;{rixpress}&lt;/code&gt;, both in early development and they let you define data pipelines in R (with helpers for Python steps), build them reproducibly using Nix, and then inspect, read, or load artifacts from Python.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re familiar with the &lt;code&gt;{targets}&lt;/code&gt; R package, this is very similar.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s designed to provide a smoother experience for those working in polyglot environments (Python, R, Julia and even Quarto/Markdown for reports) where reproducibility and cross-language workflows matter.&lt;/p&gt;\n\n&lt;p&gt;Pipelines are defined in R, but the artifacts can be explored and loaded in Python, opening up easy interoperability for teams or projects using both languages.&lt;/p&gt;\n\n&lt;p&gt;It uses Nix as the underyling build tool, so you get the power of Nix for dependency management, but can work in Python for artifact inspection and downstream tasks.&lt;/p&gt;\n\n&lt;p&gt;Here is a basic definition of a pipeline:&lt;/p&gt;\n\n&lt;p&gt;```\nlibrary(rixpress)&lt;/p&gt;\n\n&lt;p&gt;list(\n  rxp_py_file(\n    name = mtcars_pl,\n    path = &amp;#39;&lt;a href=\"https://raw.githubusercontent.com/b-rodrigues/rixpress_demos/refs/heads/master/basic_r/data/mtcars.csv\"&gt;https://raw.githubusercontent.com/b-rodrigues/rixpress_demos/refs/heads/master/basic_r/data/mtcars.csv&lt;/a&gt;&amp;#39;,\n    read_function = &amp;quot;lambda x: polars.read_csv(x, separator=&amp;#39;|&amp;#39;)&amp;quot;\n  ),&lt;/p&gt;\n\n&lt;p&gt;rxp_py(\n    name = mtcars_pl_am,\n    expr = &amp;quot;mtcars_pl.filter(polars.col(&amp;#39;am&amp;#39;) == 1)&amp;quot;,\n    user_functions = &amp;quot;functions.py&amp;quot;,\n    encoder = &amp;quot;serialize_to_json&amp;quot;,\n  ),&lt;/p&gt;\n\n&lt;p&gt;rxp_r(\n    name = mtcars_head,\n    expr = my_head(mtcars_pl_am),\n    user_functions = &amp;quot;functions.R&amp;quot;,\n    decoder = &amp;quot;jsonlite::fromJSON&amp;quot;\n  ),&lt;/p&gt;\n\n&lt;p&gt;rxp_r(\n    name = mtcars_mpg,\n    expr = dplyr::select(mtcars_head, mpg)\n  )\n) |&amp;gt;\n  rxp_populate(project_path = &amp;quot;.&amp;quot;)\n```&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s R code, but as explained, you can build it from Python and explore build artifacts from Python as well. You&amp;#39;ll also need to define the &amp;quot;execution environment&amp;quot; in which this pipeline is supposed to run, using Nix as well.&lt;/p&gt;\n\n&lt;p&gt;ryxpress is on PyPI, but you\u2019ll need Nix (and R + {rixpress}) installed. See the &lt;a href=\"https://github.com/b-rodrigues/ryxpress\"&gt;GitHub repo&lt;/a&gt; for quickstart instructions and environment setup.&lt;/p&gt;\n\n&lt;p&gt;Would love feedback, questions, or ideas for improvements! If you\u2019re interested in reproducible, multi-language pipelines, give it a try.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nq1bj4", "is_robot_indexable": true, "report_reasons": null, "author": "brodrigues_co", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nq1bj4/introducing_ryxpress_reproducible_polyglot/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nq1bj4/introducing_ryxpress_reproducible_polyglot/", "subreddit_subscribers": 2695443, "created_utc": 1758789079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do new analysts often ignore R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1nnvss1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2477, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1fd2qzwbqh", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 2477, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XrSzf15QwCNaMQ5PiLYRvSUZ2e7sfTJrGLzzvwLKKCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AnalyticsMemes", "selftext": "Maybe unfairly. I've really never used it personally. I took a course and then never really had a use case that I couldn't already cover with Python. \n\nWhat about you?", "author_fullname": "t2_1fd2qzwbqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R often gets ignored...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AnalyticsMemes", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1nn7svb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 187, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 187, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XrSzf15QwCNaMQ5PiLYRvSUZ2e7sfTJrGLzzvwLKKCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1758499610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe unfairly. I&amp;#39;ve really never used it personally. I took a course and then never really had a use case that I couldn&amp;#39;t already cover with Python. &lt;/p&gt;\n\n&lt;p&gt;What about you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/18swici6ylqf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/18swici6ylqf1.png?auto=webp&amp;s=45794834796e5696aa391fee44aa80979d1decc6", "width": 1080, "height": 1266}, "resolutions": [{"url": "https://preview.redd.it/18swici6ylqf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=702e30f34d676dd6e0dc6080f512b28bac0442d7", "width": 108, "height": 126}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=41613ad3186d4332053dcde8ab65d055d26731b6", "width": 216, "height": 253}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eab545e4b19178b385daadad4d784503b8c90e28", "width": 320, "height": 375}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e759a8dc3256088106a492d1ec8eb378c7ddf30", "width": 640, "height": 750}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b047b6abe244a1c1e9a65c3cf47de2cfc21b0a0", "width": 960, "height": 1125}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5e5d8a17a0812c483becc34b7bb8b6949aa1aa16", "width": 1080, "height": 1266}], "variants": {}, "id": "uOXIulAeRziUrYkq9DPN-prvvegYj4K3x5A_93s8sxE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_ezgh0k", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nn7svb", "is_robot_indexable": true, "report_reasons": null, "author": "ElectrikMetriks", "discussion_type": null, "num_comments": 45, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AnalyticsMemes/comments/1nn7svb/r_often_gets_ignored/", "stickied": false, "url": "https://i.redd.it/18swici6ylqf1.png", "subreddit_subscribers": 938, "created_utc": 1758499610.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1758568716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/18swici6ylqf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/18swici6ylqf1.png?auto=webp&amp;s=45794834796e5696aa391fee44aa80979d1decc6", "width": 1080, "height": 1266}, "resolutions": [{"url": "https://preview.redd.it/18swici6ylqf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=702e30f34d676dd6e0dc6080f512b28bac0442d7", "width": 108, "height": 126}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=41613ad3186d4332053dcde8ab65d055d26731b6", "width": 216, "height": 253}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eab545e4b19178b385daadad4d784503b8c90e28", "width": 320, "height": 375}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e759a8dc3256088106a492d1ec8eb378c7ddf30", "width": 640, "height": 750}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b047b6abe244a1c1e9a65c3cf47de2cfc21b0a0", "width": 960, "height": 1125}, {"url": "https://preview.redd.it/18swici6ylqf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5e5d8a17a0812c483becc34b7bb8b6949aa1aa16", "width": 1080, "height": 1266}], "variants": {}, "id": "uOXIulAeRziUrYkq9DPN-prvvegYj4K3x5A_93s8sxE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "1nnvss1", "is_robot_indexable": true, "report_reasons": null, "author": "ElectrikMetriks", "discussion_type": null, "num_comments": 289, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1nn7svb", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nnvss1/why_do_new_analysts_often_ignore_r/", "stickied": false, "url": "https://i.redd.it/18swici6ylqf1.png", "subreddit_subscribers": 2695443, "created_utc": 1758568716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When I was a data scientist at Meta, almost 50% of my week went to ad-hoc requests like:\n\n* \u201cCan we break out Marketplace feed engagement for buyers vs sellers?\u201d\n* \u201cDo translation errors spike more in Spanish than French?\u201d\n* \u201cWhat % of teen users in Reality Labs got safety warnings last release?\u201d\n\nEach one was reasonable, but stacked together it turned my entire DS team into human SQL machines.\n\nI\u2019ve been hacking on an MVP that tries to reduce this by letting the DS define a domain once (metrics, definitions, gotchas), and then AI handles repetitive questions transparently (always shows SQL + assumptions).\n\nNot trying to pitch, just genuinely curious if others have felt the same pain, and how you\u2019ve dealt with it. If you want to see what I\u2019m working on, here\u2019s the landing page: [www.takeoutforteams.com](http://www.takeoutforteams.com).\n\nWould love any feedback from folks who\u2019ve lived this, especially how your teams currently handle the flood of ad-hoc questions. Because right now there's very little beyond dashboards that let DS scale themselves.", "author_fullname": "t2_h2wdb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ad-hoc questions are the real killer. Curious if others feel this pain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1npfecr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1758728143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was a data scientist at Meta, almost 50% of my week went to ad-hoc requests like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u201cCan we break out Marketplace feed engagement for buyers vs sellers?\u201d&lt;/li&gt;\n&lt;li&gt;\u201cDo translation errors spike more in Spanish than French?\u201d&lt;/li&gt;\n&lt;li&gt;\u201cWhat % of teen users in Reality Labs got safety warnings last release?\u201d&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Each one was reasonable, but stacked together it turned my entire DS team into human SQL machines.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been hacking on an MVP that tries to reduce this by letting the DS define a domain once (metrics, definitions, gotchas), and then AI handles repetitive questions transparently (always shows SQL + assumptions).&lt;/p&gt;\n\n&lt;p&gt;Not trying to pitch, just genuinely curious if others have felt the same pain, and how you\u2019ve dealt with it. If you want to see what I\u2019m working on, here\u2019s the landing page: &lt;a href=\"http://www.takeoutforteams.com\"&gt;www.takeoutforteams.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Would love any feedback from folks who\u2019ve lived this, especially how your teams currently handle the flood of ad-hoc questions. Because right now there&amp;#39;s very little beyond dashboards that let DS scale themselves.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?auto=webp&amp;s=40ad52ac2c2869cf390a7253c5d5d1443cd346d5", "width": 2310, "height": 1234}, "resolutions": [{"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3fa1dc4b9cc59da687f18fbab77468cc93378cd", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=df31d0e4ad7aa14e4cd19eb4d26910fff0d3c1e5", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d127a6e13b5c7277e6e503f2136bf10325e78b83", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=25883e3b50fd30067a7fedd1369dc35d6eb46c62", "width": 640, "height": 341}, {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ab9a488ca9071688c71bae87f84c7a6a9995e30f", "width": 960, "height": 512}, {"url": "https://external-preview.redd.it/JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=130f4aa959eb6de87eb66db55841a5454122bfba", "width": 1080, "height": 576}], "variants": {}, "id": "JVnXjvvLfnu7cK0JXyCLp8OSb4X2ClyIVgkLuxuZXdM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1npfecr", "is_robot_indexable": true, "report_reasons": null, "author": "KyleDrogo", "discussion_type": null, "num_comments": 16, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1npfecr/adhoc_questions_are_the_real_killer_curious_if/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1npfecr/adhoc_questions_are_the_real_killer_curious_if/", "subreddit_subscribers": 2695443, "created_utc": 1758728143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I already have an MS in Statistics and two and a half YoE, but mostly in operations and business-oriented roles. I would like to work more in DS or be able to pivot into engineering. My undergrad was not directly in computer science but I did have significant exposure to AI/ML before LLMs and generative models were mainstream. I don\u2019t have any work experience directly in ML or DS, but my analyst roles over the last few years have been SQL-oriented with some scripting here and there.\n\nIf I wanted to pivot into MLE or DE would it be worth going back to school for an MSCS? I also just generally miss learning and am open to a career pivot, and also have always wanted to try working on research projects (never did it for my MS). I\u2019m leaning towards no and instead just working on relevant certifications, but I want to pivot out of Business Operations or business intelligence roles into more technical teams such as ML teams or product. Internal migration within my own company does not seem possible at the moment.", "author_fullname": "t2_od2ng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a second masters worth it for MLE roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1no5b1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758593240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already have an MS in Statistics and two and a half YoE, but mostly in operations and business-oriented roles. I would like to work more in DS or be able to pivot into engineering. My undergrad was not directly in computer science but I did have significant exposure to AI/ML before LLMs and generative models were mainstream. I don\u2019t have any work experience directly in ML or DS, but my analyst roles over the last few years have been SQL-oriented with some scripting here and there.&lt;/p&gt;\n\n&lt;p&gt;If I wanted to pivot into MLE or DE would it be worth going back to school for an MSCS? I also just generally miss learning and am open to a career pivot, and also have always wanted to try working on research projects (never did it for my MS). I\u2019m leaning towards no and instead just working on relevant certifications, but I want to pivot out of Business Operations or business intelligence roles into more technical teams such as ML teams or product. Internal migration within my own company does not seem possible at the moment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1no5b1j", "is_robot_indexable": true, "report_reasons": null, "author": "ch4nt", "discussion_type": null, "num_comments": 37, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1no5b1j/is_a_second_masters_worth_it_for_mle_roles/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1no5b1j/is_a_second_masters_worth_it_for_mle_roles/", "subreddit_subscribers": 2695443, "created_utc": 1758593240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just updated [my GitHub project Kiln](https://github.com/Kiln-AI/Kiln) **so you can build a RAG system in under 5 minutes**; just drag and drop your documents in. We want it to be the most usable RAG builder, while also offering powerful options for finding the ideal RAG parameters.\n\nHighlights:\n\n* **Easy to get started**: just drop in documents, select a template configuration, and you're up and running in a few minutes.\n* **Highly customizable**: you can customize the document extractor, chunking strategy, embedding model/dimension, and search index (vector/full-text/hybrid). Start simple with one-click templates, but go as deep as you want on tuning/customization.\n* **Document library**: manage documents, tag document sets, preview extractions, sync across your team, and more.\n* **Deep integrations**: evaluate RAG-task performance with our evals, expose RAG as a tool to any tool-compatible model\n* **Local**: the Kiln app runs locally and we can't access your data. The V1 of RAG requires API keys for extraction/embeddings, but we're working on fully-local RAG as we speak; see below for questions about where we should focus.\n\nWe have docs walking through the process: [https://docs.kiln.tech/docs/documents-and-search-rag](https://docs.kiln.tech/docs/documents-and-search-rag)\n\n**Question for you:** V1 has a decent number of options for tuning, but folks are probably going to want more. We\u2019d love suggestions for where to expand first. Options are:\n\n* **Document extraction**: V1 focuses on model-based extractors (Gemini/GPT) as they outperformed library-based extractors (docling, markitdown) in our tests. Which additional models/libraries/configs/APIs would you want? Specific open models? Marker? Docling?\n* **Embedding Models**: We're looking at EmbeddingGemma &amp; Qwen Embedding as open/local options. Any other embedding models people like for RAG?\n* **Chunking**: V1 uses the sentence splitter from llama\\_index. Do folks have preferred semantic chunkers or other chunking strategies?\n* **Vector database**: V1 uses LanceDB for vector, full-text (BM25), and hybrid search. Should we support more? Would folks want Qdrant? Chroma? Weaviate? pg-vector? HNSW tuning parameters?\n* Anything else?\n\nSome links to the repo and guides:\n\n* [Kiln AI on Github - 4k stars](https://github.com/Kiln-AI/Kiln)\n* [Documents &amp; Search (RAG) Docs/Guide](https://docs.kiln.tech/docs/documents-and-search-rag)\n* [Kiln Discord](https://getkiln.ai/discord)\n* [Homepage](https://kiln.tech)\n\nI'm happy to answer questions if anyone wants details or has ideas!!", "author_fullname": "t2_slbscky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New RAG Builder: Create a SOTA RAG system in under 5 minutes. Which models/methods should we add next? [Kiln]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_1nnsvq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Vrk9CpgrHZYhFM8dPXrKyF_UdBNOANN6tufcAKUAl_A.jpg", "edited": 1758562722.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758562227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just updated &lt;a href=\"https://github.com/Kiln-AI/Kiln\"&gt;my GitHub project Kiln&lt;/a&gt; &lt;strong&gt;so you can build a RAG system in under 5 minutes&lt;/strong&gt;; just drag and drop your documents in. We want it to be the most usable RAG builder, while also offering powerful options for finding the ideal RAG parameters.&lt;/p&gt;\n\n&lt;p&gt;Highlights:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Easy to get started&lt;/strong&gt;: just drop in documents, select a template configuration, and you&amp;#39;re up and running in a few minutes.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Highly customizable&lt;/strong&gt;: you can customize the document extractor, chunking strategy, embedding model/dimension, and search index (vector/full-text/hybrid). Start simple with one-click templates, but go as deep as you want on tuning/customization.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Document library&lt;/strong&gt;: manage documents, tag document sets, preview extractions, sync across your team, and more.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Deep integrations&lt;/strong&gt;: evaluate RAG-task performance with our evals, expose RAG as a tool to any tool-compatible model&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Local&lt;/strong&gt;: the Kiln app runs locally and we can&amp;#39;t access your data. The V1 of RAG requires API keys for extraction/embeddings, but we&amp;#39;re working on fully-local RAG as we speak; see below for questions about where we should focus.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We have docs walking through the process: &lt;a href=\"https://docs.kiln.tech/docs/documents-and-search-rag\"&gt;https://docs.kiln.tech/docs/documents-and-search-rag&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question for you:&lt;/strong&gt; V1 has a decent number of options for tuning, but folks are probably going to want more. We\u2019d love suggestions for where to expand first. Options are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Document extraction&lt;/strong&gt;: V1 focuses on model-based extractors (Gemini/GPT) as they outperformed library-based extractors (docling, markitdown) in our tests. Which additional models/libraries/configs/APIs would you want? Specific open models? Marker? Docling?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Embedding Models&lt;/strong&gt;: We&amp;#39;re looking at EmbeddingGemma &amp;amp; Qwen Embedding as open/local options. Any other embedding models people like for RAG?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Chunking&lt;/strong&gt;: V1 uses the sentence splitter from llama_index. Do folks have preferred semantic chunkers or other chunking strategies?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Vector database&lt;/strong&gt;: V1 uses LanceDB for vector, full-text (BM25), and hybrid search. Should we support more? Would folks want Qdrant? Chroma? Weaviate? pg-vector? HNSW tuning parameters?&lt;/li&gt;\n&lt;li&gt;Anything else?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some links to the repo and guides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/Kiln-AI/Kiln\"&gt;Kiln AI on Github - 4k stars&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.kiln.tech/docs/documents-and-search-rag\"&gt;Documents &amp;amp; Search (RAG) Docs/Guide&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://getkiln.ai/discord\"&gt;Kiln Discord&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://kiln.tech\"&gt;Homepage&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m happy to answer questions if anyone wants details or has ideas!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g3qm46cc4rqf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?auto=webp&amp;s=cba8676364b4e3e4f98f7c27aa9bfd11002e769c", "width": 1752, "height": 1494}, "resolutions": [{"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=02601176982215300cceaf48668e40d223e0c255", "width": 108, "height": 92}, {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f5f3b7685625d76bac02904e46ed52921139475", "width": 216, "height": 184}, {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=959164c2fdc51ee64acc9494fd34f67b704c1f64", "width": 320, "height": 272}, {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8408d82ef16bc9d66857954b0a645d46a6fa9bb9", "width": 640, "height": 545}, {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5f8d5466f01d19366d3c35fa68aa3366c50081f9", "width": 960, "height": 818}, {"url": "https://preview.redd.it/g3qm46cc4rqf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f1df13ec8e68f0b958faf57419abbb07327ac71", "width": 1080, "height": 920}], "variants": {}, "id": "UMFnG0K1U0M6NKxBw2cTijWZ6n304Vbf5YCNREuZ0ww"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1nnsvq3", "is_robot_indexable": true, "report_reasons": null, "author": "davernow", "discussion_type": null, "num_comments": 0, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nnsvq3/new_rag_builder_create_a_sota_rag_system_in_under/", "stickied": false, "url": "https://i.redd.it/g3qm46cc4rqf1.png", "subreddit_subscribers": 2695443, "created_utc": 1758562227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We know that in many companies Data Scientists are Product Analytics / Data Analysts. I thought it was because MLEs had absorbed the duties of DSs, but i have noticed that this may not be exactly the case.\n\nThere are basically three distinct roles:\n\t\n1.\tData Analyst / Product Analytics: dashboards, data analysis, A/B testing.\n\t\n2.\tMLE: build machine learning systems for user-facing products (e.g., Stripe\u2019s fraud detection or YouTube\u2019s recommendation algorithm).\n\t\n3.\tDS: use ML and advanced techniques to solve business problems and make forecasts (e.g., sales, growth, churn).\n\nThis last job is not done by MLEs, it has simply been eliminated by some companies in the last few years (but a lot of tech companies still have it).\n\nFor example Stripe used to hire DSs specifically for this function and LinkedIn profiles confirm that those people are still there doing it, but now the new hires consist only of Data Analysts.\n\nIt\u2019s hard to believe that in a world increasingly driven by data, a role focused on predictive decision making would be seen as completely useless.\n\nSo my question is: is this mostly the result of the tech recession? Companies may now prioritize \u201cessential\u201d roles that can be filled at lower costs (Data Analysts) while removing, in this difficult economy, the \u201cluxury\u201d roles (Data Scientists).\n", "author_fullname": "t2_42f6j4fc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it due to the tech recession?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nnfcwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758523574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We know that in many companies Data Scientists are Product Analytics / Data Analysts. I thought it was because MLEs had absorbed the duties of DSs, but i have noticed that this may not be exactly the case.&lt;/p&gt;\n\n&lt;p&gt;There are basically three distinct roles:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data Analyst / Product Analytics: dashboards, data analysis, A/B testing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;MLE: build machine learning systems for user-facing products (e.g., Stripe\u2019s fraud detection or YouTube\u2019s recommendation algorithm).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;DS: use ML and advanced techniques to solve business problems and make forecasts (e.g., sales, growth, churn).&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This last job is not done by MLEs, it has simply been eliminated by some companies in the last few years (but a lot of tech companies still have it).&lt;/p&gt;\n\n&lt;p&gt;For example Stripe used to hire DSs specifically for this function and LinkedIn profiles confirm that those people are still there doing it, but now the new hires consist only of Data Analysts.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s hard to believe that in a world increasingly driven by data, a role focused on predictive decision making would be seen as completely useless.&lt;/p&gt;\n\n&lt;p&gt;So my question is: is this mostly the result of the tech recession? Companies may now prioritize \u201cessential\u201d roles that can be filled at lower costs (Data Analysts) while removing, in this difficult economy, the \u201cluxury\u201d roles (Data Scientists).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nnfcwc", "is_robot_indexable": true, "report_reasons": null, "author": "FinalRide7181", "discussion_type": null, "num_comments": 47, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nnfcwc/is_it_due_to_the_tech_recession/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nnfcwc/is_it_due_to_the_tech_recession/", "subreddit_subscribers": 2695443, "created_utc": 1758523574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a DS with 2YOE (plus about 6 coops). I'm looking for feedback from folks specifically transitioned out of early career and into mid-career phase. (Unfortunately I don't have any in my immediate network)\n\nContext: I'm coming upto 2 years in my role and have been seriously evaluating the next stage of my career.\n\nQuestions:\n1. Does having a decent resume land you your next role, or even for a mid-level role do you need to network extensively i.e. what's the most optimal method for this stage of career progression.\n\n2. Most of the work I've done so far has been POC-based i.e. we find business problems and work with teams to create MVPs. Its been an interesting experience as I get to experiment with different methods and almost derive the solution from scratch, without having to worry too much about MLE/MLOps. Does this kind of work exist at this next Intermediate level? And will this kind of role even exist into the future?\n\n3. How do you decide between being able to climb up the ladder in your current company? Or switch to a different industry, maybe one that aligns more with your passion/interests, but also risk losing all of that \"capital\" you've invested into in the current company?\n\nApologies if this is a bit all over the place,  but it was a little tough getting my thoughts across.\n\nAlso would love if anyone is down to discuss more in detail on dm, if that's preferred.\n\nThanks a lot!", "author_fullname": "t2_2e9a4qox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need input from mid-career dara Scientists (2-5 year range)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nncgka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758513393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DS with 2YOE (plus about 6 coops). I&amp;#39;m looking for feedback from folks specifically transitioned out of early career and into mid-career phase. (Unfortunately I don&amp;#39;t have any in my immediate network)&lt;/p&gt;\n\n&lt;p&gt;Context: I&amp;#39;m coming upto 2 years in my role and have been seriously evaluating the next stage of my career.&lt;/p&gt;\n\n&lt;p&gt;Questions:\n1. Does having a decent resume land you your next role, or even for a mid-level role do you need to network extensively i.e. what&amp;#39;s the most optimal method for this stage of career progression.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Most of the work I&amp;#39;ve done so far has been POC-based i.e. we find business problems and work with teams to create MVPs. Its been an interesting experience as I get to experiment with different methods and almost derive the solution from scratch, without having to worry too much about MLE/MLOps. Does this kind of work exist at this next Intermediate level? And will this kind of role even exist into the future?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you decide between being able to climb up the ladder in your current company? Or switch to a different industry, maybe one that aligns more with your passion/interests, but also risk losing all of that &amp;quot;capital&amp;quot; you&amp;#39;ve invested into in the current company?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Apologies if this is a bit all over the place,  but it was a little tough getting my thoughts across.&lt;/p&gt;\n\n&lt;p&gt;Also would love if anyone is down to discuss more in detail on dm, if that&amp;#39;s preferred.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nncgka", "is_robot_indexable": true, "report_reasons": null, "author": "SmogonWanabee", "discussion_type": null, "num_comments": 33, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nncgka/need_input_from_midcareer_dara_scientists_25_year/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nncgka/need_input_from_midcareer_dara_scientists_25_year/", "subreddit_subscribers": 2695443, "created_utc": 1758513393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 22 Sep, 2025 - 29 Sep, 2025", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nnck8a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758513698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nnck8a", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 25, "send_replies": false, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nnck8a/weekly_entering_transitioning_thread_22_sep_2025/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nnck8a/weekly_entering_transitioning_thread_22_sep_2025/", "subreddit_subscribers": 2695443, "created_utc": 1758513698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone Cruyff dribbling...?", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Well well...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1nnqb2c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/81vZ9m-jV7-OCPqMG-VuFck5siM3LGscWlylw47pvr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758556495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone Cruyff dribbling...?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ss1rtnc5nqqf1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ss1rtnc5nqqf1.jpeg?auto=webp&amp;s=73859c0096a77438ed3178a750a9266818005400", "width": 456, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/ss1rtnc5nqqf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2e374e104027ae8961d44983b747798244dbd948", "width": 108, "height": 216}, {"url": "https://preview.redd.it/ss1rtnc5nqqf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef54aa2cc36376ffdfdaf031b17f025550d95464", "width": 216, "height": 432}, {"url": "https://preview.redd.it/ss1rtnc5nqqf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80393fb1f387e29ae64767811d5b2ce7ee54d270", "width": 320, "height": 640}], "variants": {}, "id": "oc2yVAeraBhjyg204xVivvxOBSAvfK6hlyWwwbVeyX8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "1nnqb2c", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 23, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nnqb2c/well_well/", "stickied": false, "url": "https://i.redd.it/ss1rtnc5nqqf1.jpeg", "subreddit_subscribers": 2695443, "created_utc": 1758556495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9g58m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updated based on subreddit feedback. Applying for mid-senior based roles. Thank you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1nl92og", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VoTeVI39inrtLP7D4L8ZctkmcZkWMxE3e8WEdjVwHlw.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758301143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4yq1ffjlj5qf1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4yq1ffjlj5qf1.png?auto=webp&amp;s=5cae138e7960fc3bce58ef2c794ddec030f257cc", "width": 660, "height": 875}, "resolutions": [{"url": "https://preview.redd.it/4yq1ffjlj5qf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1326307e86db81eb6559b595fd7146da09845767", "width": 108, "height": 143}, {"url": "https://preview.redd.it/4yq1ffjlj5qf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a31d5ef64261d55fb43eb5627464ffe7ad015c3", "width": 216, "height": 286}, {"url": "https://preview.redd.it/4yq1ffjlj5qf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d33fc18c5fe449849944a736857ff530eb0ec7b2", "width": 320, "height": 424}, {"url": "https://preview.redd.it/4yq1ffjlj5qf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=87349f8082d1346e9ac28cb53630562f38bddf23", "width": 640, "height": 848}], "variants": {}, "id": "HF3-dGjbUadQQ-HDgXWXDAa-qQhNcr9Q3ExeLaQqjSY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nl92og", "is_robot_indexable": true, "report_reasons": null, "author": "StormyT", "discussion_type": null, "num_comments": 32, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nl92og/updated_based_on_subreddit_feedback_applying_for/", "stickied": false, "url": "https://i.redd.it/4yq1ffjlj5qf1.png", "subreddit_subscribers": 2695443, "created_utc": 1758301143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have come across usually two types of scenarios here and I am not sure what\u2019s the best way to deal. \n\n- I ask for a range and they give you range. Should you just say you\u2019re okay with the range? But what if I make 80K now and their range is 90-120. In this case I don\u2019t wanna move at 90K. What should you say?\n\n- They just don\u2019t give you any range and keep pressing to give them a  number. In this case I feel like there\u2019s chances of getting low balled later.\n\nI have a couple of recruiter rounds coming up. Could really use your help. Thanks!", "author_fullname": "t2_13xfrfu1xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the right thing to say to salary expectations question?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nl4jtx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758290830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have come across usually two types of scenarios here and I am not sure what\u2019s the best way to deal. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I ask for a range and they give you range. Should you just say you\u2019re okay with the range? But what if I make 80K now and their range is 90-120. In this case I don\u2019t wanna move at 90K. What should you say?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;They just don\u2019t give you any range and keep pressing to give them a  number. In this case I feel like there\u2019s chances of getting low balled later.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have a couple of recruiter rounds coming up. Could really use your help. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nl4jtx", "is_robot_indexable": true, "report_reasons": null, "author": "Lamp_Shade_Head", "discussion_type": null, "num_comments": 60, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nl4jtx/whats_the_right_thing_to_say_to_salary/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nl4jtx/whats_the_right_thing_to_say_to_salary/", "subreddit_subscribers": 2695443, "created_utc": 1758290830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, \n\nI am working on observational studies and need some guidance on confounder and model selection, are you following a best practise when it comes to observational studies? \n\n  \nMy situation is, we have models to predict who will churn based on a whole set of features and then we reach out to them, and the ones that answer become our treatment and the ones that don't become our control. Then based on a bunch of features of their behaviour in the previous year, I use a model to find the features that most likely predict who will answer and use those as the confounders. As they were most related to the treated group. \n\n  \nThen would use something like TMLE,psw etc to find the ATE.\n\n  \nHow do you decide what to do if there isnt any domain knowledge, is there a textbook or methods you follow to conduct your tests?", "author_fullname": "t2_u7io3tm4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to actually perform observational studies in industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nl4oi1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758291139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, &lt;/p&gt;\n\n&lt;p&gt;I am working on observational studies and need some guidance on confounder and model selection, are you following a best practise when it comes to observational studies? &lt;/p&gt;\n\n&lt;p&gt;My situation is, we have models to predict who will churn based on a whole set of features and then we reach out to them, and the ones that answer become our treatment and the ones that don&amp;#39;t become our control. Then based on a bunch of features of their behaviour in the previous year, I use a model to find the features that most likely predict who will answer and use those as the confounders. As they were most related to the treated group. &lt;/p&gt;\n\n&lt;p&gt;Then would use something like TMLE,psw etc to find the ATE.&lt;/p&gt;\n\n&lt;p&gt;How do you decide what to do if there isnt any domain knowledge, is there a textbook or methods you follow to conduct your tests?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nl4oi1", "is_robot_indexable": true, "report_reasons": null, "author": "LebrawnJames416", "discussion_type": null, "num_comments": 10, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nl4oi1/how_to_actually_perform_observational_studies_in/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nl4oi1/how_to_actually_perform_observational_studies_in/", "subreddit_subscribers": 2695443, "created_utc": 1758291139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone have boilerplate Python code for using Keras or similar to run a transformer model on data where each time step of each sequence is, say, 3 dimensions?\n\nE.g.:\n\nData 1: [(3,5,0),(4,6,1)], label = 1\nData 2: [(6,3,0)], label = 0\n\nI\u2019m having trouble getting my ChatGPT-coded model to perform, which is surprising since I was able to get decent results when I just looked at one of the 3 featured with the same ordering, data, and number of steps.\n\nAny boilerplate Python code would be of great help. I\u2019m unable to find something basic online, but I\u2019m sure it\u2019s out there so appreciate being pointed in the right direction.", "author_fullname": "t2_jafoyer3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transformer with multi-dimensional timesteps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nlldi9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758331885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have boilerplate Python code for using Keras or similar to run a transformer model on data where each time step of each sequence is, say, 3 dimensions?&lt;/p&gt;\n\n&lt;p&gt;E.g.:&lt;/p&gt;\n\n&lt;p&gt;Data 1: [(3,5,0),(4,6,1)], label = 1\nData 2: [(6,3,0)], label = 0&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having trouble getting my ChatGPT-coded model to perform, which is surprising since I was able to get decent results when I just looked at one of the 3 featured with the same ordering, data, and number of steps.&lt;/p&gt;\n\n&lt;p&gt;Any boilerplate Python code would be of great help. I\u2019m unable to find something basic online, but I\u2019m sure it\u2019s out there so appreciate being pointed in the right direction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1nlldi9", "is_robot_indexable": true, "report_reasons": null, "author": "transferrr334", "discussion_type": null, "num_comments": 5, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nlldi9/transformer_with_multidimensional_timesteps/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nlldi9/transformer_with_multidimensional_timesteps/", "subreddit_subscribers": 2695443, "created_utc": 1758331885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://preview.redd.it/u9fxkmmqgspf1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=b616b9a5d725d680f9bc76dc09f2b9d62aed079a\n\nI\u2019ve been experimenting with a way to teach LLMs to extract structured data from documents by \\*\\*annotating, not prompt engineering\\*\\*. Instead of fiddling with prompts that sometimes regress, you just build up examples. Each example improves accuracy in a concrete way, and you often need far fewer than traditional ML approaches.\n\n\n\nHow it works (prototype is live):\n\n\\- Upload a document (DOCX, PDF, image, etc.)\n\n\\- Select and tag parts of it (supports nesting, arrays, custom tag structures)\n\n\\- Upload another document \u2192 click \"predict\" \u2192 see editable annotations\n\n\\- Amend them and save as another example\n\n\\- Call the API with a third document \u2192 get JSON back\n\n\n\nPotential use cases:\n\n\\- Identify important clauses in contracts\n\n\\- Extract total value from invoices\n\n\\- Subjective tags like \u201chealthy ingredients\u201d on a label\n\n\\- Objective tags like \u201cpostcode\u201d or \u201cphone number\u201d\n\nIt seems to generalize well: you can even tag things like \u201cgood rhymes\u201d in a poem. Basically anything an LLM can comprehend and extrapolate.\n\n\n\nI\u2019d love feedback on:\n\n\\- Does this kind of few-shot / K-shot approach seem useful in practice?\n\n\\- Are there other document-processing scenarios where this would be particularly impactful?\n\n\\- Pitfalls you\u2019d anticipate?\n\n  \nI've called this \"DeepTagger\", first link on google if you search that, if you want to try it! It's fully working, but this is just a first version.", "author_fullname": "t2_14wp0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "K-shot training with LLMs for document annotation/extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u9fxkmmqgspf1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=017296431ad9fa1bedf379e0f375b4e83f0008ca"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=10b57b754e64b2547332f58f980e0d1a9f6af5fd"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c5991e78e9b154f954860585689303420a288909"}, {"y": 256, "x": 640, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc98a3fd0e298482731b88e60a8046232bd981c4"}, {"y": 384, "x": 960, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ddb607fb0ece8f76b5188bab761d3faba8fb1097"}, {"y": 432, "x": 1080, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=739b3f9beb5dae81379c49774a5b43292813877b"}], "s": {"y": 800, "x": 2000, "u": "https://preview.redd.it/u9fxkmmqgspf1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=b616b9a5d725d680f9bc76dc09f2b9d62aed079a"}, "id": "u9fxkmmqgspf1"}}, "name": "t3_1njp4vy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bbntkEBs6zTHD1iQFxEFcY4lASJq1rShcOpC6Zu6wEc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758142800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/u9fxkmmqgspf1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b616b9a5d725d680f9bc76dc09f2b9d62aed079a\"&gt;https://preview.redd.it/u9fxkmmqgspf1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b616b9a5d725d680f9bc76dc09f2b9d62aed079a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been experimenting with a way to teach LLMs to extract structured data from documents by **annotating, not prompt engineering**. Instead of fiddling with prompts that sometimes regress, you just build up examples. Each example improves accuracy in a concrete way, and you often need far fewer than traditional ML approaches.&lt;/p&gt;\n\n&lt;p&gt;How it works (prototype is live):&lt;/p&gt;\n\n&lt;p&gt;- Upload a document (DOCX, PDF, image, etc.)&lt;/p&gt;\n\n&lt;p&gt;- Select and tag parts of it (supports nesting, arrays, custom tag structures)&lt;/p&gt;\n\n&lt;p&gt;- Upload another document \u2192 click &amp;quot;predict&amp;quot; \u2192 see editable annotations&lt;/p&gt;\n\n&lt;p&gt;- Amend them and save as another example&lt;/p&gt;\n\n&lt;p&gt;- Call the API with a third document \u2192 get JSON back&lt;/p&gt;\n\n&lt;p&gt;Potential use cases:&lt;/p&gt;\n\n&lt;p&gt;- Identify important clauses in contracts&lt;/p&gt;\n\n&lt;p&gt;- Extract total value from invoices&lt;/p&gt;\n\n&lt;p&gt;- Subjective tags like \u201chealthy ingredients\u201d on a label&lt;/p&gt;\n\n&lt;p&gt;- Objective tags like \u201cpostcode\u201d or \u201cphone number\u201d&lt;/p&gt;\n\n&lt;p&gt;It seems to generalize well: you can even tag things like \u201cgood rhymes\u201d in a poem. Basically anything an LLM can comprehend and extrapolate.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d love feedback on:&lt;/p&gt;\n\n&lt;p&gt;- Does this kind of few-shot / K-shot approach seem useful in practice?&lt;/p&gt;\n\n&lt;p&gt;- Are there other document-processing scenarios where this would be particularly impactful?&lt;/p&gt;\n\n&lt;p&gt;- Pitfalls you\u2019d anticipate?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve called this &amp;quot;DeepTagger&amp;quot;, first link on google if you search that, if you want to try it! It&amp;#39;s fully working, but this is just a first version.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1njp4vy", "is_robot_indexable": true, "report_reasons": null, "author": "avloss", "discussion_type": null, "num_comments": 12, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1njp4vy/kshot_training_with_llms_for_document/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1njp4vy/kshot_training_with_llms_for_document/", "subreddit_subscribers": 2695443, "created_utc": 1758142800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Edit: formatting data dictionary\n\nHello,\n\nThought this might be an interesting post for some, especially those of us who work at Financial Institutions. Here is a take home assignment used in the interview process to evaluate candidates for a data scientist role in the financial industry. This company does personal lending in the US.\n\nHopefully this is enough on topic (and not against the rules) as this is for a data scientist role, but it also is very financially focused. I'm not looking for help in anyway, just hope this might helpful to someone looking for a role in this area. I know a lot of people are against take home assignments, I get it, but the reality is many employers still use them.\n\nI'll try to format things as best as possible, but it's tough when you can't post attachments.\n\n**Instructions**\n\nEmployer uses machine learning models to evaluate borrower risk and determine loan eligibility. In July 2024, we launched **Model B** to replace **Model A**, aiming to improve loan approvals and portfolio returns. Our executive team has expressed concern that Model B might be underperforming in some cases.\n\nYour task is to assess the performance of Models A and B across these loan product types and answer the central question: **Should we roll back to Model A or keep and improve Model B?** Additionally, analyze the dataset to uncover any other insights that could guide our decision-making and optimize our lending strategy.\n\nPlease put together a presentation summarizing your findings, insights, and recommendations. Assume your audience has a low level of familiarity with the specifics of the problem but will appreciate clear, data-driven reasoning and business implications. You will present your findings in a 45 minute meeting with stakeholders but ensure to leave ample time for their questions.\n\n**Data Dictionary (for the two attachments below):**\n\n* *Origination Month:* Month in which the loan was funded.\n* *Payment Month:* Payments are made monthly. The first payment is made a month after origination. Payment number refers to future payments from the loans that originated in the specified month. For an origination taking place in Jan 2023, their 1st payment month will take place in Feb 2023, their 2nd payment month will take place in March 2023, etc\u2026\n* *Model Version:* Model\\_A is the original model and Model\\_B is the new, updated model.\n* *Scheduled Loan Repayment:* The loan repayments as determined by the amortization schedule at origination.\n* *Forecasted Loan Repayment:* The loan repayments that are forecasted by each model at origination.\n* *Actual Loan Repayment:* The actual loan repayments made during each payment month by borrowers.\n* *Application Submits:* Loan applications that are submitted.\n* *Origination Amount:* The initial principal amount when the loan is funded.\n* *Note: Employer earns revenue as a % fee of the loan origination amount and the investor (Employer\u2019s lending partners which provide the capital for Employer to lend) earns returns based on interest net loss*\n\n**Attachment 1**\n\n|| || |Month|Application Submits|Origination Amount| |1/1/23|134,194|$7,245,878| |2/1/23|118,084|$6,291,085| |3/1/23|151,789|$6,978,795| |4/1/23|147,247|$7,629,398| |5/1/23|144,106|$7,386,274| |6/1/23|166,063|$7,607,082| |7/1/23|175,438|$8,302,775| |8/1/23|173,874|$9,136,815| |9/1/23|199,833|$9,556,795| |10/1/23|173,089|$9,305,852| |11/1/23|177,250|$9,383,253| |12/1/23|229,996|$11,186,584| |1/1/24|198,578|$10,922,898| |2/1/24|216,549|$12,409,692| |3/1/24|216,083|$11,248,453| |4/1/24|215,525|$12,350,982| |5/1/24|193,528|$10,995,911| |6/1/24|201,425|$12,011,017| |7/1/24|220,760|$10,487,390| |8/1/24|199,445|$10,180,941| |9/1/24|187,549|$10,518,739| |10/1/24|187,075|$10,095,767| |11/1/24|198,951|$10,281,715| |12/1/24|210,259|$10,266,566 |\n\n**Attachement 2**\n\n|| || |Origination Month|Model Version|Payment Number|Scheduled Loan Repayment|Forecasted Loan Repayment|Actual Loan Repayment| |1/1/23|Model\\_A|1|$106,000.00|$105,788.00|$105,788.00| |1/1/23|Model\\_A|2|$106,000.00|$105,576.42|$105,945.94| |1/1/23|Model\\_A|3|$106,000.00|$105,365.27|$105,312.59| |1/1/23|Model\\_A|4|$106,000.00|$105,154.54|$105,007.32| |1/1/23|Model\\_A|5|$106,000.00|$104,944.23|$104,660.88| |1/1/23|Model\\_A|6|$106,000.00|$104,734.34|$104,430.61| |1/1/23|Model\\_A|7|$106,000.00|$104,524.87|$105,037.04| |1/1/23|Model\\_A|8|$106,000.00|$104,315.82|$104,211.50| |1/1/23|Model\\_A|9|$106,000.00|$104,107.19|$104,471.57| |1/1/23|Model\\_A|10|$106,000.00|$103,898.98|$103,898.98| |1/1/23|Model\\_A|11|$106,000.00|$103,691.18|$103,421.58| |1/1/23|Model\\_A|12|$106,000.00|$103,483.80|$103,338.92| |1/1/23|Model\\_A|13|$106,000.00|$103,276.83|$102,967.00| |1/1/23|Model\\_A|14|$106,000.00|$103,070.28|$103,163.04| |1/1/23|Model\\_A|15|$106,000.00|$102,864.14|$102,349.82| |1/1/23|Model\\_A|16|$106,000.00|$102,658.41|$102,781.60| |1/1/23|Model\\_A|17|$106,000.00|$102,453.09|$102,729.71| |1/1/23|Model\\_A|18|$106,000.00|$102,248.18|$102,329.98| |1/1/23|Model\\_A|19|$106,000.00|$102,043.68|$99,880.61| |1/1/23|Model\\_A|20|$106,000.00|$101,839.59|$99,442.54| |1/1/23|Model\\_A|21|$106,000.00|$101,635.91|$99,451.76| |1/1/23|Model\\_A|22|$106,000.00|$101,432.64|$98,451.79| |1/1/23|Model\\_A|23|$106,000.00|$101,229.77|$98,314.10| |2/1/23|Model\\_A|1|$93,730.00|$93,542.54|$93,730.00| |2/1/23|Model\\_A|2|$93,730.00|$93,355.45|$93,411.46| |2/1/23|Model\\_A|3|$93,730.00|$93,168.74|$93,429.61| |2/1/23|Model\\_A|4|$93,730.00|$92,982.40|$93,382.22| |2/1/23|Model\\_A|5|$93,730.00|$92,796.44|$92,351.02| |2/1/23|Model\\_A|6|$93,730.00|$92,610.85|$92,184.84| |2/1/23|Model\\_A|7|$93,730.00|$92,425.63|$92,887.76| |2/1/23|Model\\_A|8|$93,730.00|$92,240.78|$91,844.14| |2/1/23|Model\\_A|9|$93,730.00|$92,056.30|$92,001.07| |2/1/23|Model\\_A|10|$93,730.00|$91,872.19|$92,101.87| |2/1/23|Model\\_A|11|$93,730.00|$91,688.45|$91,624.27| |2/1/23|Model\\_A|12|$93,730.00|$91,505.07|$91,404.41| |2/1/23|Model\\_A|13|$93,730.00|$91,322.06|$90,920.24| |2/1/23|Model\\_A|14|$93,730.00|$91,139.42|$91,522.21| |2/1/23|Model\\_A|15|$93,730.00|$90,957.14|$91,139.05| |2/1/23|Model\\_A|16|$93,730.00|$90,775.23|$90,602.76| |2/1/23|Model\\_A|17|$93,730.00|$90,593.68|$90,765.81| |2/1/23|Model\\_A|18|$93,730.00|$90,412.49|$88,187.43| |2/1/23|Model\\_A|19|$93,730.00|$90,231.67|$87,694.36| |2/1/23|Model\\_A|20|$93,730.00|$90,051.21|$87,641.89| |2/1/23|Model\\_A|21|$93,730.00|$89,871.11|$87,343.93| |2/1/23|Model\\_A|22|$93,730.00|$89,691.37|$87,580.26| |3/1/23|Model\\_A|1|$98,580.00|$98,382.84|$97,989.31| |3/1/23|Model\\_A|2|$98,580.00|$98,186.07|$97,734.41| |3/1/23|Model\\_A|3|$98,580.00|$97,989.70|$98,215.08| |3/1/23|Model\\_A|4|$98,580.00|$97,793.72|$97,617.69| |3/1/23|Model\\_A|5|$98,580.00|$97,598.13|$97,754.29| |3/1/23|Model\\_A|6|$98,580.00|$97,402.93|$97,841.24| |3/1/23|Model\\_A|7|$98,580.00|$97,208.12|$96,858.17| |3/1/23|Model\\_A|8|$98,580.00|$97,013.70|$97,149.52| |3/1/23|Model\\_A|9|$98,580.00|$96,819.67|$96,626.03| |3/1/23|Model\\_A|10|$98,580.00|$96,626.03|$96,394.13| |3/1/23|Model\\_A|11|$98,580.00|$96,432.78|$96,760.65| |3/1/23|Model\\_A|12|$98,580.00|$96,239.91|$96,365.02| |3/1/23|Model\\_A|13|$98,580.00|$96,047.43|$96,114.66| |3/1/23|Model\\_A|14|$98,580.00|$95,855.34|$96,056.64| |3/1/23|Model\\_A|15|$98,580.00|$95,663.63|$95,730.59| |3/1/23|Model\\_A|16|$98,580.00|$95,472.30|$95,625.06| |3/1/23|Model\\_A|17|$98,580.00|$95,281.36|$92,490.57| |3/1/23|Model\\_A|18|$98,580.00|$95,090.80|$93,112.20| |3/1/23|Model\\_A|19|$98,580.00|$94,900.62|$92,565.12| |3/1/23|Model\\_A|20|$98,580.00|$94,710.82|$92,315.35| |3/1/23|Model\\_A|21|$98,580.00|$94,521.40|$92,600.72| |4/1/23|Model\\_A|1|$103,550.00|$103,342.90|$103,260.23| |4/1/23|Model\\_A|2|$103,550.00|$103,136.21|$103,363.11| |4/1/23|Model\\_A|3|$103,550.00|$102,929.94|$102,857.89| |4/1/23|Model\\_A|4|$103,550.00|$102,724.08|$102,272.09| |4/1/23|Model\\_A|5|$103,550.00|$102,518.63|$102,293.09| |4/1/23|Model\\_A|6|$103,550.00|$102,313.59|$102,579.61| |4/1/23|Model\\_A|7|$103,550.00|$102,108.96|$101,996.64| |4/1/23|Model\\_A|8|$103,550.00|$101,904.74|$102,322.55| |4/1/23|Model\\_A|9|$103,550.00|$101,700.93|$101,975.52| |4/1/23|Model\\_A|10|$103,550.00|$101,497.53|$101,142.29| |4/1/23|Model\\_A|11|$103,550.00|$101,294.53|$100,909.61| |4/1/23|Model\\_A|12|$103,550.00|$101,091.94|$101,395.22| |4/1/23|Model\\_A|13|$103,550.00|$100,889.76|$100,960.38| |4/1/23|Model\\_A|14|$103,550.00|$100,687.98|$100,718.19| |4/1/23|Model\\_A|15|$103,550.00|$100,486.60|$100,808.16| |4/1/23|Model\\_A|16|$103,550.00|$100,285.63|$98,247.83| |4/1/23|Model\\_A|17|$103,550.00|$100,085.06|$97,534.14| |4/1/23|Model\\_A|18|$103,550.00|$99,884.89|$97,231.94| |4/1/23|Model\\_A|19|$103,550.00|$99,685.12|$97,348.50| |4/1/23|Model\\_A|20|$103,550.00|$99,485.75|$97,182.90| |5/1/23|Model\\_A|1|$118,720.00|$118,482.56|$118,720.00| |5/1/23|Model\\_A|2|$118,720.00|$118,245.59|$118,352.01| |5/1/23|Model\\_A|3|$118,720.00|$118,009.10|$118,079.91| |5/1/23|Model\\_A|4|$118,720.00|$117,773.08|$117,902.63| |5/1/23|Model\\_A|5|$118,720.00|$117,537.53|$116,961.60| |5/1/23|Model\\_A|6|$118,720.00|$117,302.45|$116,950.54| |5/1/23|Model\\_A|7|$118,720.00|$117,067.85|$117,220.04| |5/1/23|Model\\_A|8|$118,720.00|$116,833.71|$116,646.78| |5/1/23|Model\\_A|9|$118,720.00|$116,600.04|$116,961.50| |5/1/23|Model\\_A|10|$118,720.00|$116,366.84|$116,029.38| |5/1/23|Model\\_A|11|$118,720.00|$116,134.11|$116,459.29| |5/1/23|Model\\_A|12|$118,720.00|$115,901.84|$116,006.15| |5/1/23|Model\\_A|13|$118,720.00|$115,670.04|$115,843.55| |5/1/23|Model\\_A|14|$118,720.00|$115,438.70|$115,865.82| |5/1/23|Model\\_A|15|$118,720.00|$115,207.82|$112,395.02| |5/1/23|Model\\_A|16|$118,720.00|$114,977.40|$111,688.18| |5/1/23|Model\\_A|17|$118,720.00|$114,747.45|$111,431.25| |5/1/23|Model\\_A|18|$118,720.00|$114,517.96|$111,230.72| |5/1/23|Model\\_A|19|$118,720.00|$114,288.92|$111,598.84| |6/1/23|Model\\_A|1|$109,250.00|$109,031.50|$109,250.00| |6/1/23|Model\\_A|2|$109,250.00|$108,813.44|$108,933.13| |6/1/23|Model\\_A|3|$109,250.00|$108,595.81|$108,856.44| |6/1/23|Model\\_A|4|$109,250.00|$108,378.62|$108,476.16| |6/1/23|Model\\_A|5|$109,250.00|$108,161.86|$107,642.68| |6/1/23|Model\\_A|6|$109,250.00|$107,945.54|$108,129.05| |6/1/23|Model\\_A|7|$109,250.00|$107,729.65|$107,772.74| |6/1/23|Model\\_A|8|$109,250.00|$107,514.19|$107,116.39| |6/1/23|Model\\_A|9|$109,250.00|$107,299.16|$107,470.84| |6/1/23|Model\\_A|10|$109,250.00|$107,084.56|$107,063.14| |6/1/23|Model\\_A|11|$109,250.00|$106,870.39|$106,870.39| |6/1/23|Model\\_A|12|$109,250.00|$106,656.65|$106,912.63| |6/1/23|Model\\_A|13|$109,250.00|$106,443.34|$106,666.87| |6/1/23|Model\\_A|14|$109,250.00|$106,230.45|$103,864.70| |6/1/23|Model\\_A|15|$109,250.00|$106,017.99|$102,985.08| |6/1/23|Model\\_A|16|$109,250.00|$105,805.95|$103,625.03| |6/1/23|Model\\_A|17|$109,250.00|$105,594.34|$103,335.41| |6/1/23|Model\\_A|18|$109,250.00|$105,383.15|$103,025.99| |7/1/23|Model\\_A|1|$109,740.00|$109,520.52|$109,137.20| |7/1/23|Model\\_A|2|$109,740.00|$109,301.48|$109,050.09| |7/1/23|Model\\_A|3|$109,740.00|$109,082.88|$109,355.59| |7/1/23|Model\\_A|4|$109,740.00|$108,864.71|$109,256.62| |7/1/23|Model\\_A|5|$109,740.00|$108,646.98|$108,799.09| |7/1/23|Model\\_A|6|$109,740.00|$108,429.69|$108,505.59| |7/1/23|Model\\_A|7|$109,740.00|$108,212.83|$108,515.83| |7/1/23|Model\\_A|8|$109,740.00|$107,996.40|$108,082.80| |7/1/23|Model\\_A|9|$109,740.00|$107,780.41|$107,618.74| |7/1/23|Model\\_A|10|$109,740.00|$107,564.85|$107,629.39| |7/1/23|Model\\_A|11|$109,740.00|$107,349.72|$107,596.62| |7/1/23|Model\\_A|12|$109,740.00|$107,135.02|$107,638.55| |7/1/23|Model\\_A|13|$109,740.00|$106,920.75|$104,153.91| |7/1/23|Model\\_A|14|$109,740.00|$106,706.91|$104,060.04| |7/1/23|Model\\_A|15|$109,740.00|$106,493.50|$103,415.84| |7/1/23|Model\\_A|16|$109,740.00|$106,280.51|$103,177.91| |7/1/23|Model\\_A|17|$109,740.00|$106,067.95|$103,374.88| |8/1/23|Model\\_A|1|$117,370.00|$117,135.26|$117,370.00| |8/1/23|Model\\_A|2|$117,370.00|$116,900.99|$117,064.65| |8/1/23|Model\\_A|3|$117,370.00|$116,667.19|$116,748.86| |8/1/23|Model\\_A|4|$117,370.00|$116,433.86|$116,690.01| |8/1/23|Model\\_A|5|$117,370.00|$116,200.99|$116,108.03| |8/1/23|Model\\_A|6|$117,370.00|$115,968.59|$116,351.29| |8/1/23|Model\\_A|7|$117,370.00|$115,736.65|$115,482.03| |8/1/23|Model\\_A|8|$117,370.00|$115,505.18|$115,736.19| |8/1/23|Model\\_A|9|$117,370.00|$115,274.17|$114,905.29| |8/1/23|Model\\_A|10|$117,370.00|$115,043.62|$115,124.15| |8/1/23|Model\\_A|11|$117,370.00|$114,813.53|$114,928.34| |8/1/23|Model\\_A|12|$117,370.00|$114,583.90|$111,350.63| |8/1/23|Model\\_A|13|$117,370.00|$114,354.73|$111,585.05| |8/1/23|Model\\_A|14|$117,370.00|$114,126.02|$110,850.03| |8/1/23|Model\\_A|15|$117,370.00|$113,897.77|$111,139.17| |8/1/23|Model\\_A|16|$117,370.00|$113,669.97|$110,872.55| |9/1/23|Model\\_A|1|$112,840.00|$112,614.32|$112,062.51| |9/1/23|Model\\_A|2|$112,840.00|$112,389.09|$112,096.88| |9/1/23|Model\\_A|3|$112,840.00|$112,164.31|$111,951.20| |9/1/23|Model\\_A|4|$112,840.00|$111,939.98|$112,342.96| |9/1/23|Model\\_A|5|$112,840.00|$111,716.10|$111,459.15| |9/1/23|Model\\_A|6|$112,840.00|$111,492.67|$111,838.30| |9/1/23|Model\\_A|7|$112,840.00|$111,269.68|$111,113.90| |9/1/23|Model\\_A|8|$112,840.00|$111,047.14|$111,169.29| |9/1/23|Model\\_A|9|$112,840.00|$110,825.05|$110,913.71| |9/1/23|Model\\_A|10|$112,840.00|$110,603.40|$110,271.59| |9/1/23|Model\\_A|11|$112,840.00|$110,382.19|$107,730.26| |9/1/23|Model\\_A|12|$112,840.00|$110,161.43|$107,514.80| |9/1/23|Model\\_A|13|$112,840.00|$109,941.11|$106,656.62| |9/1/23|Model\\_A|14|$112,840.00|$109,721.23|$107,149.36| |9/1/23|Model\\_A|15|$112,840.00|$109,501.79|$106,700.19| |10/1/23|Model\\_A|1|$121,920.00|$121,676.16|$121,920.00| |10/1/23|Model\\_A|2|$121,920.00|$121,432.81|$121,177.80| |10/1/23|Model\\_A|3|$121,920.00|$121,189.94|$120,680.94| |10/1/23|Model\\_A|4|$121,920.00|$120,947.56|$120,475.86| |10/1/23|Model\\_A|5|$121,920.00|$120,705.66|$120,307.33| |10/1/23|Model\\_A|6|$121,920.00|$120,464.25|$120,825.64| |10/1/23|Model\\_A|7|$121,920.00|$120,223.32|$120,680.17| |10/1/23|Model\\_A|8|$121,920.00|$119,982.87|$120,570.79| |10/1/23|Model\\_A|9|$121,920.00|$119,742.90|$120,185.95| |10/1/23|Model\\_A|10|$121,920.00|$119,503.41|$116,224.53| |10/1/23|Model\\_A|11|$121,920.00|$119,264.40|$115,724.63| |10/1/23|Model\\_A|12|$121,920.00|$119,025.87|$115,806.52| |10/1/23|Model\\_A|13|$121,920.00|$118,787.82|$115,667.57| |10/1/23|Model\\_A|14|$121,920.00|$118,550.24|$115,378.43| |11/1/23|Model\\_A|1|$127,400.00|$127,145.20|$127,374.06| |11/1/23|Model\\_A|2|$127,400.00|$126,890.91|$127,208.14| |11/1/23|Model\\_A|3|$127,400.00|$126,637.13|$126,295.21| |11/1/23|Model\\_A|4|$127,400.00|$126,383.86|$126,257.48| |11/1/23|Model\\_A|5|$127,400.00|$126,131.09|$125,815.76| |11/1/23|Model\\_A|6|$127,400.00|$125,878.83|$125,715.19| |11/1/23|Model\\_A|7|$127,400.00|$125,627.07|$125,639.63| |11/1/23|Model\\_A|8|$127,400.00|$125,375.82|$124,786.55| |11/1/23|Model\\_A|9|$127,400.00|$125,125.07|$121,948.14| |11/1/23|Model\\_A|10|$127,400.00|$124,874.82|$121,752.95| |11/1/23|Model\\_A|11|$127,400.00|$124,625.07|$121,363.63| |11/1/23|Model\\_A|12|$127,400.00|$124,375.82|$121,133.03| |11/1/23|Model\\_A|13|$127,400.00|$124,127.07|$121,447.47| |12/1/23|Model\\_A|1|$126,350.00|$126,097.30|$125,895.54| |12/1/23|Model\\_A|2|$126,350.00|$125,845.11|$125,945.79| |12/1/23|Model\\_A|3|$126,350.00|$125,593.42|$125,794.37| |12/1/23|Model\\_A|4|$126,350.00|$125,342.23|$125,104.08| |12/1/23|Model\\_A|5|$126,350.00|$125,091.55|$124,916.42| |12/1/23|Model\\_A|6|$126,350.00|$124,841.37|$125,465.58| |12/1/23|Model\\_A|7|$126,350.00|$124,591.69|$124,853.33| |12/1/23|Model\\_A|8|$126,350.00|$124,342.51|$121,512.79| |12/1/23|Model\\_A|9|$126,350.00|$124,093.82|$120,640.60| |12/1/23|Model\\_A|10|$126,350.00|$123,845.63|$120,858.16| |12/1/23|Model\\_A|11|$126,350.00|$123,597.94|$120,110.32| |12/1/23|Model\\_A|12|$126,350.00|$123,350.74|$120,014.41| |1/1/24|Model\\_A|1|$134,640.00|$134,370.72|$134,236.35| |1/1/24|Model\\_A|2|$134,640.00|$134,101.98|$134,640.00| |1/1/24|Model\\_A|3|$134,640.00|$133,833.78|$133,606.26| |1/1/24|Model\\_A|4|$134,640.00|$133,566.11|$133,472.61| |1/1/24|Model\\_A|5|$134,640.00|$133,298.98|$133,538.92| |1/1/24|Model\\_A|6|$134,640.00|$133,032.38|$133,631.03| |1/1/24|Model\\_A|7|$134,640.00|$132,766.32|$129,408.33| |1/1/24|Model\\_A|8|$134,640.00|$132,500.79|$129,304.54| |1/1/24|Model\\_A|9|$134,640.00|$132,235.79|$129,097.51| |1/1/24|Model\\_A|10|$134,640.00|$131,971.32|$128,028.67| |1/1/24|Model\\_A|11|$134,640.00|$131,707.38|$128,016.61| |2/1/24|Model\\_A|1|$127,880.00|$127,624.24|$127,560.43| |2/1/24|Model\\_A|2|$127,880.00|$127,368.99|$126,846.78| |2/1/24|Model\\_A|3|$127,880.00|$127,114.25|$127,482.88| |2/1/24|Model\\_A|4|$127,880.00|$126,860.02|$127,481.63| |2/1/24|Model\\_A|5|$127,880.00|$126,606.30|$126,770.89| |2/1/24|Model\\_A|6|$127,880.00|$126,353.09|$123,108.02| |2/1/24|Model\\_A|7|$127,880.00|$126,100.38|$122,566.73| |2/1/24|Model\\_A|8|$127,880.00|$125,848.18|$123,205.06| |2/1/24|Model\\_A|9|$127,880.00|$125,596.48|$122,236.15| |2/1/24|Model\\_A|10|$127,880.00|$125,345.29|$121,686.15| |3/1/24|Model\\_A|1|$129,220.00|$128,961.56|$128,561.78| |3/1/24|Model\\_A|2|$129,220.00|$128,703.64|$129,192.71| |3/1/24|Model\\_A|3|$129,220.00|$128,446.23|$129,049.93| |3/1/24|Model\\_A|4|$129,220.00|$128,189.34|$128,253.43| |3/1/24|Model\\_A|5|$129,220.00|$127,932.96|$124,884.32| |3/1/24|Model\\_A|6|$129,220.00|$127,677.09|$124,273.54| |3/1/24|Model\\_A|7|$129,220.00|$127,421.74|$123,975.30| |3/1/24|Model\\_A|8|$129,220.00|$127,166.90|$124,161.31| |3/1/24|Model\\_A|9|$129,220.00|$126,912.57|$124,271.83| |4/1/24|Model\\_A|1|$134,850.00|$134,580.30|$134,270.77| |4/1/24|Model\\_A|2|$134,850.00|$134,311.14|$133,881.34| |4/1/24|Model\\_A|3|$134,850.00|$134,042.52|$133,559.97| |4/1/24|Model\\_A|4|$134,850.00|$133,774.43|$130,077.91| |4/1/24|Model\\_A|5|$134,850.00|$133,506.88|$130,156.19| |4/1/24|Model\\_A|6|$134,850.00|$133,239.87|$129,259.33| |4/1/24|Model\\_A|7|$134,850.00|$132,973.39|$129,363.83| |4/1/24|Model\\_A|8|$134,850.00|$132,707.44|$129,557.96| |5/1/24|Model\\_A|1|$134,680.00|$134,410.64|$134,680.00| |5/1/24|Model\\_A|2|$134,680.00|$134,141.82|$134,490.59| |5/1/24|Model\\_A|3|$134,680.00|$133,873.54|$130,017.64| |5/1/24|Model\\_A|4|$134,680.00|$133,605.79|$130,304.72| |5/1/24|Model\\_A|5|$134,680.00|$133,338.58|$130,408.13| |5/1/24|Model\\_A|6|$134,680.00|$133,071.90|$129,394.79| |5/1/24|Model\\_A|7|$134,680.00|$132,805.76|$128,928.83| |6/1/24|Model\\_A|1|$154,020.00|$153,711.96|$154,020.00| |6/1/24|Model\\_A|2|$154,020.00|$153,404.54|$149,389.94| |6/1/24|Model\\_A|3|$154,020.00|$153,097.73|$149,165.80| |6/1/24|Model\\_A|4|$154,020.00|$152,791.53|$149,567.63| |6/1/24|Model\\_A|5|$154,020.00|$152,485.95|$148,837.34| |6/1/24|Model\\_A|6|$154,020.00|$152,180.98|$148,064.87| |7/1/24|Model\\_B|1|$127,066.50|$126,812.37|$123,431.87| |7/1/24|Model\\_B|2|$127,066.50|$126,558.75|$123,690.93| |7/1/24|Model\\_B|3|$127,066.50|$126,305.63|$123,455.86| |7/1/24|Model\\_B|4|$127,066.50|$126,053.02|$122,655.89| |7/1/24|Model\\_B|5|$127,066.50|$125,800.91|$122,888.93| |8/1/24|Model\\_B|1|$130,917.00|$130,655.17|$127,644.08| |8/1/24|Model\\_B|2|$130,917.00|$130,393.86|$126,739.90| |8/1/24|Model\\_B|3|$130,917.00|$130,133.07|$126,968.56| |8/1/24|Model\\_B|4|$130,917.00|$129,872.80|$126,208.11| |9/1/24|Model\\_B|1|$133,484.00|$133,217.03|$129,419.01| |9/1/24|Model\\_B|2|$133,484.00|$132,950.60|$129,212.03| |9/1/24|Model\\_B|3|$133,484.00|$132,684.70|$129,755.68| |10/1/24|Model\\_B|1|$125,783.00|$125,531.43|$122,601.21| |10/1/24|Model\\_B|2|$125,783.00|$125,280.37|$122,026.21| |11/1/24|Model\\_B|1|$130,917.00|$130,655.17|$127,528.92 |", "author_fullname": "t2_vgaagv00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Example Take Home Assignment For Interview - Data Science in Finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1njcvfv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career | US", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1758116771.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758114945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: formatting data dictionary&lt;/p&gt;\n\n&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Thought this might be an interesting post for some, especially those of us who work at Financial Institutions. Here is a take home assignment used in the interview process to evaluate candidates for a data scientist role in the financial industry. This company does personal lending in the US.&lt;/p&gt;\n\n&lt;p&gt;Hopefully this is enough on topic (and not against the rules) as this is for a data scientist role, but it also is very financially focused. I&amp;#39;m not looking for help in anyway, just hope this might helpful to someone looking for a role in this area. I know a lot of people are against take home assignments, I get it, but the reality is many employers still use them.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll try to format things as best as possible, but it&amp;#39;s tough when you can&amp;#39;t post attachments.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Employer uses machine learning models to evaluate borrower risk and determine loan eligibility. In July 2024, we launched &lt;strong&gt;Model B&lt;/strong&gt; to replace &lt;strong&gt;Model A&lt;/strong&gt;, aiming to improve loan approvals and portfolio returns. Our executive team has expressed concern that Model B might be underperforming in some cases.&lt;/p&gt;\n\n&lt;p&gt;Your task is to assess the performance of Models A and B across these loan product types and answer the central question: &lt;strong&gt;Should we roll back to Model A or keep and improve Model B?&lt;/strong&gt; Additionally, analyze the dataset to uncover any other insights that could guide our decision-making and optimize our lending strategy.&lt;/p&gt;\n\n&lt;p&gt;Please put together a presentation summarizing your findings, insights, and recommendations. Assume your audience has a low level of familiarity with the specifics of the problem but will appreciate clear, data-driven reasoning and business implications. You will present your findings in a 45 minute meeting with stakeholders but ensure to leave ample time for their questions.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Dictionary (for the two attachments below):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;Origination Month:&lt;/em&gt; Month in which the loan was funded.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Payment Month:&lt;/em&gt; Payments are made monthly. The first payment is made a month after origination. Payment number refers to future payments from the loans that originated in the specified month. For an origination taking place in Jan 2023, their 1st payment month will take place in Feb 2023, their 2nd payment month will take place in March 2023, etc\u2026&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Model Version:&lt;/em&gt; Model_A is the original model and Model_B is the new, updated model.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Scheduled Loan Repayment:&lt;/em&gt; The loan repayments as determined by the amortization schedule at origination.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Forecasted Loan Repayment:&lt;/em&gt; The loan repayments that are forecasted by each model at origination.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Actual Loan Repayment:&lt;/em&gt; The actual loan repayments made during each payment month by borrowers.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Application Submits:&lt;/em&gt; Loan applications that are submitted.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Origination Amount:&lt;/em&gt; The initial principal amount when the loan is funded.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Note: Employer earns revenue as a % fee of the loan origination amount and the investor (Employer\u2019s lending partners which provide the capital for Employer to lend) earns returns based on interest net loss&lt;/em&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Attachment 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;|| || |Month|Application Submits|Origination Amount| |1/1/23|134,194|$7,245,878| |2/1/23|118,084|$6,291,085| |3/1/23|151,789|$6,978,795| |4/1/23|147,247|$7,629,398| |5/1/23|144,106|$7,386,274| |6/1/23|166,063|$7,607,082| |7/1/23|175,438|$8,302,775| |8/1/23|173,874|$9,136,815| |9/1/23|199,833|$9,556,795| |10/1/23|173,089|$9,305,852| |11/1/23|177,250|$9,383,253| |12/1/23|229,996|$11,186,584| |1/1/24|198,578|$10,922,898| |2/1/24|216,549|$12,409,692| |3/1/24|216,083|$11,248,453| |4/1/24|215,525|$12,350,982| |5/1/24|193,528|$10,995,911| |6/1/24|201,425|$12,011,017| |7/1/24|220,760|$10,487,390| |8/1/24|199,445|$10,180,941| |9/1/24|187,549|$10,518,739| |10/1/24|187,075|$10,095,767| |11/1/24|198,951|$10,281,715| |12/1/24|210,259|$10,266,566 |&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Attachement 2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;|| || |Origination Month|Model Version|Payment Number|Scheduled Loan Repayment|Forecasted Loan Repayment|Actual Loan Repayment| |1/1/23|Model_A|1|$106,000.00|$105,788.00|$105,788.00| |1/1/23|Model_A|2|$106,000.00|$105,576.42|$105,945.94| |1/1/23|Model_A|3|$106,000.00|$105,365.27|$105,312.59| |1/1/23|Model_A|4|$106,000.00|$105,154.54|$105,007.32| |1/1/23|Model_A|5|$106,000.00|$104,944.23|$104,660.88| |1/1/23|Model_A|6|$106,000.00|$104,734.34|$104,430.61| |1/1/23|Model_A|7|$106,000.00|$104,524.87|$105,037.04| |1/1/23|Model_A|8|$106,000.00|$104,315.82|$104,211.50| |1/1/23|Model_A|9|$106,000.00|$104,107.19|$104,471.57| |1/1/23|Model_A|10|$106,000.00|$103,898.98|$103,898.98| |1/1/23|Model_A|11|$106,000.00|$103,691.18|$103,421.58| |1/1/23|Model_A|12|$106,000.00|$103,483.80|$103,338.92| |1/1/23|Model_A|13|$106,000.00|$103,276.83|$102,967.00| |1/1/23|Model_A|14|$106,000.00|$103,070.28|$103,163.04| |1/1/23|Model_A|15|$106,000.00|$102,864.14|$102,349.82| |1/1/23|Model_A|16|$106,000.00|$102,658.41|$102,781.60| |1/1/23|Model_A|17|$106,000.00|$102,453.09|$102,729.71| |1/1/23|Model_A|18|$106,000.00|$102,248.18|$102,329.98| |1/1/23|Model_A|19|$106,000.00|$102,043.68|$99,880.61| |1/1/23|Model_A|20|$106,000.00|$101,839.59|$99,442.54| |1/1/23|Model_A|21|$106,000.00|$101,635.91|$99,451.76| |1/1/23|Model_A|22|$106,000.00|$101,432.64|$98,451.79| |1/1/23|Model_A|23|$106,000.00|$101,229.77|$98,314.10| |2/1/23|Model_A|1|$93,730.00|$93,542.54|$93,730.00| |2/1/23|Model_A|2|$93,730.00|$93,355.45|$93,411.46| |2/1/23|Model_A|3|$93,730.00|$93,168.74|$93,429.61| |2/1/23|Model_A|4|$93,730.00|$92,982.40|$93,382.22| |2/1/23|Model_A|5|$93,730.00|$92,796.44|$92,351.02| |2/1/23|Model_A|6|$93,730.00|$92,610.85|$92,184.84| |2/1/23|Model_A|7|$93,730.00|$92,425.63|$92,887.76| |2/1/23|Model_A|8|$93,730.00|$92,240.78|$91,844.14| |2/1/23|Model_A|9|$93,730.00|$92,056.30|$92,001.07| |2/1/23|Model_A|10|$93,730.00|$91,872.19|$92,101.87| |2/1/23|Model_A|11|$93,730.00|$91,688.45|$91,624.27| |2/1/23|Model_A|12|$93,730.00|$91,505.07|$91,404.41| |2/1/23|Model_A|13|$93,730.00|$91,322.06|$90,920.24| |2/1/23|Model_A|14|$93,730.00|$91,139.42|$91,522.21| |2/1/23|Model_A|15|$93,730.00|$90,957.14|$91,139.05| |2/1/23|Model_A|16|$93,730.00|$90,775.23|$90,602.76| |2/1/23|Model_A|17|$93,730.00|$90,593.68|$90,765.81| |2/1/23|Model_A|18|$93,730.00|$90,412.49|$88,187.43| |2/1/23|Model_A|19|$93,730.00|$90,231.67|$87,694.36| |2/1/23|Model_A|20|$93,730.00|$90,051.21|$87,641.89| |2/1/23|Model_A|21|$93,730.00|$89,871.11|$87,343.93| |2/1/23|Model_A|22|$93,730.00|$89,691.37|$87,580.26| |3/1/23|Model_A|1|$98,580.00|$98,382.84|$97,989.31| |3/1/23|Model_A|2|$98,580.00|$98,186.07|$97,734.41| |3/1/23|Model_A|3|$98,580.00|$97,989.70|$98,215.08| |3/1/23|Model_A|4|$98,580.00|$97,793.72|$97,617.69| |3/1/23|Model_A|5|$98,580.00|$97,598.13|$97,754.29| |3/1/23|Model_A|6|$98,580.00|$97,402.93|$97,841.24| |3/1/23|Model_A|7|$98,580.00|$97,208.12|$96,858.17| |3/1/23|Model_A|8|$98,580.00|$97,013.70|$97,149.52| |3/1/23|Model_A|9|$98,580.00|$96,819.67|$96,626.03| |3/1/23|Model_A|10|$98,580.00|$96,626.03|$96,394.13| |3/1/23|Model_A|11|$98,580.00|$96,432.78|$96,760.65| |3/1/23|Model_A|12|$98,580.00|$96,239.91|$96,365.02| |3/1/23|Model_A|13|$98,580.00|$96,047.43|$96,114.66| |3/1/23|Model_A|14|$98,580.00|$95,855.34|$96,056.64| |3/1/23|Model_A|15|$98,580.00|$95,663.63|$95,730.59| |3/1/23|Model_A|16|$98,580.00|$95,472.30|$95,625.06| |3/1/23|Model_A|17|$98,580.00|$95,281.36|$92,490.57| |3/1/23|Model_A|18|$98,580.00|$95,090.80|$93,112.20| |3/1/23|Model_A|19|$98,580.00|$94,900.62|$92,565.12| |3/1/23|Model_A|20|$98,580.00|$94,710.82|$92,315.35| |3/1/23|Model_A|21|$98,580.00|$94,521.40|$92,600.72| |4/1/23|Model_A|1|$103,550.00|$103,342.90|$103,260.23| |4/1/23|Model_A|2|$103,550.00|$103,136.21|$103,363.11| |4/1/23|Model_A|3|$103,550.00|$102,929.94|$102,857.89| |4/1/23|Model_A|4|$103,550.00|$102,724.08|$102,272.09| |4/1/23|Model_A|5|$103,550.00|$102,518.63|$102,293.09| |4/1/23|Model_A|6|$103,550.00|$102,313.59|$102,579.61| |4/1/23|Model_A|7|$103,550.00|$102,108.96|$101,996.64| |4/1/23|Model_A|8|$103,550.00|$101,904.74|$102,322.55| |4/1/23|Model_A|9|$103,550.00|$101,700.93|$101,975.52| |4/1/23|Model_A|10|$103,550.00|$101,497.53|$101,142.29| |4/1/23|Model_A|11|$103,550.00|$101,294.53|$100,909.61| |4/1/23|Model_A|12|$103,550.00|$101,091.94|$101,395.22| |4/1/23|Model_A|13|$103,550.00|$100,889.76|$100,960.38| |4/1/23|Model_A|14|$103,550.00|$100,687.98|$100,718.19| |4/1/23|Model_A|15|$103,550.00|$100,486.60|$100,808.16| |4/1/23|Model_A|16|$103,550.00|$100,285.63|$98,247.83| |4/1/23|Model_A|17|$103,550.00|$100,085.06|$97,534.14| |4/1/23|Model_A|18|$103,550.00|$99,884.89|$97,231.94| |4/1/23|Model_A|19|$103,550.00|$99,685.12|$97,348.50| |4/1/23|Model_A|20|$103,550.00|$99,485.75|$97,182.90| |5/1/23|Model_A|1|$118,720.00|$118,482.56|$118,720.00| |5/1/23|Model_A|2|$118,720.00|$118,245.59|$118,352.01| |5/1/23|Model_A|3|$118,720.00|$118,009.10|$118,079.91| |5/1/23|Model_A|4|$118,720.00|$117,773.08|$117,902.63| |5/1/23|Model_A|5|$118,720.00|$117,537.53|$116,961.60| |5/1/23|Model_A|6|$118,720.00|$117,302.45|$116,950.54| |5/1/23|Model_A|7|$118,720.00|$117,067.85|$117,220.04| |5/1/23|Model_A|8|$118,720.00|$116,833.71|$116,646.78| |5/1/23|Model_A|9|$118,720.00|$116,600.04|$116,961.50| |5/1/23|Model_A|10|$118,720.00|$116,366.84|$116,029.38| |5/1/23|Model_A|11|$118,720.00|$116,134.11|$116,459.29| |5/1/23|Model_A|12|$118,720.00|$115,901.84|$116,006.15| |5/1/23|Model_A|13|$118,720.00|$115,670.04|$115,843.55| |5/1/23|Model_A|14|$118,720.00|$115,438.70|$115,865.82| |5/1/23|Model_A|15|$118,720.00|$115,207.82|$112,395.02| |5/1/23|Model_A|16|$118,720.00|$114,977.40|$111,688.18| |5/1/23|Model_A|17|$118,720.00|$114,747.45|$111,431.25| |5/1/23|Model_A|18|$118,720.00|$114,517.96|$111,230.72| |5/1/23|Model_A|19|$118,720.00|$114,288.92|$111,598.84| |6/1/23|Model_A|1|$109,250.00|$109,031.50|$109,250.00| |6/1/23|Model_A|2|$109,250.00|$108,813.44|$108,933.13| |6/1/23|Model_A|3|$109,250.00|$108,595.81|$108,856.44| |6/1/23|Model_A|4|$109,250.00|$108,378.62|$108,476.16| |6/1/23|Model_A|5|$109,250.00|$108,161.86|$107,642.68| |6/1/23|Model_A|6|$109,250.00|$107,945.54|$108,129.05| |6/1/23|Model_A|7|$109,250.00|$107,729.65|$107,772.74| |6/1/23|Model_A|8|$109,250.00|$107,514.19|$107,116.39| |6/1/23|Model_A|9|$109,250.00|$107,299.16|$107,470.84| |6/1/23|Model_A|10|$109,250.00|$107,084.56|$107,063.14| |6/1/23|Model_A|11|$109,250.00|$106,870.39|$106,870.39| |6/1/23|Model_A|12|$109,250.00|$106,656.65|$106,912.63| |6/1/23|Model_A|13|$109,250.00|$106,443.34|$106,666.87| |6/1/23|Model_A|14|$109,250.00|$106,230.45|$103,864.70| |6/1/23|Model_A|15|$109,250.00|$106,017.99|$102,985.08| |6/1/23|Model_A|16|$109,250.00|$105,805.95|$103,625.03| |6/1/23|Model_A|17|$109,250.00|$105,594.34|$103,335.41| |6/1/23|Model_A|18|$109,250.00|$105,383.15|$103,025.99| |7/1/23|Model_A|1|$109,740.00|$109,520.52|$109,137.20| |7/1/23|Model_A|2|$109,740.00|$109,301.48|$109,050.09| |7/1/23|Model_A|3|$109,740.00|$109,082.88|$109,355.59| |7/1/23|Model_A|4|$109,740.00|$108,864.71|$109,256.62| |7/1/23|Model_A|5|$109,740.00|$108,646.98|$108,799.09| |7/1/23|Model_A|6|$109,740.00|$108,429.69|$108,505.59| |7/1/23|Model_A|7|$109,740.00|$108,212.83|$108,515.83| |7/1/23|Model_A|8|$109,740.00|$107,996.40|$108,082.80| |7/1/23|Model_A|9|$109,740.00|$107,780.41|$107,618.74| |7/1/23|Model_A|10|$109,740.00|$107,564.85|$107,629.39| |7/1/23|Model_A|11|$109,740.00|$107,349.72|$107,596.62| |7/1/23|Model_A|12|$109,740.00|$107,135.02|$107,638.55| |7/1/23|Model_A|13|$109,740.00|$106,920.75|$104,153.91| |7/1/23|Model_A|14|$109,740.00|$106,706.91|$104,060.04| |7/1/23|Model_A|15|$109,740.00|$106,493.50|$103,415.84| |7/1/23|Model_A|16|$109,740.00|$106,280.51|$103,177.91| |7/1/23|Model_A|17|$109,740.00|$106,067.95|$103,374.88| |8/1/23|Model_A|1|$117,370.00|$117,135.26|$117,370.00| |8/1/23|Model_A|2|$117,370.00|$116,900.99|$117,064.65| |8/1/23|Model_A|3|$117,370.00|$116,667.19|$116,748.86| |8/1/23|Model_A|4|$117,370.00|$116,433.86|$116,690.01| |8/1/23|Model_A|5|$117,370.00|$116,200.99|$116,108.03| |8/1/23|Model_A|6|$117,370.00|$115,968.59|$116,351.29| |8/1/23|Model_A|7|$117,370.00|$115,736.65|$115,482.03| |8/1/23|Model_A|8|$117,370.00|$115,505.18|$115,736.19| |8/1/23|Model_A|9|$117,370.00|$115,274.17|$114,905.29| |8/1/23|Model_A|10|$117,370.00|$115,043.62|$115,124.15| |8/1/23|Model_A|11|$117,370.00|$114,813.53|$114,928.34| |8/1/23|Model_A|12|$117,370.00|$114,583.90|$111,350.63| |8/1/23|Model_A|13|$117,370.00|$114,354.73|$111,585.05| |8/1/23|Model_A|14|$117,370.00|$114,126.02|$110,850.03| |8/1/23|Model_A|15|$117,370.00|$113,897.77|$111,139.17| |8/1/23|Model_A|16|$117,370.00|$113,669.97|$110,872.55| |9/1/23|Model_A|1|$112,840.00|$112,614.32|$112,062.51| |9/1/23|Model_A|2|$112,840.00|$112,389.09|$112,096.88| |9/1/23|Model_A|3|$112,840.00|$112,164.31|$111,951.20| |9/1/23|Model_A|4|$112,840.00|$111,939.98|$112,342.96| |9/1/23|Model_A|5|$112,840.00|$111,716.10|$111,459.15| |9/1/23|Model_A|6|$112,840.00|$111,492.67|$111,838.30| |9/1/23|Model_A|7|$112,840.00|$111,269.68|$111,113.90| |9/1/23|Model_A|8|$112,840.00|$111,047.14|$111,169.29| |9/1/23|Model_A|9|$112,840.00|$110,825.05|$110,913.71| |9/1/23|Model_A|10|$112,840.00|$110,603.40|$110,271.59| |9/1/23|Model_A|11|$112,840.00|$110,382.19|$107,730.26| |9/1/23|Model_A|12|$112,840.00|$110,161.43|$107,514.80| |9/1/23|Model_A|13|$112,840.00|$109,941.11|$106,656.62| |9/1/23|Model_A|14|$112,840.00|$109,721.23|$107,149.36| |9/1/23|Model_A|15|$112,840.00|$109,501.79|$106,700.19| |10/1/23|Model_A|1|$121,920.00|$121,676.16|$121,920.00| |10/1/23|Model_A|2|$121,920.00|$121,432.81|$121,177.80| |10/1/23|Model_A|3|$121,920.00|$121,189.94|$120,680.94| |10/1/23|Model_A|4|$121,920.00|$120,947.56|$120,475.86| |10/1/23|Model_A|5|$121,920.00|$120,705.66|$120,307.33| |10/1/23|Model_A|6|$121,920.00|$120,464.25|$120,825.64| |10/1/23|Model_A|7|$121,920.00|$120,223.32|$120,680.17| |10/1/23|Model_A|8|$121,920.00|$119,982.87|$120,570.79| |10/1/23|Model_A|9|$121,920.00|$119,742.90|$120,185.95| |10/1/23|Model_A|10|$121,920.00|$119,503.41|$116,224.53| |10/1/23|Model_A|11|$121,920.00|$119,264.40|$115,724.63| |10/1/23|Model_A|12|$121,920.00|$119,025.87|$115,806.52| |10/1/23|Model_A|13|$121,920.00|$118,787.82|$115,667.57| |10/1/23|Model_A|14|$121,920.00|$118,550.24|$115,378.43| |11/1/23|Model_A|1|$127,400.00|$127,145.20|$127,374.06| |11/1/23|Model_A|2|$127,400.00|$126,890.91|$127,208.14| |11/1/23|Model_A|3|$127,400.00|$126,637.13|$126,295.21| |11/1/23|Model_A|4|$127,400.00|$126,383.86|$126,257.48| |11/1/23|Model_A|5|$127,400.00|$126,131.09|$125,815.76| |11/1/23|Model_A|6|$127,400.00|$125,878.83|$125,715.19| |11/1/23|Model_A|7|$127,400.00|$125,627.07|$125,639.63| |11/1/23|Model_A|8|$127,400.00|$125,375.82|$124,786.55| |11/1/23|Model_A|9|$127,400.00|$125,125.07|$121,948.14| |11/1/23|Model_A|10|$127,400.00|$124,874.82|$121,752.95| |11/1/23|Model_A|11|$127,400.00|$124,625.07|$121,363.63| |11/1/23|Model_A|12|$127,400.00|$124,375.82|$121,133.03| |11/1/23|Model_A|13|$127,400.00|$124,127.07|$121,447.47| |12/1/23|Model_A|1|$126,350.00|$126,097.30|$125,895.54| |12/1/23|Model_A|2|$126,350.00|$125,845.11|$125,945.79| |12/1/23|Model_A|3|$126,350.00|$125,593.42|$125,794.37| |12/1/23|Model_A|4|$126,350.00|$125,342.23|$125,104.08| |12/1/23|Model_A|5|$126,350.00|$125,091.55|$124,916.42| |12/1/23|Model_A|6|$126,350.00|$124,841.37|$125,465.58| |12/1/23|Model_A|7|$126,350.00|$124,591.69|$124,853.33| |12/1/23|Model_A|8|$126,350.00|$124,342.51|$121,512.79| |12/1/23|Model_A|9|$126,350.00|$124,093.82|$120,640.60| |12/1/23|Model_A|10|$126,350.00|$123,845.63|$120,858.16| |12/1/23|Model_A|11|$126,350.00|$123,597.94|$120,110.32| |12/1/23|Model_A|12|$126,350.00|$123,350.74|$120,014.41| |1/1/24|Model_A|1|$134,640.00|$134,370.72|$134,236.35| |1/1/24|Model_A|2|$134,640.00|$134,101.98|$134,640.00| |1/1/24|Model_A|3|$134,640.00|$133,833.78|$133,606.26| |1/1/24|Model_A|4|$134,640.00|$133,566.11|$133,472.61| |1/1/24|Model_A|5|$134,640.00|$133,298.98|$133,538.92| |1/1/24|Model_A|6|$134,640.00|$133,032.38|$133,631.03| |1/1/24|Model_A|7|$134,640.00|$132,766.32|$129,408.33| |1/1/24|Model_A|8|$134,640.00|$132,500.79|$129,304.54| |1/1/24|Model_A|9|$134,640.00|$132,235.79|$129,097.51| |1/1/24|Model_A|10|$134,640.00|$131,971.32|$128,028.67| |1/1/24|Model_A|11|$134,640.00|$131,707.38|$128,016.61| |2/1/24|Model_A|1|$127,880.00|$127,624.24|$127,560.43| |2/1/24|Model_A|2|$127,880.00|$127,368.99|$126,846.78| |2/1/24|Model_A|3|$127,880.00|$127,114.25|$127,482.88| |2/1/24|Model_A|4|$127,880.00|$126,860.02|$127,481.63| |2/1/24|Model_A|5|$127,880.00|$126,606.30|$126,770.89| |2/1/24|Model_A|6|$127,880.00|$126,353.09|$123,108.02| |2/1/24|Model_A|7|$127,880.00|$126,100.38|$122,566.73| |2/1/24|Model_A|8|$127,880.00|$125,848.18|$123,205.06| |2/1/24|Model_A|9|$127,880.00|$125,596.48|$122,236.15| |2/1/24|Model_A|10|$127,880.00|$125,345.29|$121,686.15| |3/1/24|Model_A|1|$129,220.00|$128,961.56|$128,561.78| |3/1/24|Model_A|2|$129,220.00|$128,703.64|$129,192.71| |3/1/24|Model_A|3|$129,220.00|$128,446.23|$129,049.93| |3/1/24|Model_A|4|$129,220.00|$128,189.34|$128,253.43| |3/1/24|Model_A|5|$129,220.00|$127,932.96|$124,884.32| |3/1/24|Model_A|6|$129,220.00|$127,677.09|$124,273.54| |3/1/24|Model_A|7|$129,220.00|$127,421.74|$123,975.30| |3/1/24|Model_A|8|$129,220.00|$127,166.90|$124,161.31| |3/1/24|Model_A|9|$129,220.00|$126,912.57|$124,271.83| |4/1/24|Model_A|1|$134,850.00|$134,580.30|$134,270.77| |4/1/24|Model_A|2|$134,850.00|$134,311.14|$133,881.34| |4/1/24|Model_A|3|$134,850.00|$134,042.52|$133,559.97| |4/1/24|Model_A|4|$134,850.00|$133,774.43|$130,077.91| |4/1/24|Model_A|5|$134,850.00|$133,506.88|$130,156.19| |4/1/24|Model_A|6|$134,850.00|$133,239.87|$129,259.33| |4/1/24|Model_A|7|$134,850.00|$132,973.39|$129,363.83| |4/1/24|Model_A|8|$134,850.00|$132,707.44|$129,557.96| |5/1/24|Model_A|1|$134,680.00|$134,410.64|$134,680.00| |5/1/24|Model_A|2|$134,680.00|$134,141.82|$134,490.59| |5/1/24|Model_A|3|$134,680.00|$133,873.54|$130,017.64| |5/1/24|Model_A|4|$134,680.00|$133,605.79|$130,304.72| |5/1/24|Model_A|5|$134,680.00|$133,338.58|$130,408.13| |5/1/24|Model_A|6|$134,680.00|$133,071.90|$129,394.79| |5/1/24|Model_A|7|$134,680.00|$132,805.76|$128,928.83| |6/1/24|Model_A|1|$154,020.00|$153,711.96|$154,020.00| |6/1/24|Model_A|2|$154,020.00|$153,404.54|$149,389.94| |6/1/24|Model_A|3|$154,020.00|$153,097.73|$149,165.80| |6/1/24|Model_A|4|$154,020.00|$152,791.53|$149,567.63| |6/1/24|Model_A|5|$154,020.00|$152,485.95|$148,837.34| |6/1/24|Model_A|6|$154,020.00|$152,180.98|$148,064.87| |7/1/24|Model_B|1|$127,066.50|$126,812.37|$123,431.87| |7/1/24|Model_B|2|$127,066.50|$126,558.75|$123,690.93| |7/1/24|Model_B|3|$127,066.50|$126,305.63|$123,455.86| |7/1/24|Model_B|4|$127,066.50|$126,053.02|$122,655.89| |7/1/24|Model_B|5|$127,066.50|$125,800.91|$122,888.93| |8/1/24|Model_B|1|$130,917.00|$130,655.17|$127,644.08| |8/1/24|Model_B|2|$130,917.00|$130,393.86|$126,739.90| |8/1/24|Model_B|3|$130,917.00|$130,133.07|$126,968.56| |8/1/24|Model_B|4|$130,917.00|$129,872.80|$126,208.11| |9/1/24|Model_B|1|$133,484.00|$133,217.03|$129,419.01| |9/1/24|Model_B|2|$133,484.00|$132,950.60|$129,212.03| |9/1/24|Model_B|3|$133,484.00|$132,684.70|$129,755.68| |10/1/24|Model_B|1|$125,783.00|$125,531.43|$122,601.21| |10/1/24|Model_B|2|$125,783.00|$125,280.37|$122,026.21| |11/1/24|Model_B|1|$130,917.00|$130,655.17|$127,528.92 |&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ea9e2296-0db0-11ef-bb4d-6e8d785fd493", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1njcvfv", "is_robot_indexable": true, "report_reasons": null, "author": "chasing_green_roads", "discussion_type": null, "num_comments": 17, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1njcvfv/example_take_home_assignment_for_interview_data/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1njcvfv/example_take_home_assignment_for_interview_data/", "subreddit_subscribers": 2695443, "created_utc": 1758114945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, we are running some campaigns and then looking back retrospectively to see if they worked. How do you determine the correct sample size? Does a normal power size calculator work in this scenario? \n\nI\u2019ve seen some conflicting thoughts on this, wondering how you\u2019ve all done it on your projects.", "author_fullname": "t2_u7io3tm4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you conduct a power analysis on a causal observational study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nj55qy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1758088747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, we are running some campaigns and then looking back retrospectively to see if they worked. How do you determine the correct sample size? Does a normal power size calculator work in this scenario? &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen some conflicting thoughts on this, wondering how you\u2019ve all done it on your projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nj55qy", "is_robot_indexable": true, "report_reasons": null, "author": "LebrawnJames416", "discussion_type": null, "num_comments": 14, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nj55qy/how_do_you_conduct_a_power_analysis_on_a_causal/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nj55qy/how_do_you_conduct_a_power_analysis_on_a_causal/", "subreddit_subscribers": 2695443, "created_utc": 1758088747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1c7jac40", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Privacy-Safe Tabular Synthetic Data with TabPFN", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1nj9mu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=140&amp;height=93&amp;crop=140:93,smart&amp;auto=webp&amp;s=afe389fbfb24cf74580fe67ed04ea53fe0233844", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758105679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@kursat002/generate-privacy-safe-tabular-synthetic-data-in-seconds-with-tabpfn-2a2567937fb5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?auto=webp&amp;s=674b4d7b1f2ffb2a5751548cd4ab3995744aee3e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1cd64e3781e2a3251ec4f6784b817aa71a6a143", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0827a48d637f923ecf76b227e1da57ebca3e05c4", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2bd32fdac4a797150f378520419f383d3baf9210", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7779cb4c8a7ae85ab4c89964a14d43731828a2c4", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=549a19a89103055527bb437124d5ec8950be5d61", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd9ed2db7388a3d82ea8345a3720465f16b8e795", "width": 1080, "height": 720}], "variants": {}, "id": "JftUQuX5xZUjtaMUBoHCkUhMZ7gNl_M66q5zSIOdRX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1nj9mu5", "is_robot_indexable": true, "report_reasons": null, "author": "rsesrsfh", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nj9mu5/privacysafe_tabular_synthetic_data_with_tabpfn/", "stickied": false, "url": "https://medium.com/@kursat002/generate-privacy-safe-tabular-synthetic-data-in-seconds-with-tabpfn-2a2567937fb5", "subreddit_subscribers": 2695443, "created_utc": 1758105679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1niop8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6it324j4", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1niop8o", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=beee7ba622a469094b275dd7aaba6e9d522e234d", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "PythonProjects2", "selftext": "You can start from Anywhere. From Beginners or Intermediate or Advanced or You can Shuffle and Just Enjoy the journey of learning python by these Useful Projects.\n\nWhether you are a beginner or an intermediate in Python. This 5 Hour long Python Project Video will leave you with tremendous information , on how to build logic and Apps and also with an introduction to Gemini. \n\nYou will start from Beginner Projects and End up with Building Live apps. This Python Project video will help you in putting some great resume projects  and also help you in understanding the real use case of python. \n\nThis is an eye opening Python Video and you will be not the same python programmer after completing it.", "author_fullname": "t2_6it324j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "link_flair_richtext": [], "subreddit_name_prefixed": "r/PythonProjects2", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1nfsouc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1nfsouc", "height": 200}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "image", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "created": 1757753891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can start from Anywhere. From Beginners or Intermediate or Advanced or You can Shuffle and Just Enjoy the journey of learning python by these Useful Projects.&lt;/p&gt;\n\n&lt;p&gt;Whether you are a beginner or an intermediate in Python. This 5 Hour long Python Project Video will leave you with tremendous information , on how to build logic and Apps and also with an introduction to Gemini. &lt;/p&gt;\n\n&lt;p&gt;You will start from Beginner Projects and End up with Building Live apps. This Python Project video will help you in putting some great resume projects  and also help you in understanding the real use case of python. &lt;/p&gt;\n\n&lt;p&gt;This is an eye opening Python Video and you will be not the same python programmer after completing it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/wIrPdBnoZHo", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?auto=webp&amp;s=8244e765d6da605b2aaf440d7d9896883c305a86", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4754d23c9b72e9e645358337e04f80b437164a90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04573cdd072b51a6967d81225dddfb28a75f00c3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4f4fafe5e486d53b6f7838f419ede8b26e0fd0c", "width": 320, "height": 240}], "variants": {}, "id": "gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_fnrmm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1nfsouc", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Buyer-569", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/PythonProjects2/comments/1nfsouc/python_projects_for_beginners_to_advanced_build/", "stickied": false, "url": "https://youtu.be/wIrPdBnoZHo", "subreddit_subscribers": 47952, "created_utc": 1757753891.0, "num_crossposts": 1, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_video": false}], "created": 1758045430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/wIrPdBnoZHo", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?auto=webp&amp;s=8244e765d6da605b2aaf440d7d9896883c305a86", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4754d23c9b72e9e645358337e04f80b437164a90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04573cdd072b51a6967d81225dddfb28a75f00c3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4f4fafe5e486d53b6f7838f419ede8b26e0fd0c", "width": 320, "height": 240}], "variants": {}, "id": "gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1niop8o", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Buyer-569", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1nfsouc", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1niop8o/python_projects_for_beginners_to_advanced_build/", "stickied": false, "url": "https://youtu.be/wIrPdBnoZHo", "subreddit_subscribers": 2695443, "created_utc": 1758045430.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Only those win who stay till the end.\u201d\n\nComplete the whole series and become really good at python. You can skip the intro.\n\nYou can start from Anywhere. From Beginners or Intermediate or Advanced or You can Shuffle and Just Enjoy the journey of learning python by these Useful Projects.\n\nWhether you are a beginner or an intermediate in Python. This 5 Hour long Python Project Video will leave you with tremendous information , on how to build logic and Apps and also with an introduction to Gemini. \n\nYou will start from Beginner Projects and End up with Building Live apps. This Python Project video will help you in putting some great resume projects  and also help you in understanding the real use case of python. \n\nThis is an eye opening Python Video and you will be not the same python programmer after completing it.\n", "author_fullname": "t2_6it324j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1nioq77", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1nioq77", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=beee7ba622a469094b275dd7aaba6e9d522e234d", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1758045487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Only those win who stay till the end.\u201d&lt;/p&gt;\n\n&lt;p&gt;Complete the whole series and become really good at python. You can skip the intro.&lt;/p&gt;\n\n&lt;p&gt;You can start from Anywhere. From Beginners or Intermediate or Advanced or You can Shuffle and Just Enjoy the journey of learning python by these Useful Projects.&lt;/p&gt;\n\n&lt;p&gt;Whether you are a beginner or an intermediate in Python. This 5 Hour long Python Project Video will leave you with tremendous information , on how to build logic and Apps and also with an introduction to Gemini. &lt;/p&gt;\n\n&lt;p&gt;You will start from Beginner Projects and End up with Building Live apps. This Python Project video will help you in putting some great resume projects  and also help you in understanding the real use case of python. &lt;/p&gt;\n\n&lt;p&gt;This is an eye opening Python Video and you will be not the same python programmer after completing it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/wIrPdBnoZHo?si=w2aAK5X2c_yTFmep", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?auto=webp&amp;s=8244e765d6da605b2aaf440d7d9896883c305a86", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4754d23c9b72e9e645358337e04f80b437164a90", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04573cdd072b51a6967d81225dddfb28a75f00c3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4f4fafe5e486d53b6f7838f419ede8b26e0fd0c", "width": 320, "height": 240}], "variants": {}, "id": "gGAgIFlCaP32m4uZrQNw7UBIh_phSx7cC1YWLI9s_8I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1nioq77", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Buyer-569", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nioq77/python_projects_for_beginners_to_advanced_build/", "stickied": false, "url": "https://youtu.be/wIrPdBnoZHo?si=w2aAK5X2c_yTFmep", "subreddit_subscribers": 2695443, "created_utc": 1758045487.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wIrPdBnoZHo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini\"&gt;&lt;/iframe&gt;", "author_name": "Console Flare", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wIrPdBnoZHo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@consoleflare"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\nI recently got the chance to speak with the HR at a healthcare company that\u2019s working on AI agents to optimize prescription pricing. \nWhile I haven\u2019t directly built AI agents before, I\u2019d like to design a small prototype for my hiring manager round and use that discussion to show how I can tackle their challenges.\nI\u2019ve got about a week to prepare and only ~30 minutes for the conversation, so I\u2019m looking for advice on:\n- How to outline the initial architecture for a project like this (at a high level).\n- What aspects of the design/implementation are most valuable for a hiring manager or senior engineer to see.\n- What to leave out and what to keep so the presentation/my pitch stays focused and impactful.\n\nAppreciate any thoughts\u2014especially from folks who have been on the hiring side and know what really makes someone stand out.\nI am just a bit confused that even if I have a prototype how should I present it naturally and smartly.\n\nEdit : the goal here is to optimize the prescription price by lowering prices where it's still profitable for the company. ", "author_fullname": "t2_acayb4rpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on presenting yourself", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nhzoam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1757982481.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1757973972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI recently got the chance to speak with the HR at a healthcare company that\u2019s working on AI agents to optimize prescription pricing. \nWhile I haven\u2019t directly built AI agents before, I\u2019d like to design a small prototype for my hiring manager round and use that discussion to show how I can tackle their challenges.\nI\u2019ve got about a week to prepare and only ~30 minutes for the conversation, so I\u2019m looking for advice on:\n- How to outline the initial architecture for a project like this (at a high level).\n- What aspects of the design/implementation are most valuable for a hiring manager or senior engineer to see.\n- What to leave out and what to keep so the presentation/my pitch stays focused and impactful.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any thoughts\u2014especially from folks who have been on the hiring side and know what really makes someone stand out.\nI am just a bit confused that even if I have a prototype how should I present it naturally and smartly.&lt;/p&gt;\n\n&lt;p&gt;Edit : the goal here is to optimize the prescription price by lowering prices where it&amp;#39;s still profitable for the company. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nhzoam", "is_robot_indexable": true, "report_reasons": null, "author": "-Cicada7-", "discussion_type": null, "num_comments": 14, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nhzoam/advice_on_presenting_yourself/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nhzoam/advice_on_presenting_yourself/", "subreddit_subscribers": 2695443, "created_utc": 1757973972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI was wondering how do you perform the experiment and factor the seasonality while analyzing it?  (Especially on e-commerce side) \n\nFor example i often wonder when marketing campaigns are done during black Friday/holiday season, how do they know whether the campaign had the causal effect? And how much? When we know people tend to buy more things in holiday season. \n\nSo what test or statistical methods do you use to factor into? Or what are the other methods you use to find how the campaign performed? \n\nFirst i think of is use historical data of the same season for last year, and compare it, but what if we don\u2019t have historical data? \n\nWhat other things need to keep in mind while designing an experiment when we know seasonality could be play big role? And there\u2019s no way we can perform the experiment outside of season? \n\nThanks!\n\n\nEdit- 2nd question, lets say we want to run a promotion during a season, like bf sale, how do you keep treatment and control? Or how do you analyze the effect of sale? As you would not want to hold out on users during sales? Or what companies do during this time to keep a control group ? ", "author_fullname": "t2_5bsp2h4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you factor seasonality in A/B test experiments? Which methods you personally use and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1nhskvc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1757961634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1757958028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I was wondering how do you perform the experiment and factor the seasonality while analyzing it?  (Especially on e-commerce side) &lt;/p&gt;\n\n&lt;p&gt;For example i often wonder when marketing campaigns are done during black Friday/holiday season, how do they know whether the campaign had the causal effect? And how much? When we know people tend to buy more things in holiday season. &lt;/p&gt;\n\n&lt;p&gt;So what test or statistical methods do you use to factor into? Or what are the other methods you use to find how the campaign performed? &lt;/p&gt;\n\n&lt;p&gt;First i think of is use historical data of the same season for last year, and compare it, but what if we don\u2019t have historical data? &lt;/p&gt;\n\n&lt;p&gt;What other things need to keep in mind while designing an experiment when we know seasonality could be play big role? And there\u2019s no way we can perform the experiment outside of season? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;Edit- 2nd question, lets say we want to run a promotion during a season, like bf sale, how do you keep treatment and control? Or how do you analyze the effect of sale? As you would not want to hold out on users during sales? Or what companies do during this time to keep a control group ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1nhskvc", "is_robot_indexable": true, "report_reasons": null, "author": "Starktony11", "discussion_type": null, "num_comments": 40, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1nhskvc/how_do_you_factor_seasonality_in_ab_test/", "stickied": false, "url": "https://www.reddit.com/r/datascience/comments/1nhskvc/how_do_you_factor_seasonality_in_ab_test/", "subreddit_subscribers": 2695443, "created_utc": 1757958028.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}